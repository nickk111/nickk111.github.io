[{"content":"","date":"2024-08-25T11:05:09+08:00","permalink":"https://nickk111.github.io/p/second/","title":"Second"},{"content":"ç¨‹åºäººç”Ÿ \u0026ndash;ä»¥ä¸‹æ˜¯ã€Šæ·±å…¥æµ…å‡ºMFCã€‹ä½œè€…ä¾¯æ·å…ˆç”Ÿäº2001å¹´æ¥åä¸­ç§‘æŠ€å¤§å­¦åšäººæ–‡è®²åº§æ—¶çš„æ¼”è®²å†…å®¹ã€‚\nå¦‚æœä½ ä¸æ›¾å¬è¿‡ä¾¯æ·çš„åå­—ï¼Œä¸æ›¾çŸ¥é“ä¾¯æ·åšçš„äº‹æƒ…ï¼Œä½ ä¸å¯èƒ½æœ‰å…´è¶£èµ°å…¥ä¼šåœºã€‚å› æ­¤ï¼Œå„ä½è¿œé“è€Œæ¥ï¼Œæˆ‘çªƒä»¥ä¸ºï¼Œæ— éæƒ³çœ‹çœ‹ä¾¯æ·æœ¬äººï¼Œå¬å¬ä»–è¯´è¯ã€‚å¦‚æœä½ æœŸç›¼åœ¨è¿™ç§åœºåˆå¬åˆ°æŸæŸæŠ€æœ¯çš„å‰–æï¼ŒæŸæŸè¶‹åŠ¿çš„å‘å±•ï¼Œè‚¯å®šä½ ä¼šå¤±æœ›ã€‚æˆ‘ä¸æ˜¯è¶‹åŠ¿ä¸“å®¶ï¼Œå¯¹æ­¤ä¹Ÿæ¯«æ— å…´è¶£ã€‚å°ä¸Šè¯´è¯å’Œå°ä¸‹èŠå¤©ä¸åŒï¼Œæˆ‘ä¸èƒ½ä¹Ÿä¸æ•¢è®²æˆ‘æ²¡æœ‰å¿ƒå¾—æ²¡æœ‰ç ”ç©¶çš„è¯é¢˜ã€‚â€œ ç¨‹åºäººç”Ÿâ€ è¿™ä¸ªè¯é¢˜æ—¨åœ¨è®©å¤§å®¶å¯¹ä¸€ä¸ªä½ æ„Ÿå…´è¶£çš„äººï¼ˆä¾¯æ·æˆ‘ï¼‰çš„å­¦ä¹ å†ç¨‹æœ‰äº›äº†è§£ï¼Œæˆ–è®¸ä»ä¸­ç»™ä½ ä¸€äº›çµæ„Ÿæˆ–æ¿€åŠ±ã€‚ æˆ‘åœ¨ä¸€ä¸ªè¢«æ˜µç§°ä¸ºâ€œ å°‘æ—å¯ºâ€ï¼ˆå°æ¹¾å·¥ç ”é™¢ï¼‰çš„åœ°æ–¹ï¼Œç£¨ç»ƒä¸‰å¹´ã€‚ååŠæœŸå› ä¸ºå‘ç°äº†è‡ªå·±æµ“çƒˆçš„å…´è¶£ä¸ä¸é”™çš„å¤©èµ‹ï¼Œå†³å®šè½¬å‘æŠ€æœ¯å†™ä½œä¸æ•™è‚²è¿™æ¡è·¯ã€‚3 0å²ä¹‹åçš„æˆ‘ï¼Œ è¡Œäº‹å¸¸æ€â€œ è´¡çŒ®åº¦â€ï¼Œæˆ‘çŸ¥é“è‡ªå·±åœ¨æŠ€æœ¯å†™ä½œä¸æ•™è‚²è¿™æ¡è·¯ä¸Šèƒ½å¤Ÿèµ°å¾—æ¯”ç¨‹åºå¼€å‘æ›´å¥½ï¼Œæ‰€ä»¥å†³å®šæŠŠè‡ªå·±æ‘†åœ¨æœ€é€‚å½“çš„ä½ç½®ã€‚ä¸€å£é£Ÿç‰©ï¼Œæ”¾åœ¨å˜´é‡Œæ˜¯ä½³è‚´ï¼Œåå‡ºæ¥å°±æˆäº†ç§½ç‰©ã€‚å¤©ç”Ÿæˆ‘æå¿…æœ‰ç”¨ï¼Œæ¯ä¸ªäººéƒ½åº”è¯¥ä»”ç»†æ€è€ƒï¼Œè‡ªå·±çœŸæ­£çš„å…´è¶£å’Œæ‰èƒ½åœ¨å“ªé‡Œã€‚å¾ˆå¤šäººéƒ½é—®ï¼Œ3 0 å²ä¹‹ååšä¸åŠ¨ç¨‹åºå‘˜äº†æ€ä¹ˆåŠã€‚3 0 å¹´æ­£æ˜¯è‹±å¹´ï¼Œä½“åŠ›å’Œæ™ºåŠ›å’Œæˆç†Ÿåº¦éƒ½æ­£è¾¾åˆ°å·…å³°ï¼Œæ€ä¹ˆä¼šåšä¸åŠ¨ç¨‹åºï¼Ÿæƒ³å¾€ç®¡ç†é˜¶å±‚èµ°å½“ç„¶å¾ˆå¥½ï¼Œé‚£å°±åŠªåŠ›å……å®è‡ªå·±ï¼Œå¹¶ä¸”æ‰ªå¿ƒè‡ªé—®ï¼Œä½ åšç®¡ç†å¿«ä¹å—ï¼Ÿè¦çŸ¥é“ï¼Œäººäº‹ç»å¯¹æ¯”æœºå™¨è®©ä½ æ›´ç„¦å¤´çƒ‚é¢ã€‚å¦‚æœä½ å†³å®šäº‰å–ä¸€ä¸ªç²¥å°‘åƒ§å¤šçš„èŒä½ï¼Œå°±ä¸è¦å†é—®â€œ æ€ä¹ˆåŠâ€ã€‚è¿˜èƒ½æ€ä¹ˆåŠï¼ŸåŠªåŠ›ä»¥èµ´å‘€ã€‚æ¯”èµ›è¿˜æ²¡å¼€å§‹å°±é—®è¾“äº†æ€ä¹ˆåŠï¼Œè¿™ä¸åƒè¯ï¼Œä½ æ³¨å®šè¦è¾“ã€‚ æŠ€æœ¯å…»æˆé˜¶æ®µï¼Œå¯¹æˆ‘å½±å“æœ€å¤§çš„ä¸€ä»¶äº‹æ˜¯ï¼Œæˆ‘è‡ªåŠ¨è¯·ç¼¨åšä¸€å¥—å…¬ç”¨ç¨‹åºåº“ï¼Œç›®æ ‡ç»™å…¨éƒ¨é—¨ä¹ƒè‡³å…¨æ‰€ä½¿ç”¨ã€‚è¿™ä½¿æˆ‘å­¦ä¹ åˆ°æŠ€æœ¯çš„æ•´ç†ã€æ–‡ä»¶ï¼ˆd o c u m e n t s ï¼‰çš„æ’°å†™ã€äººé™…çš„æ²Ÿé€šã€‚é‡è¦çš„ä¸åœ¨å…·ä½“å®ä½œï¼Œè€Œåœ¨å¤šæ–¹åŸ¹å…»äº†æ­£ç¡®è§‚å¿µã€‚å¦‚æœä½ é—®æˆ‘ï¼Œå¯¹äºç¨‹åºï¼Œæˆ‘æœ€é‡è§†ä»€ä¹ˆï¼Ÿæˆ‘æœ€é‡è§†å¯è¯»æ€§ï¼ˆå«è¯´æ˜æ–‡ä»¶ï¼‰ã€ç»´æŠ¤æ€§ã€å¤ç”¨æ€§ï¼Œå®Œæ•´æ€§ã€‚è¿™äº›å…¶å®æ˜¯ä¸€ä½“å¤šé¢ã€‚ è½¬å‘æŠ€æœ¯å†™ä½œåï¼Œæˆ‘çš„ç”Ÿæ´»å’Œå¾…åœ¨ä¸šç•Œæ²¡æœ‰ä»€ä¹ˆæ”¹å˜ï¼Œåªä¸è¿‡ä¸šç•Œçš„äº§å‡ºæ˜¯è½¯ä½“ï¼Œæˆ‘çš„äº§å‡ºæ˜¯ä¹¦ç±å’Œæ–‡ç« ã€‚å†™ä¸€æœ¬ä¹¦å’Œè§„åˆ’ä¸€ä¸ªä¸“æ¡ˆï¼ˆp r o j e c t ï¼‰æ²¡ä»€ä¹ˆä¸¤æ ·ã€‚ä½†æ˜¯ï¼Œä¸“å¿ƒäºæŠ€æœ¯å†™ä½œä¹‹åï¼Œä»æ­¤æˆ‘æœ‰ç»å¯¹çš„è‡ªç”±é’»ç ”æˆ‘æœ€æ„Ÿå…´è¶£çš„â€œ æŠ€æœ¯æœ¬è´¨â€ ä¸â€œ æŠ€æœ¯æ ¸å¿ƒâ€ã€‚æˆ‘å‘¨é­çš„æœ‹å‹ï¼Œä½†å‡¡è¡¨ç°ä¸å‡¡è€…ï¼Œéƒ½æœ‰éå‡¡çš„èµ„æ–™æ•´ç†åŠŸå¤«ã€‚å¦‚ä»Šç½‘ç»œå‘è¾¾ï¼Œèµ„è®¯çˆ†ç‚¸ï¼Œç¡¬ç›˜åˆä¾¿å®œï¼Œèµ„æ–™æ•´ç†åŠŸå¤«æ›´æ˜¾é‡è¦ã€‚æ²¡æœ‰ç»è¿‡è‡ªå·±æ•´ç†çš„èµ„æ–™ï¼Œå½¢åŒåƒåœ¾ã€‚è®¸å¤šäººå–œæ¬¢ä¸Šç½‘â€œ æ”¶é›†â€ ä¸€å¤§å †ç”µå­ä¹¦ã€ç”µå­æ–‡æ¡£ã€‚ä½ å¾—æƒ³ä¸ªåŠæ³•æŠŠè¿™äº›åºå¤§çš„èµ„æ–™åŒ–ä¸ºä½ çš„å›¾ä¹¦é¦†ï¼Œè€Œä¸æ˜¯æåœ¨ç¡¬ç›˜è§’è½é‡Œåšä¸ºå®‰æ…°æˆ–ç‚«è€€ã€‚ä¹¦ç±ä¹Ÿä¸€æ ·ï¼Œä¹°æ¥è¦çœ‹ï¼Œå®‰æ…°è‡ªå·±æˆ–ç‚«è€€ä»–äººéƒ½æ²¡æœ‰ä»»ä½•æ„ä¹‰ã€‚å½“ç„¶ï¼Œä¸€æ—¦ä½ åˆ°è¾¾æŸç§å±‚æ¬¡ï¼Œä»¥åŠæŸç§ç»æµèƒ½åŠ›ï¼Œä½ ä¹°ä¹¦ä¸è§å¾—é©¬ä¸Šçœ‹ï¼Œä¸è§å¾—æ•´æœ¬çœ‹ã€‚æˆ‘æœ‰ä¸ªç§äººå°å›¾ä¹¦é¦†ï¼Œå…¶ä¸­çš„ä¹¦æœ‰è®¸å¤šè¿˜æ²¡çœ‹ï¼Œå½“åˆè´­ä¹°æ˜¯å‡†å¤‡éšæ—¶å‚è€ƒç”¨çš„ï¼Œä¹Ÿæœ‰äº›æ˜¯å½“åšå­¦ä¹ çš„ç›®æ ‡ï¼Œæ‘†ç€å‡†å¤‡æœ‰ç©ºæ—¶çœ‹ã€‚ä»Šå¹´æ˜¯æˆ‘å†™ä½œçš„ç¬¬1 0 ä¸ªå¹´å¤´ã€‚æˆ‘è®¤ä¸ºè‡ªå·±ç¡®å®èµ°ä¸Šäº†ä¸€æ¡æœ€é€‚åˆæˆ‘çš„è·¯ï¼Œå°¤å…¶ä»Šå¤©è¿™ä¹ˆçƒ­çƒˆçš„åœºé¢ï¼Œå®åœ¨ä»¤æˆ‘æƒ…ç»ªæ¿€æ˜‚ã€‚æˆ‘ä¸ä¼šå¿¸æ€©ä½œæ€åœ°ä¸æ„¿æ‰¿è®¤æˆ‘çš„ä½œå“ç»™åˆ«äººå¸¦æ¥å¸®åŠ©ï¼Œç„¶è€Œæˆ‘è¦è¯´ï¼Œä½œè€…å’Œè¯»è€…æ˜¯ç›¸äº’æ¿€åŠ±ç›¸äº’å½±å“çš„ï¼Œæˆ‘ä»¬å½¼æ­¤è¿›å…¥äº†ä¸€ä¸ªè‰¯æ€§å¾ªç¯ã€‚æ²¡æœ‰ä¼˜ç§€çš„è¯»è€…ï¼Œå°±æ²¡æœ‰ä¼˜ç§€çš„ä½œè€…ã€‚è‰ºæœ¯å®¶å¯èƒ½ä¸æ˜¯è¿™æ ·ï¼Œä½†ç”µè„‘æŠ€æœ¯å†™ä½œï¼Œæˆ–æ›´ç¼©å°èŒƒå›´åœ°è¯´ï¼Œæˆ‘ï¼Œæ˜¯è¿™æ ·ã€‚å› æ­¤ï¼Œæˆ‘è¦è¡·å¿ƒæ„Ÿè°¢é‚£äº›ç»™æˆ‘é¼“èˆã€ç»™æˆ‘å‹˜è¯¯ã€ç»™æˆ‘èµç¾ã€ç»™æˆ‘æ‰¹è¯„çš„çƒ­æƒ…è¯»è€…ã€‚ä¸‹é¢å›ç­”å‡ ä¸ªå¸¸è¢«æå‡ºæ¥çš„é—®é¢˜ã€‚ 1 . å¦‚ä½•å­¦ä¹  å¤§å“‰é—®ã€‚å­¦ä¹ éœ€è¦æ˜å¸ˆã€‚ä½†æ˜¯æ˜å¸ˆå¯é‡ä¸å¯æ±‚ï¼Œæ‰€ä»¥é€€è€Œæ±‚å…¶æ¬¡ä½ éœ€è¦å¥½ä¹¦ï¼Œå¹¶å°½æ—©å»ºç«‹è‡ªä¿®çš„åŸºç¡€ã€‚è¿·æ—¶å¸ˆæ¸¡ï¼Œæ‚Ÿäº†è‡ªæ¸¡ï¼Œå¯»å¥½ä¹¦çœ‹å¥½ä¹¦ï¼Œå°±æ˜¯ä½ çš„è‡ªæ¸¡æ³•é—¨ã€‚åˆ‡è®°ï¼Œå¾’å­¦ä¸è¶³ä»¥è‡ªè¡Œï¼Œè®¡ç®—æœºæ˜¯å®ä½œæ€§å¾ˆå¼ºçš„ä¸€é—¨ç§‘æŠ€ï¼Œä½ ä¸€å®šè¦åŠ¨æ‰‹åšï¼Œæœ€å¿Œè®³çœ¼é«˜æ‰‹ä½ã€‚å­¦è€Œä¸æ€åˆ™ç½”ï¼Œæ€è€Œä¸å­¦åˆ™æ®†ï¼Œä¸€å®šè¦æ€è€ƒã€æ²‰æ·€ã€æ•´ç†ã€‚æ•´ç†çš„åŠŸå¤«æˆ‘è¦ç‰¹åˆ«å¼ºè°ƒã€‚è®¸å¤šäººä¸€å‘³å‹‡å¾€ç›´å‰ï¼Œè¿½æ±‚æœ€æ–°æŠ€æœ¯å‘å±•ï¼Œå´å¿½ç•¥äº†æ•´ç†æ²‰æ·€çš„åŠŸå¤«ã€‚å¦‚æœçŸ¥è¯†ä¸èƒ½æ·±åˆ»å†…åŒ–ä¸ºä½ çš„æ€æƒ³ï¼Œé‚£ä¹ˆè¿™ä»½çŸ¥è¯†å¾ˆå¿«ä¼šç¦»ä½ è€Œå»ã€‚ 2 . ç§‘ç­ä¸éç§‘ç­, åæ ¡ä¸éåæ ¡ å„ä½èº«ä¸ºåæ ¡å­¦ç”Ÿï¼Œèº«ä¸ºç§‘ç­ç”Ÿï¼Œä»æ¥ä¸å¿…åœ¨ä¹è¿™ä¸ªé—®é¢˜ï¼Œé‚£æ˜¯é¥±äººä¸çŸ¥é¥¿äººé¥¥ã€‚è¿™ä¸ªé¢˜ç›®ä¸Šæˆ‘æ˜¯5 0 æ¯”5 0 ï¼Œæˆ‘å‡ºèº«åæ ¡ï¼Œä½†éç§‘ç­ã€‚è™½ç„¶æˆ‘ä»æ¥æ²¡æœ‰è¢«è¿™ä¸ªé—®é¢˜æ‰€æƒ‘ï¼Œä½†çš„ç¡®æœ‰è®¸å¤šå¹´è½»å­¦å­ä¸ºæ­¤è¾—è½¬åä¾§ï¼Œè‹¦æ¼ä¸å·²ã€‚å­¦å†å’ŒèƒŒæ™¯åªæ˜¯ä¸€ä¸ªè¯æ˜ï¼Œè¯æ˜ä½ æ›¾ç»ç»å†è¿‡æŸç§è€ƒéªŒï¼Œè¯æ˜ä½ æ›¾ç»ç»å†è¿‡æŸç§è®­ç»ƒã€‚ä½†å¹¶ä¸ä¿è¯è€ƒéªŒåæˆ–è®­ç»ƒåçš„è´¨é‡ã€‚ä½ æ‰€å¤„çš„ç¯å¢ƒå¦‚æœæé‡è§†å‡ºèº«ï¼Œè¿™æ˜¯ä½ æ— èƒ½ä¸ºåŠ›çš„â€” â€” æ¯›ä¸»å¸­è¦åºŸé™¤å°å»ºï¼Œåƒç™¾å¹´æ¥çš„äººå¿ƒå´éš¾ä»¥åºŸé™¤ã€‚ä½†æ˜¯ä¸è¦æ°”é¦ï¼Œä½ æ€»æœ‰æœºä¼šè¯æ˜ä½ çš„èƒ½åŠ›ã€‚ä¸Šå¤©ä¸ä¼šä¸ç»™ä»»ä½•äººè‡³å°‘ä¸€ä¸ªæœºä¼šï¼Œå…³é”®åœ¨äºæœºä¼šæ¥æ—¶ä½ å‡†å¤‡å¥½äº†æ²¡æœ‰ã€‚ 3 . å‡å­¦ï¼ˆ è€ƒç ”ï¼‰ä¸å°±ä¸š å…ˆå‡å­¦å¥½è¿˜æ˜¯å…ˆå°±ä¸šå¥½ï¼Ÿæœªæ›¾æ·±åˆ»å¯¹å‘é—®è€…çš„ä¸ªäººèƒŒæ™¯åšä¸€ç•ªäº†è§£ä¸åˆ†æï¼Œå°±é½ç„¶ç»™ç­”æ¡ˆï¼Œæ˜¯ä¸è´Ÿè´£ä»»çš„éª—å­ã€‚æˆ‘åªèƒ½è¯´ï¼Œä»¥æˆ‘çš„ç»éªŒå’Œæˆ‘çš„è§‚å¯Ÿï¼Œå¦‚æœä½ èƒ½å¤Ÿå…ˆå°±ä¸šå†ç»§ç»­æ·±é€ ï¼Œå°±ä¸šæ‰€å¾—çš„å„ç§ç»éªŒä¼šå¯¹ä½ çš„æ²»å­¦æ–¹å¼å¸¦æ¥å¾ˆå¤§çš„å¸®åŠ©ã€‚å°±è¿ä½ çš„äººç”Ÿå†ç»ƒï¼Œéƒ½ä¼šå¯¹ä½ å’Œä½ çš„æŒ‡å¯¼æ•™æˆçš„ç›¸å¤„å¸¦æ¥å¸®åŠ©â”€ è¿™å¯æ˜¯ä»¶å¤§äº‹ï¼Œ å½±å“ä½ 3 ~ 6 å¹´çš„ç”Ÿæ´»ã€‚ï¼ˆ æ³¨ï¼šå°æ¹¾ç¡•å£«ç”Ÿä¸¤å¹´ï¼Œåšå£«ç”Ÿå››å¹´ï¼Œå¤§é™†ç¡•å£«ç”Ÿä¸‰å¹´ï¼Œåšå£«ç”Ÿä¸‰å¹´ï¼‰ã€‚ 4 . åŸ¹å…»è‡ªä¿¡å¿ƒ å˜´å·´æ— æ³•åŸ¹å…»è‡ªä¿¡å¿ƒï¼Œæ‰‹æ‰èƒ½å¤Ÿã€‚åªè¦åˆ‡åˆ‡å®å®åœ°åŠ¨æ‰‹åšç‚¹ä¸œè¥¿ï¼Œä½ çš„è‡ªä¿¡å¿ƒå°±ä¼šé€æ¸å»ºç«‹èµ·æ¥ã€‚éšç€è‡ªä¿¡å¿ƒçš„å»ºç«‹ï¼Œä½ å°±å†ä¹Ÿä¸ä¼šé—®â€œC + + è¿˜æœ‰å‰é€”å—â€ã€ â€œJ a v a è¿˜æœ‰å‰é€”å—â€ã€â€œV B è¿˜æœ‰å‰é€”å—â€è¿™ç§é—®é¢˜ã€‚ä¸‹é¢æ˜¯æˆ‘ç»™åŒå­¦çš„ä¸ƒä¸ªå‹‰åŠ± 1 . ä¹è¶£ L i n u x æ“ä½œç³»ç»Ÿçš„åˆ›é€ è€… L i n u s æœ€è¿‘å‡ºäº†ä¸€æœ¬è‡ªä¼ ï¼šã€ŠJ u s t f o r F u n ã€‹ï¼Œç®€ä½“ç‰ˆè¯‘åä¸ºã€Šä¹è€…ä¸ºç‹ã€‹ã€‚å¦‚æœæˆ‘æ¥è¯‘ï¼Œæˆ‘å°±è¯‘ä¸ºã€Šä¸€åˆ‡åªä¸ºä¹è¶£ã€‹ã€‚æ˜¯çš„ï¼Œå…´è¶£æ‰èƒ½ä½¿ä½ ä¹åœ¨å…¶ä¸­ï¼Œä¹åœ¨å…¶ä¸­ä½ æ‰ä¼šäº§ç”Ÿçƒ­æƒ…ï¼Œçƒ­æƒ…æ‰èƒ½ä½¿ä½ å“è¶Šã€‚è¦å¿ äºè‡ªå·±çš„å…´è¶£ã€‚æœ‰äººé—®ï¼Œæ€æ ·æ‰èƒ½æ‰¾åˆ°è‡ªå·±çš„å…´è¶£ï¼Œå¦‚æœæˆ‘æœ‰ç­”æ¡ˆï¼Œæˆ‘å°±å¯ä»¥å¼€ä¸€ä¸ªâ€œ å¡å†…åŸºå…´è¶£å¼€å‘ä¸­å¿ƒâ€ï¼Œæˆä¸ºå…¨çƒé¦–å¯Œã€‚è¿™ç§é—®é¢˜ä¸ä¼šæœ‰æ˜ç¡®ç­”æ¡ˆçš„ï¼Œä½ çš„å…´è¶£è¦åˆ«äººæ¥å¸®ä½ å¼€å‘ï¼Œå’„å’„æ€ªäº‹ã€‚ä½ å¯ä»¥å¤šæ–¹å°è¯•ï¼Œä½†æ˜¯é¦–å…ˆè¦æœ‰èµ·ç çš„åšæŒã€‚ç»ƒç´å¾ˆè¾›è‹¦ï¼ŒéŸ³é˜¶è®­ç»ƒæ¯ç‡¥æ— æ¯”ï¼Œä½†å¦‚æœç¨åŠ åšæŒï¼Œä¹Ÿè®¸ä½ å¾—åˆ°äº†èµç¾ï¼Œä¹Ÿå°±å‘æ˜äº†å…´è¶£ã€‚å¾ˆå¤šäººè¯´å…´è¶£ä¸èƒ½å½“é¥­åƒï¼Œé”™ï¼Œå…´è¶£å¯ä»¥å½“é¥­åƒã€‚å‡ºé—®é¢˜çš„ä¸åœ¨â€œ å…´è¶£ä½•æ–¹â€ï¼Œ è€Œåœ¨ â€œ èƒ½å¦åšæŒâ€ã€‚ 2 . åšæŒ æˆ‘åœ¨ä»Šå¹´å››æœˆä»½ç»™æ–°ç«¹äº¤é€šå¤§å­¦èµ„è®¯ç³»ä¸€ä¸ªæ¼”è®²ï¼Œé¢˜ç›®æ˜¯ï¼šå”¯åšæŒå¾—æˆåŠŸã€‚æˆ‘è‡ªå·±æ‰èƒ½å¹³åº¸ï¼Œä½†æˆ‘å¾ˆèƒ½åšæŒã€‚æˆ‘çš„è¿™ç§ä¸ªæ€§åœ¨æœ‹å‹ä¹‹é—´æ˜¯è¢«ç§°é“çš„ã€‚åšæŒå¹¶ä¸ä»£è¡¨ä¸€å®šæˆåŠŸï¼Œä¸è¿‡åšæŒæœ¬èº«å°±æ˜¯ä¸€ç§ç¾å¥½çš„æƒ…æ“ã€‚æ‰€è°“è°‹äº‹åœ¨äººï¼Œæˆäº‹åœ¨å¤©ï¼Œåªè¦åšæŒï¼Œæˆ‘ä»¬æ€»å¯ä»¥å¿ƒå®‰ç†å¾—åœ°è¯´ï¼šé‚£ç¾å¥½çš„æˆ˜æˆ‘æ‰“è¿‡äº†ã€‚äººç”Ÿæœ€åè¦çš„ä¸å°±æ˜¯å¿ƒå®‰ç†å¾—å—ï¼Ÿ 3 . æ ¼è°ƒ åšäº‹ä¸ä½†è¦åšæŒï¼Œè€Œä¸”è¦åšæŒé«˜æ ¼è°ƒã€‚æ ¼è°ƒä½¿äººé«˜è´µã€‚ä¿—ä¸–æˆåŠŸä¸ä¿è¯æ ¼è°ƒï¼Œæ ¼è°ƒä¹Ÿä¸ä¿è¯ä¿—ä¸–æˆåŠŸï¼Œä½†æ˜¯æ ¼è°ƒä½¿äººæ‹¥æœ‰å°Šä¸¥ï¼Œä½¿äººè·å¾—å°Šæ•¬ã€‚æˆ‘åœ¨å°æ¹¾ï¼Œè§‚å¯Ÿè®¡ç®—æœºä¹¦ç±çš„å†™ä½œä¸å‡ºç‰ˆï¼Œå¯¹äºæ ¼è°ƒç‰¹åˆ«æœ‰æ‰€æ„Ÿè§¦ã€‚æœ‰äº›ä½œè€…ä¸å‡ºç‰ˆç¤¾ï¼Œå¹¶ä¸åœ¨ä¹æ ¼è°ƒï¼Œä¹Ÿä¸åœ¨ä¹è´¡çŒ®ï¼Œåªåœ¨ä¹ç”Ÿæ„ï¼Œåªåœ¨ä¹åˆ©æ¶¦ã€‚ç”Ÿæ„è¦åšï¼Œåˆ©æ¶¦è¦èµšï¼Œä¼ é“è¿˜éœ€é“ç²®å˜›ï¼Œä½†æ˜¯é‡‘é’±ç»ä¸èƒ½æ‘†åœ¨ç¬¬ä¸€ä½ï¼Œå¦åˆ™ç”Ÿæ„å’Œåˆ©æ¶¦éƒ½ä¸ä¼šé•¿è¿œã€‚å› é‡‘é’±è€Œç»“åˆçš„ï¼Œç»ˆå°†å› é‡‘é’±è€Œåˆ†æ‰‹è€Œç»“æŸã€‚å…³äºè¿™ä¸ªï¼Œå°æ¹¾æœ‰è®¸å¤šæ´»ç”Ÿç”Ÿçš„ä¾‹å­ï¼Œå¯ä¸ºå¤§é™†å‡ºç‰ˆç¤¾å€Ÿé‰´ã€‚ 4 . è°¦è™šä¸æ•™å…» å†æ€ä¹ˆå¼€æ˜çš„å¸ˆé•¿å‰è¾ˆï¼Œä¹Ÿè®¸å¯ä»¥æ¥çº³å¹´è½»äººçš„é£æ‰¬è·‹æ‰ˆï¼Œä¹Ÿè®¸å¯ä»¥æ¥å—å¹´è½»äººçš„æ— ç†å–é—¹ï¼Œä½†å½“ä»–çœŸæ­£éœ€è¦å¸®æ‰‹æˆ–çœŸæ­£è¦åŸ¹å…»äººæ‰æ—¶ï¼Œä»–ä¸€å®šç‰¹åˆ«è€ƒè™‘è°¦è™šæœ‰æ•™å…»çš„å¹´è½»äººã€‚æ²¡æœ‰ä»€ä¹ˆæ˜¯ä¸èƒ½æŒ‘æˆ˜çš„ï¼Œä½†æ˜¯åšä¸ºæŒ‘æˆ˜è€…ï¼Œä½ è¦è¨€ä¹‹æœ‰ç‰©ã€è¨€ä¹‹æœ‰ç†ã€‚æ¯›ä¸»å¸­è¯´ï¼Œ â€œ æ²¡æœ‰è°ƒæŸ¥å°±æ²¡æœ‰å‘è¨€æƒâ€ï¼Œè¿™è¯è¯´çš„çœŸå¥½ã€‚æ¯›ä¸»å¸­åˆè¯´â€œé€ åæœ‰ç†â€ï¼Œè¨€ä¸‹ä¹‹æ„æ˜¯æ‰€æœ‰çš„é€ åéƒ½æœ‰ç†ï¼Œè¿™è¯å°±å¾ˆæ²¡æœ‰é“ç†ã€‚ 5 . æ°”åŠ¿ æ°”åŠ¿å’Œå…ˆå‰è¯´åˆ°çš„è°¦è™šï¼Œä¸¤é—´ä¹‹é—´ä¸å¥½æ‹¿æï¼Œæ‹¿æå°ºå¯¸å±äºè‰ºæœ¯èŒƒç•´ã€‚åœ†ç†Ÿçš„äººç”Ÿå†ç»ƒï¼Œæ‰èƒ½æŠŠä¸¤è€…è°ƒç†å¾—æ°åˆ°å¥½å¤„ã€‚æˆ‘çš„æƒ³æ³•æ˜¯ï¼šåšäººè¦è°¦è™šï¼Œåšäº‹è¦æœ‰æ°”åŠ¿ã€‚è¿™æ¬¡æ¥å†…åœ°æ¼”è®²ï¼Œæ¥è§¦è¯»è€…ï¼Œç½‘ä¸Šå¾ˆå¤šçš„è¯„è¯­æ˜¯ï¼šä»–å¾ˆè°¦è™šã€‚ä¸ºä»€ä¹ˆè¿™ä¹ˆè¯´ï¼Ÿéš¾é“ä¾¯æ·æ›¾ç»ç»™äººä¸è°¦è™šçš„å°è±¡å—ï¼Ÿæ˜¯å› ä¸ºæˆ‘æ–‡ç« ä¸­çš„æ°”åŠ¿å—ï¼Ÿè°¦è™šå’Œæ°”åŠ¿ï¼Œå¹¶ä¸æ˜¯ä¸¤æ¡å¹³è¡Œçº¿ã€‚ 6 . å‹¤å¥‹ çˆ±è¿ªç”Ÿè¯´ï¼Œâ€œ æˆåŠŸæ˜¯ç™¾åˆ†ä¹‹ä¸€çš„å¤©æ‰åŠ ä¸Šç™¾åˆ†ä¹‹ä¹åä¹çš„åŠªåŠ›â€ã€‚é“ç†éå¸¸æ¸…æ¥šï¼Œæˆ‘æ²¡æœ‰ä»€ä¹ˆå¼•ç”³ã€‚ä½ é—®ä»»ä½•ä¸€ä½ä½ è®¤ä¸ºæˆåŠŸçš„äººä»–æ˜¯å¦å‹¤å¥‹ï¼Œçœ‹çœ‹ä»–æ€ä¹ˆè¯´ã€‚æˆ‘æœ‰ä¸€ä½å¤§å­¦åŒå­¦ï¼Œè·³èˆæ‰“ç‰Œçˆ±åƒçˆ±ç©ï¼Œä½†æ˜¯æ¯æ¬¡å¾®ç§¯åˆ†è€ƒè¯•éƒ½æ¯”æˆ‘å¥½ã€‚æˆ‘æ¯”ä»–å‹¤å¥‹ï¼Œä»–æ¯”æˆ‘èªæ˜ã€‚å¤©èµ‹ä½¿ç„¶ï¼Œåˆ«åœ¨ä¸Šé¢é’»ç‰›è§’å°–ï¼ˆæˆ‘æ›¾ç»é’»å¾—å¾ˆç—›è‹¦ï¼‰ã€‚è¦çŸ¥é“ï¼Œäººç”Ÿçš„æˆç»©å•å’Œå­¦æ ¡çš„æˆç»©å•æ²¡æœ‰å¿…ç„¶å…³è”ã€‚äººç”Ÿå¾ˆé•¿ï¼Œè¦çœ‹é•¿è¿œï¼Œè¦è®¡ä¹…é•¿ã€‚ 7 . è¶…è¶Šè‡ªå·±çš„â€œ å±€é™â€ æ¸…åä¸€ä½åŒå­¦é—®æˆ‘ï¼Œæœ€ä½©æœå“ªäº›ç¨‹åºå‘˜ï¼Œæˆ‘ä¸€æ—¶ç­”ä¸ä¸Šæ¥ã€‚ç»è¿‡åŒå­¦çš„å¼•å¯¼ï¼Œæˆ‘è¯´äº†å‡ ä¸ªåå­—ã€‚åŒå­¦åˆé—®æˆ‘ï¼Œæˆ‘ä½©æœçš„éƒ½æ˜¯äº›å¤–å›½äººå—ï¼Ÿæˆ‘ç•¥ç•¥æƒ³äº†ä¸€ä¸‹è¯´æ˜¯ã€‚åŒå­¦ï¼ˆä¼¼ä¹ï¼‰å¤±æœ›åœ°åäº†ä¸‹æ¥ã€‚ äº‹å®ä¸Šï¼Œåœ¨é‚£ä¸ªçªç„¶çš„é—®é¢˜ä¸­ï¼Œæˆ‘çš„æ€è€ƒè¿·äº†è·¯ã€‚æˆ‘çš„å›ç­”å¹¶ä¸çœŸæ­£ä»£è¡¨æˆ‘çš„å¿ƒæ„ã€‚æˆ‘ä»æ¥æ²¡æœ‰æƒ³è¿‡è°æ˜¯æˆ‘æœ€ä½©æœçš„ç¨‹åºå‘˜ã€‚åœ¨æˆ‘çš„ç”Ÿæ´»ä¸­é‚£æ˜¯ä¸€ä¸ªä¸å­˜åœ¨çš„è¯é¢˜ã€‚æŠ€æœ¯ä¸æ˜¯çœŸç†ï¼Œæˆ‘æ²¡æœ‰å´‡æ‹œè¿‡å“ªä¸€ä½ç¨‹åºå‘˜æˆ–æŠ€æœ¯å¤§å¸ˆã€‚æˆ‘çŸ¥é“å¤§é™†æœ‰ç€åœ°ä½æä¸ºå´‡é«˜ï¼ˆè¿‘ä¹æ°‘æ—è‹±é›„ï¼‰çš„ç¨‹åºå‘˜ï¼Œä»–ä»¬çš„äº‹è¿¹å¯¹æ¥è‡ªå°æ¹¾åœ°åŒºçš„æˆ‘è€Œè¨€ï¼Œæ€»æ˜¯æœ‰ç€ä¸€å±‚é™Œç”Ÿã€‚å½“ç„¶ï¼Œä¼ å¥‡ä»¤äººç¥å¾€ï¼Œæˆ‘ä¹Ÿçˆ±å¬ä»–ä»¬çš„äº‹è¿¹ã€‚è‡³äºå°æ¹¾ï¼Œä»æ¥æ²¡æœ‰çŸ¥åçš„ç¨‹åºå‘˜ï¼Œå°æ¹¾ä¸æ›¾èµ°è¿‡è¿™æ ·ä¸€ä¸ªä¸ªäººè‹±é›„æ—¶ä»£ã€‚ç°åœ¨ï¼Œæˆ‘è¦ä¿®æ­£æˆ‘åœ¨æ¸…åçš„å›ç­”ã€‚æˆ‘çœŸæ­£ä½©æœçš„ï¼Œæ˜¯é‚£äº›è¶…è¶Šè‡ªå·±å±€é™çš„äºº- - ä»»ä½•äººï¼Œä¸åªæ˜¯ç¨‹åºå‘˜ã€‚â€œ å±€é™â€ æ˜¯ä½ çš„å®¶åº­ã€ä½ çš„ç¯å¢ƒåŠ åœ¨ä½ èº«ä¸Šçš„å…ˆå¤©æ¡æ¢ï¼Œè°èƒ½æ‘†è„±å…ˆå¤©æ¡æ¢ï¼Œè°ä¾¿æ˜¯äººç”Ÿå‹‡è€…ï¼Œå€¼å¾—æœ€å¤§çš„å°Šæ•¬ä¸ä½©æœã€‚å¦‚æœæˆ‘çš„è¯»è€…ä¹‹ä¸­æœ‰äººä½©æœæˆ‘ï¼Œæˆ‘å¸Œæœ›é‚£æ˜¯å› ä¸ºæˆ‘å¯¹æŠ€æœ¯å†™ä½œçš„æ‰§ç€ä»¥åŠå¯¹å¹´è½»å­¦å­çš„å…³æ€€ï¼Œä¸æ˜¯å› ä¸ºæˆ‘çš„æŠ€æœ¯ã€‚å†ä¸”ï¼Œæˆ‘çš„æŠ€æœ¯ä¹Ÿåªæ™®é€šè€Œå·²ã€‚ ä»»é‡è€Œé“è¿œ æˆ‘ä¸ºä»€ä¹ˆæœ‰æœºä¼šåœ¨åä¸­ç§‘æŠ€å¤§å­¦å’ŒåŒå­¦ä»¬æœ‰è¿™ä¹ˆçƒ­çƒˆçš„ä¸€æ¬¡æ¥è§¦ï¼ŸåŸå› æ˜¯æˆ‘çš„ä¹¦åœ¨åä¸­ç§‘æŠ€å¤§å­¦å‡ºç‰ˆç¤¾å‡ºç‰ˆï¼Œè€Œä»–ä»¬è¿½æ±‚è´¨é‡çš„æ€åº¦ï¼Œå¯¹ä½œè€…çš„å°Šé‡ï¼Œä»¤æˆ‘æ„ŸåŠ¨ã€‚å½“æˆ‘æ‹¿åˆ°ã€ŠEssential C++ã€‹ç®€ä½“ç‰ˆï¼Œæˆ‘å¤§åƒä¸€æƒŠï¼Œåˆ¶ä½œè´¨é‡å®Œå…¨ä¸é€Šäºç¹ä½“ç‰ˆã€‚æˆ‘å‘Šè¯‰æˆ‘çš„ç¼–è¾‘ï¼Œä¾¯æ·æ‰€æœ‰åç»­ä¹¦ç±ç§‰æ­¤åŠç†ã€‚è¿™å‡ å¤©ï¼Œä»”ç»†äº†è§£ã€Šæ·±å…¥æµ…å‡ºMFCã€‹ä¸€æ³¢ä¸‰æŠ˜çš„å‡ºç‰ˆè¿‡ç¨‹åï¼ŒçœŸæ­£ä½“ä¼šåˆ°ï¼Œæ²¡æœ‰ä¼˜ç§€çš„åæ´ï¼Œå¥½ä¹¦ç»ˆç©¶åˆ°ä¸äº†è¯»è€…æ‰‹ä¸Šï¼Œé‚£ä¹ˆï¼Œä½œè€…å†å¤šçš„è´¨é‡ã€åšæŒã€æ ¼è°ƒï¼Œç»ˆæ˜¯ä¸€åœºç©ºã€‚ èº«ä¸ºä¸€ä¸ªè‡ªç”±ä½œå®¶ï¼Œæ²¡æœ‰ä»»ä½•ç†ç”±æˆ‘éœ€è¦åœ¨ä¹è®¡ç®—å™¨æŠ€æœ¯ä¹¦ç±çš„æ•´ä½“å‘å±•ã€‚æˆ‘æŠŠè‡ªå·±çš„ä¹¦å†™å¥½ï¼Œå·²ç»å¾ˆå¯¹å¾—èµ·æˆ‘çš„ç¤¾ä¼šè´£ä»»ã€‚ç„¶è€Œæˆ‘è¯šæ³å‘Šè¯‰å„ä½ï¼Œè®¡ç®—å™¨æŠ€æœ¯ä¹¦ç±çš„æ•´ä½“å‘å±•å’Œä¾¯æ·ä¸ªäººçš„å‘å±•ï¼Œä¸¤è€…åœ¨æˆ‘å¿ƒä¸­æœ‰ç›¸åŒçš„æ¯”é‡ã€‚å‰è€…è¯´å°äº†ï¼Œå½±å“å¤§å®¶çš„æ±‚çŸ¥ï¼Œè¯´å¤§äº†ï¼Œå½±å“å›½å®¶çš„ITäº§ä¸šã€‚è¯»è€…å¯¹äºè¿™æ–¹é¢çš„æ®·åˆ‡æœŸå¾…ï¼Œåœ¨ä¾¯æ·ç½‘ç«™ä¸Šçš„è¯»è€…æ¥å‡½ä¸­ä¸€å†å‡ºç°ã€‚æ˜¨å¤©æˆ‘ä»å‘¨è€å¸ˆæ‰‹ä¸Šåˆè·å¾—å‡ å°è¯»è€…æ¥ä¿¡ï¼Œå…¶ä¸­ä¸€å°è¨€è¯è¯šæ³ï¼Œä¸å‘ä¸äº¢ï¼Œç‰¹åˆ«ä»¤æˆ‘æ„ŸåŠ¨ï¼Œæˆ‘æŠŠå®ƒå¿µå‡ºæ¥ä¸å¤§å®¶åˆ†äº«ã€‚ä¿¡ä¸­å¯¹æˆ‘ä¸ªäººçš„è°¬èµï¼Œä¸æ•¢å½“ã€‚\n","date":"2024-08-24T16:04:14+08:00","permalink":"https://nickk111.github.io/p/myfirstblog/","title":"MyFirstBlog"},{"content":"æ­£æ–‡æµ‹è¯• è€Œè¿™äº›å¹¶ä¸æ˜¯å®Œå…¨é‡è¦ï¼Œæ›´åŠ é‡è¦çš„é—®é¢˜æ˜¯ï¼Œ å¸¦ç€è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æ¥å®¡è§†ä¸€ä¸‹å­¦ç”Ÿä¼šé€€ä¼šã€‚ æ—¢ç„¶å¦‚ä½•ï¼Œ å¯¹æˆ‘ä¸ªäººè€Œè¨€ï¼Œå­¦ç”Ÿä¼šé€€ä¼šä¸ä»…ä»…æ˜¯ä¸€ä¸ªé‡å¤§çš„äº‹ä»¶ï¼Œè¿˜å¯èƒ½ä¼šæ”¹å˜æˆ‘çš„äººç”Ÿã€‚ æˆ‘ä»¬ä¸å¾—ä¸é¢å¯¹ä¸€ä¸ªéå¸¸å°´å°¬çš„äº‹å®ï¼Œé‚£å°±æ˜¯ï¼Œ å¯æ˜¯ï¼Œå³ä½¿æ˜¯è¿™æ ·ï¼Œå­¦ç”Ÿä¼šé€€ä¼šçš„å‡ºç°ä»ç„¶ä»£è¡¨äº†ä¸€å®šçš„æ„ä¹‰ã€‚ å­¦ç”Ÿä¼šé€€ä¼šï¼Œå‘ç”Ÿäº†ä¼šå¦‚ä½•ï¼Œä¸å‘ç”Ÿåˆä¼šå¦‚ä½•ã€‚ ç»è¿‡ä¸Šè¿°è®¨è®ºï¼Œ ç”Ÿæ´»ä¸­ï¼Œè‹¥å­¦ç”Ÿä¼šé€€ä¼šå‡ºç°äº†ï¼Œæˆ‘ä»¬å°±ä¸å¾—ä¸è€ƒè™‘å®ƒå‡ºç°äº†çš„äº‹å®ã€‚ å­¦ç”Ÿä¼šé€€ä¼šï¼Œåˆ°åº•åº”è¯¥å¦‚ä½•å®ç°ã€‚ è¿™æ ·çœ‹æ¥ï¼Œ åœ¨è¿™ç§å›°éš¾çš„æŠ‰æ‹©ä¸‹ï¼Œæœ¬äººæ€æ¥æƒ³å»ï¼Œå¯é£Ÿéš¾å®‰ã€‚ å¯¹æˆ‘ä¸ªäººè€Œè¨€ï¼Œå­¦ç”Ÿä¼šé€€ä¼šä¸ä»…ä»…æ˜¯ä¸€ä¸ªé‡å¤§çš„äº‹ä»¶ï¼Œè¿˜å¯èƒ½ä¼šæ”¹å˜æˆ‘çš„äººç”Ÿã€‚ å°±æˆ‘ä¸ªäººæ¥è¯´ï¼Œå­¦ç”Ÿä¼šé€€ä¼šå¯¹æˆ‘çš„æ„ä¹‰ï¼Œä¸èƒ½ä¸è¯´éå¸¸é‡å¤§ã€‚ èå£«æ¯”äºšæ›¾ç»æåˆ°è¿‡ï¼Œäººçš„ä¸€ç”Ÿæ˜¯çŸ­çš„ï¼Œä½†å¦‚æœå‘åŠ£åœ°è¿‡è¿™ä¸€ç”Ÿï¼Œå°±å¤ªé•¿äº†ã€‚è¿™ä¼¼ä¹è§£ç­”äº†æˆ‘çš„ç–‘æƒ‘ã€‚ è«æ‰ç‰¹è¯´è¿‡ä¸€å¥å¯Œæœ‰å“²ç†çš„è¯ï¼Œè°å’Œæˆ‘ä¸€æ ·ç”¨åŠŸï¼Œè°å°±ä¼šå’Œæˆ‘ä¸€æ ·æˆåŠŸã€‚è¿™å¯å‘äº†æˆ‘ï¼Œ å¯¹æˆ‘ä¸ªäººè€Œè¨€ï¼Œå­¦ç”Ÿä¼šé€€ä¼šä¸ä»…ä»…æ˜¯ä¸€ä¸ªé‡å¤§çš„äº‹ä»¶ï¼Œè¿˜å¯èƒ½ä¼šæ”¹å˜æˆ‘çš„äººç”Ÿã€‚ å­¦ç”Ÿä¼šé€€ä¼šï¼Œåˆ°åº•åº”è¯¥å¦‚ä½•å®ç°ã€‚ ä¸€èˆ¬æ¥è¯´ï¼Œ ä»è¿™ä¸ªè§’åº¦æ¥çœ‹ï¼Œ è¿™ç§äº‹å®å¯¹æœ¬äººæ¥è¯´æ„ä¹‰é‡å¤§ï¼Œç›¸ä¿¡å¯¹è¿™ä¸ªä¸–ç•Œä¹Ÿæ˜¯æœ‰ä¸€å®šæ„ä¹‰çš„ã€‚ åœ¨è¿™ç§å›°éš¾çš„æŠ‰æ‹©ä¸‹ï¼Œæœ¬äººæ€æ¥æƒ³å»ï¼Œå¯é£Ÿéš¾å®‰ã€‚ äº†è§£æ¸…æ¥šå­¦ç”Ÿä¼šé€€ä¼šåˆ°åº•æ˜¯ä¸€ç§æ€ä¹ˆæ ·çš„å­˜åœ¨ï¼Œæ˜¯è§£å†³ä¸€åˆ‡é—®é¢˜çš„å…³é”®ã€‚ ä¸€èˆ¬æ¥è¯´ï¼Œ ç”Ÿæ´»ä¸­ï¼Œè‹¥å­¦ç”Ÿä¼šé€€ä¼šå‡ºç°äº†ï¼Œæˆ‘ä»¬å°±ä¸å¾—ä¸è€ƒè™‘å®ƒå‡ºç°äº†çš„äº‹å®ã€‚ é—®é¢˜çš„å…³é”®ç©¶ç«Ÿä¸ºä½•ï¼Ÿ è€Œè¿™äº›å¹¶ä¸æ˜¯å®Œå…¨é‡è¦ï¼Œæ›´åŠ é‡è¦çš„é—®é¢˜æ˜¯ã€‚\nå¥¥æ–¯ç‰¹æ´›å¤«æ–¯åŸºæ›¾ç»è¯´è¿‡ï¼Œå…±åŒçš„äº‹ä¸šï¼Œå…±åŒçš„æ–—äº‰ï¼Œå¯ä»¥ä½¿äººä»¬äº§ç”Ÿå¿å—ä¸€åˆ‡çš„åŠ›é‡ã€‚ã€€å¸¦ç€è¿™å¥è¯ï¼Œæˆ‘ä»¬è¿˜è¦æ›´åŠ æ…é‡çš„å®¡è§†è¿™ä¸ªé—®é¢˜ï¼š ä¸€èˆ¬æ¥è®²ï¼Œæˆ‘ä»¬éƒ½å¿…é¡»åŠ¡å¿…æ…é‡çš„è€ƒè™‘è€ƒè™‘ã€‚ æ—¢ç„¶å¦‚æ­¤ï¼Œ è¿™ç§äº‹å®å¯¹æœ¬äººæ¥è¯´æ„ä¹‰é‡å¤§ï¼Œç›¸ä¿¡å¯¹è¿™ä¸ªä¸–ç•Œä¹Ÿæ˜¯æœ‰ä¸€å®šæ„ä¹‰çš„ã€‚ å¸¦ç€è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æ¥å®¡è§†ä¸€ä¸‹å­¦ç”Ÿä¼šé€€ä¼šã€‚ æˆ‘è®¤ä¸ºï¼Œ æˆ‘è®¤ä¸ºï¼Œ åœ¨è¿™ç§å›°éš¾çš„æŠ‰æ‹©ä¸‹ï¼Œæœ¬äººæ€æ¥æƒ³å»ï¼Œå¯é£Ÿéš¾å®‰ã€‚ é—®é¢˜çš„å…³é”®ç©¶ç«Ÿä¸ºä½•ï¼Ÿ æ¯ä¸ªäººéƒ½ä¸å¾—ä¸é¢å¯¹è¿™äº›é—®é¢˜ã€‚ åœ¨é¢å¯¹è¿™ç§é—®é¢˜æ—¶ï¼Œ è¦æƒ³æ¸…æ¥šï¼Œå­¦ç”Ÿä¼šé€€ä¼šï¼Œåˆ°åº•æ˜¯ä¸€ç§æ€ä¹ˆæ ·çš„å­˜åœ¨ã€‚ æˆ‘è®¤ä¸ºï¼Œ æ—¢ç„¶å¦‚æ­¤ï¼Œ æ¯ä¸ªäººéƒ½ä¸å¾—ä¸é¢å¯¹è¿™äº›é—®é¢˜ã€‚ åœ¨é¢å¯¹è¿™ç§é—®é¢˜æ—¶ï¼Œ é‚£ä¹ˆï¼Œ æˆ‘è®¤ä¸ºï¼Œ å­¦ç”Ÿä¼šé€€ä¼šå› ä½•è€Œå‘ç”Ÿã€‚\nå¼•ç”¨ æ€å¿µæ˜¯æœ€æš–çš„å¿§ä¼¤åƒä¸€åŒç¿…è†€\nè®©æˆ‘åœä¸äº†é£ä¸è¿œåœ¨è¿‡å¾€æ¸¸è¡\nä¸å‘Šè€Œåˆ«çš„ä½  å°±ç®—ä¸ºäº†æˆ‘ç€æƒ³\nè¿™ä¹ˆæ²‰ç—›çš„å‘µæŠ¤ æˆ‘æ€ä¹ˆèƒ½ç¿±ç¿”\næœ€æš–çš„æ†‚å‚· - ç”°é¦¥ç”„\nå›¾ç‰‡ 1 2 3 ![Photo by Florian Klauer on Unsplash](florian-klauer-nptLmg6jqDo-unsplash.jpg) ![Photo by Luca Bravo on Unsplash](luca-bravo-alS7ewQ41M8-unsplash.jpg) ![Photo by Helena Hertz on Unsplash](helena-hertz-wWZzXlDpMog-unsplash.jpg) ![Photo by Hudai Gayiran on Unsplash](hudai-gayiran-3Od_VKcDEAA-unsplash.jpg) ç›¸å†Œè¯­æ³•æ¥è‡ª Typlog\n","date":"2020-09-09T00:00:00Z","image":"https://nickk111.github.io/p/test-chinese/helena-hertz-wWZzXlDpMog-unsplash_hu4699868770670889127.jpg","permalink":"https://nickk111.github.io/p/test-chinese/","title":"Chinese Test"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;â€”\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\nâ€” Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements â€” abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-03-11T00:00:00Z","image":"https://nickk111.github.io/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash_hu6307248181568134095.jpg","permalink":"https://nickk111.github.io/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"},{"content":"Lorem est tota propiore conpellat pectoribus de pectora summo.\nRedit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\nExierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\nComas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et Vagus elidunt The Van de Graaf Canon\nMane refeci capiebant unda mulcebat Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n","date":"2019-03-09T00:00:00Z","image":"https://nickk111.github.io/p/placeholder-text/matt-le-SJSpo9hQf7s-unsplash_hu10664154974910995856.jpg","permalink":"https://nickk111.github.io/p/placeholder-text/","title":"Placeholder Text"},{"content":"Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\nIn this example we will be using KaTeX\nCreate a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so: 1 2 3 {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }} To enable KaTeX globally set the parameter math to true in a project\u0026rsquo;s configuration To enable KaTeX on a per page basis include the parameter math: true in content files Note: Use the online reference of Supported TeX Functions\nExamples Inline math: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887â€¦$\nBlock math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n","date":"2019-03-08T00:00:00Z","permalink":"https://nickk111.github.io/p/math-typesetting/","title":"Math Typesetting"},{"content":"Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your site\u0026rsquo;s configuration and then you can type emoji shorthand codes directly in content files; e.g.\nğŸ™ˆ :see_no_evil: ğŸ™‰ :hear_no_evil: ğŸ™Š :speak_no_evil:\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\nN.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n1 2 3 .emoji { font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; } ","date":"2019-03-05T00:00:00Z","image":"https://nickk111.github.io/p/emoji-support/the-creative-exchange-d2zvqp3fpro-unsplash_hu5876398126655421130.jpg","permalink":"https://nickk111.github.io/p/emoji-support/","title":"Emoji Support"},{"content":"YOLOv11æ”¹è¿› | Conv/å·ç§¯ç¯‡ | åˆ©ç”¨2024æœ€æ–°YOLOv9çš„GELANæ¨¡å—æ›¿æ¢C3k2ç»“æ„ï¼ˆé™„è½»é‡åŒ–ç‰ˆæœ¬ + é«˜æ•ˆæ¶¨ç‚¹ç‰ˆæœ¬ + ç»“æ„å›¾ ä¸€ã€æœ¬æ–‡ä»‹ç» æœ¬æ–‡ç»™å¤§å®¶å¸¦æ¥çš„æ”¹è¿›æœºåˆ¶æ˜¯åˆ©ç”¨2024/02/21å·å‘å¸ƒçš„ YOLOv9å…¶ä¸­æå‡ºçš„GELANæ¨¡å—æ¥æ”¹è¿›YOLOv11ä¸­çš„C3k2 ï¼ŒGELANèåˆäº†CSPNetå’ŒELANæœºåˆ¶åŒæ—¶å…¶ä¸­åˆ©ç”¨åˆ°äº†RepConvåœ¨è·å–æ›´å¤šæœ‰æ•ˆç‰¹å¾çš„åŒæ—¶åœ¨æ¨ç†æ—¶ä¸“ç”¨å•åˆ†æ”¯ç»“æ„ä»è€Œä¸å½±å“æ¨ç†é€Ÿåº¦ï¼ŒåŒæ—¶æœ¬æ–‡çš„å†…å®¹æä¾›äº†ä¸¤ç§ç‰ˆæœ¬ä¸€ç§æ˜¯å‚æ•°é‡æ›´ä½æ¶¨ç‚¹æ•ˆæœç•¥å¾®å¼±ä¸€äº›çš„ç‰ˆæœ¬ï¼Œå¦ä¸€ç§æ˜¯å‚æ•°é‡ç¨å¤šä¸€äº›ä½†æ˜¯æ•ˆæœè¦ä¸å‚æ•°é‡ä½çš„æ•ˆæœè¦å¥½ä¸€äº›ï¼ˆå‡ä¸ºæˆ‘ä¸ªäººæ•´ç†ï¼‰ï¼Œæä¾›ä¸¤ç§ç‰ˆæœ¬æ˜¯ä¸ºäº†é€‚é…ä¸åŒéœ€æ±‚çš„è¯»è€…ï¼Œå…·ä½“é€‰æ‹©é‚£ç§å¤§å®¶å¯ä»¥æ ¹æ®è‡ªèº«çš„éœ€æ±‚æ¥é€‰æ‹©å³å¯ï¼Œæ–‡ç« ä¸­æˆ‘éƒ½å‡å·²æä¾›ï¼Œ åŒæ—¶æœ¬æ–‡çš„ç»“æ„å­˜åœ¨å¤§é‡çš„äºŒæ¬¡åˆ›æ–°æœºä¼šï¼Œåé¢æˆ‘ä¹Ÿä¼šæä¾›ã€‚\n** ä¸“æ å›é¡¾ï¼š ** ** YOLOv11æ”¹è¿›ç³»åˆ—ä¸“æ â€”â€”æœ¬ä¸“æ æŒç»­å¤ä¹ å„ç§é¡¶ä¼šå†…å®¹â€”â€”ç§‘ç ”å¿…å¤‡******\nç›®å½•\nä¸€ã€æœ¬æ–‡ä»‹ç»\näºŒã€GELANçš„åŸç†\n2.1 Generalized ELAN\n2.2 Generalized ELANç»“æ„å›¾\nä¸‰ã€æ ¸å¿ƒä»£ç \nå››ã€æ‰‹æŠŠæ‰‹æ•™ä½ æ·»åŠ GELANæœºåˆ¶\n4.1 ä¿®æ”¹ä¸€\n4.2 ä¿®æ”¹äºŒ\n4.3 ä¿®æ”¹ä¸‰\n4.4 ä¿®æ”¹å››\näº”ã€GELANçš„yamlæ–‡ä»¶å’Œè¿è¡Œè®°å½•\n5.1 GELANä½å‚æ•°é‡ç‰ˆæœ¬çš„yamlæ–‡ä»¶\n5.2 GELANé«˜å‚æ•°é‡ç‰ˆæœ¬çš„yamlæ–‡ä»¶\n5.3 è®­ç»ƒä»£ç \n5.3 GELANçš„è®­ç»ƒè¿‡ç¨‹æˆªå›¾\n5.3.1 ä½å‚æ•°é‡ç‰ˆæœ¬\n5.3.2 é«˜å‚æ•°é‡ç‰ˆæœ¬\näº”ã€æœ¬æ–‡æ€»ç»“\näºŒã€GELANçš„åŸç† 2.1 Generalized ELAN åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬æè¿°äº†æå‡ºçš„æ–°ç½‘ç»œæ¶æ„ - GELANã€‚é€šè¿‡ç»“åˆä¸¤ç§ç¥ç»ç½‘ç»œæ¶æ„CSPNetå’ŒELANï¼Œè¿™ä¸¤ç§æ¶æ„éƒ½æ˜¯ä»¥æ¢¯åº¦è·¯å¾„è§„åˆ’è®¾è®¡çš„ï¼Œæˆ‘ä»¬è®¾è®¡äº†è€ƒè™‘äº†è½»é‡çº§ã€æ¨ç†é€Ÿåº¦å’Œå‡†ç¡®æ€§çš„å¹¿ä¹‰é«˜æ•ˆå±‚èšåˆç½‘ç»œï¼ˆGELANï¼‰ã€‚å…¶æ•´ä½“æ¶æ„å¦‚å›¾4æ‰€ç¤ºã€‚æˆ‘ä»¬æ¨å¹¿äº†ELANçš„èƒ½åŠ›ï¼ŒELANåŸæœ¬åªä½¿ç”¨å·ç§¯å±‚çš„å †å ï¼Œåˆ°ä¸€ä¸ªæ–°çš„æ¶æ„ï¼Œå¯ä»¥ä½¿ç”¨ä»»ä½•è®¡ç®—å—ã€‚\nè¿™å¼ å›¾ï¼ˆå›¾4ï¼‰å±•ç¤ºäº†å¹¿ä¹‰é«˜æ•ˆå±‚èšåˆç½‘ç»œï¼ˆGELANï¼‰çš„æ¶æ„ï¼Œä»¥åŠå®ƒæ˜¯å¦‚ä½•ä»CSPNetå’ŒELANè¿™ä¸¤ç§ç¥ç»ç½‘ç»œæ¶æ„æ¼”å˜è€Œæ¥çš„ã€‚è¿™ä¸¤ç§æ¶æ„éƒ½è®¾è®¡æœ‰æ¢¯åº¦è·¯å¾„è§„åˆ’ã€‚\na) CSPNetï¼š åœ¨CSPNetçš„æ¶æ„ä¸­ï¼Œè¾“å…¥é€šè¿‡ä¸€ä¸ªè½¬æ¢å±‚è¢«åˆ†å‰²ä¸ºä¸¤éƒ¨åˆ†ï¼Œç„¶ååˆ†åˆ«é€šè¿‡ä»»æ„çš„è®¡ç®—å—ã€‚ä¹‹åï¼Œè¿™äº›åˆ†æ”¯è¢«é‡æ–°åˆå¹¶ï¼ˆé€šè¿‡concatenationï¼‰ï¼Œå¹¶å†æ¬¡é€šè¿‡è½¬æ¢å±‚ã€‚\nb) ELANï¼š ä¸CSPNetç›¸æ¯”ï¼ŒELANé‡‡ç”¨äº†å †å çš„å·ç§¯å±‚ï¼Œå…¶ä¸­æ¯ä¸€å±‚çš„è¾“å‡ºéƒ½ä¼šä¸ä¸‹ä¸€å±‚çš„è¾“å…¥ç›¸ç»“åˆï¼Œå†ç»è¿‡å·ç§¯å¤„ç†ã€‚\nc) GELANï¼š ç»“åˆäº†CSPNetå’ŒELANçš„è®¾è®¡ï¼Œæå‡ºäº†GELANã€‚å®ƒé‡‡ç”¨äº†CSPNetçš„åˆ†å‰²å’Œé‡ç»„çš„æ¦‚å¿µï¼Œå¹¶åœ¨æ¯ä¸€éƒ¨åˆ†å¼•å…¥äº†ELANçš„å±‚çº§å·ç§¯å¤„ç†æ–¹å¼ã€‚ä¸åŒä¹‹å¤„åœ¨äºGELANä¸ä»…ä½¿ç”¨å·ç§¯å±‚ï¼Œè¿˜å¯ä»¥ä½¿ç”¨ä»»ä½•è®¡ç®—å—ï¼Œä½¿å¾—ç½‘ç»œæ›´åŠ çµæ´»ï¼Œèƒ½å¤Ÿæ ¹æ®ä¸åŒçš„åº”ç”¨éœ€æ±‚å®šåˆ¶ã€‚\nGELANçš„è®¾è®¡è€ƒè™‘åˆ°äº†è½»é‡åŒ–ã€æ¨ç†é€Ÿåº¦å’Œç²¾ç¡®åº¦ï¼Œä»¥æ­¤æ¥æé«˜æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚å›¾ä¸­æ˜¾ç¤ºçš„æ¨¡å—å’Œåˆ†åŒºçš„å¯é€‰æ€§è¿›ä¸€æ­¥å¢åŠ äº†ç½‘ç»œçš„é€‚åº”æ€§å’Œå¯å®šåˆ¶æ€§ã€‚GELANçš„è¿™ç§ç»“æ„å…è®¸å®ƒæ”¯æŒå¤šç§ç±»å‹çš„è®¡ç®—å—ï¼Œè¿™ä½¿å¾—å®ƒå¯ä»¥æ›´å¥½åœ°é€‚åº”å„ç§ä¸åŒçš„è®¡ç®—éœ€æ±‚å’Œç¡¬ä»¶çº¦æŸã€‚\næ€»çš„æ¥è¯´ï¼ŒGELANçš„æ¶æ„æ˜¯ä¸ºäº†æä¾›ä¸€ä¸ªæ›´åŠ é€šç”¨å’Œé«˜æ•ˆçš„ç½‘ç»œï¼Œå¯ä»¥é€‚åº”ä»è½»é‡çº§åˆ°å¤æ‚çš„æ·±åº¦å­¦ä¹ ä»»åŠ¡ï¼ŒåŒæ—¶ä¿æŒæˆ–å¢å¼ºè®¡ç®—æ•ˆç‡å’Œæ€§èƒ½ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒGELANæ—¨åœ¨è§£å†³ç°æœ‰æ¶æ„çš„é™åˆ¶ï¼Œæä¾›ä¸€ä¸ªå¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆï¼Œä»¥é€‚åº”æœªæ¥æ·±åº¦å­¦ä¹ çš„å‘å±•ã€‚\nå¤§å®¶çœ‹å›¾ç‰‡ä¸€çœ¼å°±èƒ½çœ‹å‡ºæ¥å®ƒèåˆäº†ä»€ä¹ˆï¼Œå°±æ˜¯å°†CSPHetçš„anyBlockæ¨¡å—å †å çš„æ–¹å¼å’ŒELANèåˆåˆ°äº†ä¸€èµ·ã€‚\n2.2 Generalized ELANç»“æ„å›¾ YOLOv9æœ€ä¸»è¦çš„åˆ›æ–°ç›®å‰èƒ½å¤Ÿå¾—åˆ°çš„å°±æ˜¯å…¶ä¸­çš„ GELANç»“æ„ ï¼Œæˆ‘ä¹Ÿæ˜¯åˆ†æå…¶ä»£ç æ ¹æ®è®ºæ–‡å°†å…¶ç»“æ„å›¾ç»˜ç”»å‡ºæ¥ã€‚\nä¸‹é¢çš„æ–‡ä»¶ä¸ºYOLOv9çš„yamlæ–‡ä»¶ã€‚å¯ä»¥çœ‹åˆ°çš„æ˜¯å…¶æå‡ºäº†ä¸€ç§ç»“æ„åå­—RepNCSPELAN4ï¼Œå…¶ä¸­çš„ç»“æ„å›¾concatåçš„é€šé“æ•°æˆ‘æ²¡æœ‰ç”»æ˜¯å› ä¸ºå®ƒæœ‰è®¡ç®—ä¸­é—´çš„å‚æ•°çš„å˜é‡æ˜¯æ ¹æ®ä¸ªäººè®¾ç½®æ¥çš„ã€‚\nå…¶ä»£ç å’Œç»“æ„å›¾å¦‚ä¸‹æ‰€ç¤ºï¼\nclass RepNCSPELAN4(nn.Module): # csp-elan def __init__(self, c1, c2, c5=1): # c5 = repeat super().__init__() c3 = int(c2 / 2) c4 = int(c3 / 2) self.c = c3 // 2 self.cv1 = Conv(c1, c3, 1, 1) self.cv2 = nn.Sequential(RepNCSP(c3 // 2, c4, c5), Conv(c4, c4, 3, 1)) self.cv3 = nn.Sequential(RepNCSP(c4, c4, c5), Conv(c4, c4, 3, 1)) self.cv4 = Conv(c3 + (2 * c4), c2, 1, 1) def forward(self, x): y = list(self.cv1(x).chunk(2, 1)) y.extend((m(y[-1])) for m in [self.cv2, self.cv3]) return self.cv4(torch.cat(y, 1)) def forward_split(self, x): y = list(self.cv1(x).split((self.c, self.c), 1)) y.extend(m(y[-1]) for m in [self.cv2, self.cv3]) return self.cv4(torch.cat(y, 1))\rä¸‰ã€æ ¸å¿ƒä»£ç  æ ¸å¿ƒä»£ç çš„ä½¿ç”¨æ–¹å¼çœ‹ç« èŠ‚å››ï¼\nimport torchimport torch.nn as nnimport numpy as np __all__ = ['RepNCSPELAN4_low', 'RepNCSPELAN4_high'] class RepConvN(nn.Module): \u0026quot;\u0026quot;\u0026quot;RepConv is a basic rep-style block, including training and deploy status This code is based on https://github.com/DingXiaoH/RepVGG/blob/main/repvgg.py \u0026quot;\u0026quot;\u0026quot; default_act = nn.SiLU() # default activation def __init__(self, c1, c2, k=3, s=1, p=1, g=1, d=1, act=True, bn=False, deploy=False): super().__init__() assert k == 3 and p == 1 self.g = g self.c1 = c1 self.c2 = c2 self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity() self.bn = None self.conv1 = Conv(c1, c2, k, s, p=p, g=g, act=False) self.conv2 = Conv(c1, c2, 1, s, p=(p - k // 2), g=g, act=False) def forward_fuse(self, x): \u0026quot;\u0026quot;\u0026quot;Forward process\u0026quot;\u0026quot;\u0026quot; return self.act(self.conv(x)) def forward(self, x): \u0026quot;\u0026quot;\u0026quot;Forward process\u0026quot;\u0026quot;\u0026quot; id_out = 0 if self.bn is None else self.bn(x) return self.act(self.conv1(x) + self.conv2(x) + id_out) def get_equivalent_kernel_bias(self): kernel3x3, bias3x3 = self._fuse_bn_tensor(self.conv1) kernel1x1, bias1x1 = self._fuse_bn_tensor(self.conv2) kernelid, biasid = self._fuse_bn_tensor(self.bn) return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid def _avg_to_3x3_tensor(self, avgp): channels = self.c1 groups = self.g kernel_size = avgp.kernel_size input_dim = channels // groups k = torch.zeros((channels, input_dim, kernel_size, kernel_size)) k[np.arange(channels), np.tile(np.arange(input_dim), groups), :, :] = 1.0 / kernel_size ** 2 return k def _pad_1x1_to_3x3_tensor(self, kernel1x1): if kernel1x1 is None: return 0 else: return torch.nn.functional.pad(kernel1x1, [1, 1, 1, 1]) def _fuse_bn_tensor(self, branch): if branch is None: return 0, 0 if isinstance(branch, Conv): kernel = branch.conv.weight running_mean = branch.bn.running_mean running_var = branch.bn.running_var gamma = branch.bn.weight beta = branch.bn.bias eps = branch.bn.eps elif isinstance(branch, nn.BatchNorm2d): if not hasattr(self, 'id_tensor'): input_dim = self.c1 // self.g kernel_value = np.zeros((self.c1, input_dim, 3, 3), dtype=np.float32) for i in range(self.c1): kernel_value[i, i % input_dim, 1, 1] = 1 self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device) kernel = self.id_tensor running_mean = branch.running_mean running_var = branch.running_var gamma = branch.weight beta = branch.bias eps = branch.eps std = (running_var + eps).sqrt() t = (gamma / std).reshape(-1, 1, 1, 1) return kernel * t, beta - running_mean * gamma / std def fuse_convs(self): if hasattr(self, 'conv'): return kernel, bias = self.get_equivalent_kernel_bias() self.conv = nn.Conv2d(in_channels=self.conv1.conv.in_channels, out_channels=self.conv1.conv.out_channels, kernel_size=self.conv1.conv.kernel_size, stride=self.conv1.conv.stride, padding=self.conv1.conv.padding, dilation=self.conv1.conv.dilation, groups=self.conv1.conv.groups, bias=True).requires_grad_(False) self.conv.weight.data = kernel self.conv.bias.data = bias for para in self.parameters(): para.detach_() self.__delattr__('conv1') self.__delattr__('conv2') if hasattr(self, 'nm'): self.__delattr__('nm') if hasattr(self, 'bn'): self.__delattr__('bn') if hasattr(self, 'id_tensor'): self.__delattr__('id_tensor') class RepNBottleneck(nn.Module): # Standard bottleneck def __init__(self, c1, c2, shortcut=True, g=1, k=(3, 3), e=0.5): # ch_in, ch_out, shortcut, kernels, groups, expand super().__init__() c_ = int(c2 * e) # hidden channels self.cv1 = RepConvN(c1, c_, k[0], 1) self.cv2 = Conv(c_, c2, k[1], 1, g=g) self.add = shortcut and c1 == c2 def forward(self, x): return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x)) class RepNCSP(nn.Module): # CSP Bottleneck with 3 convolutions def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5): # ch_in, ch_out, number, shortcut, groups, expansion super().__init__() c_ = int(c2 * e) # hidden channels self.cv1 = Conv(c1, c_, 1, 1) self.cv2 = Conv(c1, c_, 1, 1) self.cv3 = Conv(2 * c_, c2, 1) # optional act=FReLU(c2) self.m = nn.Sequential(*(RepNBottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n))) def forward(self, x): return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1)) def autopad(k, p=None, d=1): # kernel, padding, dilation # Pad to 'same' shape outputs if d \u0026gt; 1: k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k] # actual kernel-size if p is None: p = k // 2 if isinstance(k, int) else [x // 2 for x in k] # auto-pad return p class Conv(nn.Module): # Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation) default_act = nn.SiLU() # default activation def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True): super().__init__() self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False) self.bn = nn.BatchNorm2d(c2) self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity() def forward(self, x): return self.act(self.bn(self.conv(x))) def forward_fuse(self, x): return self.act(self.conv(x)) class RepNCSPELAN4_low(nn.Module): # csp-elan def __init__(self, c1, c2, c5=1): # c5 = repeat super().__init__() c3 = int(c2 / 2) c4 = int(c3 / 2) self.c = c3 // 2 self.cv1 = Conv(c1, c3, 1, 1) self.cv3 = nn.Sequential(RepNCSP(c3, c3, c5)) self.cv4 = Conv(c3 + (2 * c4), c2, 1, 1) def forward(self, x): temp = self.cv1(x) temp3 = self.cv3(temp) y = list(temp.chunk(2, 1)) y.append(temp3) temp2 = torch.cat(y, 1) return self.cv4(temp2) def forward_split(self, x): y = list(self.cv1(x).split((self.c, self.c), 1)) y.extend(m(y[-1]) for m in [self.cv2, self.cv3]) return self.cv4(torch.cat(y, 1)) class RepNCSPELAN4_high(nn.Module): # csp-elan def __init__(self, c1, c2, c5=1): # c5 = repeat super().__init__() c3 = c2 c4 = int(c3 / 2) self.c = c3 // 2 self.cv1 = Conv(c1, c3, 1, 1) self.cv2 = nn.Sequential(RepNCSP(c3 // 2, c4, c5), Conv(c4, c4, 3, 1)) self.cv3 = nn.Sequential(RepNCSP(c4, c4, c5), Conv(c4, c4, 3, 1)) self.cv4 = Conv(c3 + (2 * c4), c2, 1, 1) def forward(self, x): y = list(self.cv1(x).chunk(2, 1)) y.extend((m(y[-1])) for m in [self.cv2, self.cv3]) return self.cv4(torch.cat(y, 1)) def forward_split(self, x): y = list(self.cv1(x).split((self.c, self.c), 1)) y.extend(m(y[-1]) for m in [self.cv2, self.cv3]) return self.cv4(torch.cat(y, 1)) if __name__ == \u0026quot;__main__\u0026quot;: # Generating Sample image image_size = (1, 24, 224, 224) image = torch.rand(*image_size) # Model mobilenet_v1 = RepNCSPELAN4_low(24, 24) out = mobilenet_v1(image) print(out.size())\rå››ã€æ‰‹æŠŠæ‰‹æ•™ä½ æ·»åŠ GELANæœºåˆ¶ 4.1 ä¿®æ”¹ä¸€ ç¬¬ä¸€è¿˜æ˜¯å»ºç«‹æ–‡ä»¶ï¼Œæˆ‘ä»¬æ‰¾åˆ°å¦‚ä¸‹ultralytics/nn/modulesæ–‡ä»¶å¤¹ä¸‹å»ºç«‹ä¸€ä¸ªç›®å½•åå­—å‘¢å°±æ˜¯\u0026rsquo;Addmodules\u0026rsquo;æ–‡ä»¶å¤¹( ç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€æ–°å»º) ï¼ç„¶ååœ¨å…¶å†…éƒ¨å»ºç«‹ä¸€ä¸ªæ–°çš„pyæ–‡ä»¶å°†æ ¸å¿ƒä»£ç å¤åˆ¶ç²˜è´´è¿›å»å³å¯ã€‚\n4.2 ä¿®æ”¹äºŒ ç¬¬äºŒæ­¥æˆ‘ä»¬åœ¨è¯¥ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªæ–°çš„pyæ–‡ä»¶åå­—ä¸º\u0026rsquo;init.py\u0026rsquo;( ç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€æ–°å»º) ï¼Œç„¶ååœ¨å…¶å†…éƒ¨å¯¼å…¥æˆ‘ä»¬çš„æ£€æµ‹å¤´å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\n4.3 ä¿®æ”¹ä¸‰ ç¬¬ä¸‰æ­¥æˆ‘é—¨ä¸­åˆ°å¦‚ä¸‹æ–‡ä»¶\u0026rsquo;ultralytics/nn/tasks.py\u0026rsquo;è¿›è¡Œå¯¼å…¥å’Œæ³¨å†Œæˆ‘ä»¬çš„æ¨¡å—( ç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€é‡æ–°å¯¼å…¥ç›´æ¥å¼€å§‹ç¬¬å››æ­¥å³å¯) ï¼\nä»ä»Šå¤©å¼€å§‹ä»¥åçš„æ•™ç¨‹å°±éƒ½ç»Ÿä¸€æˆè¿™ä¸ªæ ·å­äº†ï¼Œå› ä¸ºæˆ‘é»˜è®¤å¤§å®¶ç”¨äº†æˆ‘ç¾¤å†…çš„æ–‡ä»¶æ¥è¿›è¡Œä¿®æ”¹ï¼ï¼\n4.4 ä¿®æ”¹å›› æŒ‰ç…§æˆ‘çš„æ·»åŠ åœ¨parse_modelé‡Œæ·»åŠ å³å¯ã€‚\nåˆ°æ­¤å°±ä¿®æ”¹å®Œæˆäº†ï¼Œå¤§å®¶å¯ä»¥å¤åˆ¶ä¸‹é¢çš„yamlæ–‡ä»¶è¿è¡Œã€‚\näº”ã€GELANçš„yamlæ–‡ä»¶å’Œè¿è¡Œè®°å½• 5.1 GELANä½å‚æ•°é‡ç‰ˆæœ¬çš„yamlæ–‡ä»¶ æ­¤ç‰ˆæœ¬è®­ç»ƒä¿¡æ¯ï¼šYOLO11-RepGELAN-low summary: 403 layers, 2,218,027 parameters, 2,218,011 gradients, 6.3 GFLOPs\n# Ultralytics YOLO ğŸš€, AGPL-3.0 license# YOLO11 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect # Parametersnc: 80 # number of classesscales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n' # [depth, width, max_channels] n: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs s: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs m: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs l: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs x: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs # YOLO11n backbonebackbone: # [from, repeats, module, args] - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2 - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4 - [-1, 2, RepNCSPELAN4_low, [256]] - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8 - [-1, 2, RepNCSPELAN4_low, [512]] - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16 - [-1, 2, RepNCSPELAN4_low, [512]] - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32 - [-1, 2, RepNCSPELAN4_low, [1024]] - [-1, 1, SPPF, [1024, 5]] # 9 - [-1, 2, C2PSA, [1024]] # 10 # YOLO11n headhead: - [-1, 1, nn.Upsample, [None, 2, \u0026quot;nearest\u0026quot;]] - [[-1, 6], 1, Concat, [1]] # cat backbone P4 - [-1, 2, RepNCSPELAN4_low, [512]] # 13 - [-1, 1, nn.Upsample, [None, 2, \u0026quot;nearest\u0026quot;]] - [[-1, 4], 1, Concat, [1]] # cat backbone P3 - [-1, 2, RepNCSPELAN4_low, [256]] # 16 (P3/8-small) - [-1, 1, Conv, [256, 3, 2]] - [[-1, 13], 1, Concat, [1]] # cat head P4 - [-1, 2, RepNCSPELAN4_low, [512]] # 19 (P4/16-medium) - [-1, 1, Conv, [512, 3, 2]] - [[-1, 10], 1, Concat, [1]] # cat head P5 - [-1, 2, RepNCSPELAN4_low, [1024]] # 22 (P5/32-large) - [[16, 19, 22], 1, Detect, [nc]] # Detect(P3, P4, P5)\r5.2 GELANé«˜å‚æ•°é‡ç‰ˆæœ¬çš„yamlæ–‡ä»¶ æ­¤ç‰ˆæœ¬è®­ç»ƒä¿¡æ¯ï¼šYOLO11-RepGELAN-high summary: 651 layers, 3,837,803 parameters, 3,837,787 gradients, 12.1 GFLOPs\n# Ultralytics YOLO ğŸš€, AGPL-3.0 license# YOLO11 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect # Parametersnc: 80 # number of classesscales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n' # [depth, width, max_channels] n: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs s: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs m: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs l: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs x: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs # YOLO11n backbonebackbone: # [from, repeats, module, args] - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2 - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4 - [-1, 2, RepNCSPELAN4_high, [256]] - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8 - [-1, 2, RepNCSPELAN4_high, [512]] - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16 - [-1, 2, RepNCSPELAN4_high, [512]] - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32 - [-1, 2, RepNCSPELAN4_high, [1024]] - [-1, 1, SPPF, [1024, 5]] # 9 - [-1, 2, C2PSA, [1024]] # 10 # YOLO11n headhead: - [-1, 1, nn.Upsample, [None, 2, \u0026quot;nearest\u0026quot;]] - [[-1, 6], 1, Concat, [1]] # cat backbone P4 - [-1, 2, RepNCSPELAN4_high, [512]] # 13 - [-1, 1, nn.Upsample, [None, 2, \u0026quot;nearest\u0026quot;]] - [[-1, 4], 1, Concat, [1]] # cat backbone P3 - [-1, 2, RepNCSPELAN4_high, [256]] # 16 (P3/8-small) - [-1, 1, Conv, [256, 3, 2]] - [[-1, 13], 1, Concat, [1]] # cat head P4 - [-1, 2, RepNCSPELAN4_high, [512]] # 19 (P4/16-medium) - [-1, 1, Conv, [512, 3, 2]] - [[-1, 10], 1, Concat, [1]] # cat head P5 - [-1, 2, RepNCSPELAN4_high, [1024]] # 22 (P5/32-large) - [[16, 19, 22], 1, Detect, [nc]] # Detect(P3, P4, P5)\r5.3 è®­ç»ƒä»£ç  å¤§å®¶å¯ä»¥åˆ›å»ºä¸€ä¸ªpyæ–‡ä»¶å°†æˆ‘ç»™çš„ä»£ç å¤åˆ¶ç²˜è´´è¿›å»ï¼Œé…ç½®å¥½è‡ªå·±çš„æ–‡ä»¶è·¯å¾„å³å¯è¿è¡Œã€‚\nimport warningswarnings.filterwarnings('ignore')from ultralytics import YOLO if __name__ == '__main__': model = YOLO('ultralytics/cfg/models/v8/yolov8-C2f-FasterBlock.yaml') # model.load('yolov8n.pt') # loading pretrain weights model.train(data=r'æ›¿æ¢æ•°æ®é›†yamlæ–‡ä»¶åœ°å€', # å¦‚æœå¤§å®¶ä»»åŠ¡æ˜¯å…¶å®ƒçš„'ultralytics/cfg/default.yaml'æ‰¾åˆ°è¿™é‡Œä¿®æ”¹taskå¯ä»¥æ”¹æˆdetect, segment, classify, pose cache=False, imgsz=640, epochs=150, single_cls=False, # æ˜¯å¦æ˜¯å•ç±»åˆ«æ£€æµ‹ batch=4, close_mosaic=10, workers=0, device='0', optimizer='SGD', # using SGD # resume='', # å¦‚è¿‡æƒ³ç»­è®­å°±è®¾ç½®last.ptçš„åœ°å€ amp=False, # å¦‚æœå‡ºç°è®­ç»ƒæŸå¤±ä¸ºNanå¯ä»¥å…³é—­amp project='runs/train', name='exp', )\r5.3 GELANçš„è®­ç»ƒè¿‡ç¨‹æˆªå›¾ 5.3.1 ä½å‚æ•°é‡ç‰ˆæœ¬ 5.3.2 é«˜å‚æ•°é‡ç‰ˆæœ¬ äº”ã€æœ¬æ–‡æ€»ç»“ åˆ°æ­¤æœ¬æ–‡çš„æ­£å¼åˆ†äº«å†…å®¹å°±ç»“æŸäº†ï¼Œåœ¨è¿™é‡Œç»™å¤§å®¶æ¨èæˆ‘çš„YOLOv11æ”¹è¿›æœ‰æ•ˆæ¶¨ç‚¹ä¸“æ ï¼Œæœ¬ä¸“æ ç›®å‰ä¸ºæ–°å¼€çš„å¹³å‡è´¨é‡åˆ†98åˆ†ï¼ŒåæœŸæˆ‘ä¼šæ ¹æ®å„ç§æœ€æ–°çš„å‰æ²¿é¡¶ä¼šè¿›è¡Œè®ºæ–‡å¤ç°ï¼Œä¹Ÿä¼šå¯¹ä¸€äº›è€çš„æ”¹è¿›æœºåˆ¶è¿›è¡Œè¡¥å……ï¼Œå¦‚æœå¤§å®¶è§‰å¾—æœ¬æ–‡å¸®åŠ©åˆ°ä½ äº†ï¼Œè®¢é˜…æœ¬ä¸“æ ï¼Œå…³æ³¨åç»­æ›´å¤šçš„æ›´æ–°~\n","date":"0001-01-01T00:00:00Z","permalink":"https://nickk111.github.io/p/","title":""},{"content":"YOLOv11 | ä¸€æ–‡å¸¦ä½ æ·±å…¥ç†è§£ultralyticsæœ€æ–°ä½œå“yolov11çš„åˆ›æ–° | è®­ç»ƒã€æ¨ç†ã€éªŒè¯ã€å¯¼å‡º ï¼ˆé™„ç½‘ç»œç»“æ„å›¾ï¼‰ ç›®å½•\nä¸€ã€æœ¬æ–‡ä»‹ç»\näºŒã€YOLOv11å’ŒYOLOv8å¯¹æ¯”\nä¸‰ã€YOLOv11çš„ç½‘ç»œç»“æ„è§£æ\nå››ã€YOLOv11ä¸‹è½½ã€ç¯å¢ƒå®‰è£…ã€æ•°æ®é›†è·å–\näº”ã€æ¨¡å‹è®­ç»ƒ\n5.1 è®­ç»ƒçš„ä¸‰ç§æ–¹å¼\n5.1.1 æ–¹å¼ä¸€\n5.1.2 æ–¹å¼äºŒ\n5.1.3 æ–¹å¼ä¸‰ ï¼ˆæ¨èï¼Œé¿å…keyErroré”™è¯¯.ï¼‰\nå…­ã€æ¨¡å‹éªŒè¯/æµ‹è¯•\nä¸ƒã€æ¨¡å‹æ¨ç†\nå…«ã€æ¨¡å‹è¾“å‡º\nä¸€ã€æœ¬æ–‡ä»‹ç» ultralyticså‘å¸ƒäº†æœ€æ–°çš„ä½œå“YOLOv11ï¼Œè¿™ä¸€æ¬¡YOLOv11çš„å˜åŒ–ç›¸å¯¹äºultralyticså…¬å¸çš„ä¸Šä¸€ä»£ä½œå“YOLOv8å˜åŒ–ä¸æ˜¯å¾ˆå¤§çš„ï¼ˆYOLOv9ã€YOLOv10å‡ä¸æ˜¯ultralyticså…¬å¸ä½œå“ï¼‰ï¼Œå…¶ä¸­æ”¹å˜çš„ä½ç½®æ¶‰åŠåˆ°C2få˜ä¸ºC3K2ï¼Œåœ¨SPPFåé¢åŠ äº†ä¸€å±‚ç±»ä¼¼äºæ³¨æ„åŠ›æœºåˆ¶çš„C2PSAï¼Œè¿˜æœ‰ä¸€ä¸ªå˜åŒ–å¤§å®¶ä»yamlæ–‡ä»¶æ˜¯çœ‹ä¸å‡ºæ¥çš„å°±æ˜¯å®ƒçš„æ£€æµ‹å¤´å†…éƒ¨æ›¿æ¢äº†ä¸¤ä¸ªDWConvï¼Œä»¥åŠæ¨¡å‹çš„æ·±åº¦å’Œå®½åº¦å‚æ•°è¿›è¡Œäº†å¤§å¹…åº¦è°ƒæ•´ï¼Œä½†æ˜¯åœ¨æŸå¤±å‡½æ•°æ–¹é¢å°±æ²¡æœ‰å˜åŒ–è¿˜æ˜¯é‡‡ç”¨çš„CIoUä½œä¸ºè¾¹ç•Œæ¡†å›å½’æŸå¤±ï¼Œä¸‹é¢å¸¦å¤§å®¶æ·±å…¥ç†è§£ä¸€ä¸‹ultralyticsæœ€æ–°ä½œå“YOLOv11çš„åˆ›æ–°ç‚¹ã€‚\nä¸‹å›¾ä¸ºæœ€è¿‘çš„YOLOç³»åˆ—å‘å¸ƒæ—¶é—´çº¿ï¼\näºŒã€YOLOv11å’ŒYOLOv8å¯¹æ¯” åœ¨YOLOYOLOv5ï¼ŒYOLOv8ï¼Œå’ŒYOLOv11æ˜¯ultralyticså…¬å¸ä½œå“ï¼ˆultralyticså‡ºå“å¿…å±ç²¾å“ï¼‰ï¼Œä¸‹é¢ç”¨ä¸€å¼ å›¾ç‰‡ä»yamlæ–‡ä»¶æ¥å¸¦å¤§å®¶å¯¹æ¯”ä¸€ä¸‹YOLOv8å’ŒYOLOv11çš„åŒºåˆ«ï¼Œé…ç½®æ–‡ä»¶å˜å¾—å†…å®¹æ¯”è¾ƒå°‘å¤§å®¶å¯ä»¥çœ‹ä¸€å¡ï¼Œå·¦ä¾§ä¸ºYOLOv8å³ä¾§ä¸ºYOLOv11ï¼Œä¸åŒçš„ç‚¹æˆ‘ç”¨é»‘çº¿æ ‡æ³¨äº†å‡ºæ¥ã€‚\nä¸‰ã€YOLOv11çš„ç½‘ç»œç»“æ„è§£æ ä¸‹é¢çš„å›¾ç‰‡ä¸ºYOLOv11çš„ç½‘ç»œç»“æ„å›¾ã€‚\n**å…¶ä¸­ä¸»è¦åˆ›æ–°ç‚¹å¯ä»¥æ€»ç»“å¦‚ä¸‹- \u0026gt; **\n1. æå‡ºC3k2æœºåˆ¶ï¼Œå…¶ä¸­C3k2æœ‰å‚æ•°ä¸ºc3kï¼Œå…¶ä¸­åœ¨ç½‘ç»œçš„æµ…å±‚c3kè®¾ç½®ä¸ºFalseï¼ˆä¸‹å›¾ä¸­å¯ä»¥çœ‹åˆ°c3k2ç¬¬äºŒä¸ªå‚æ•°è¢«è®¾ç½®ä¸ºFalseï¼Œå°±æ˜¯å¯¹åº”çš„c3kå‚æ•°ï¼‰ã€‚\næ­¤æ—¶æ‰€è°“çš„C3k2å°±ç›¸å½“äºYOLOv8ä¸­çš„C2fï¼Œå…¶ç½‘ç»œç»“æ„ä¸ºä¸€è‡´çš„ï¼Œå…¶ä¸­çš„C3kæœºåˆ¶çš„ç½‘ç»œç»“æ„å›¾å¦‚ä¸‹å›¾æ‰€ç¤º ï¼ˆä¸ºä»€ä¹ˆå«C3k2ï¼Œæˆ‘ä¸ªäººç†è§£æ˜¯å› ä¸ºC3kçš„è°ƒç”¨æ—¶C3kå…¶ä¸­çš„å‚æ•°Nå›ºå®šè®¾ç½®ä¸º2çš„åŸå› ï¼Œä¸ªäººç†è§£ä¸ä¸€å®šå¯¹ ï¼‰ã€‚\n2. ç¬¬äºŒä¸ªåˆ›æ–°ç‚¹æ˜¯æå‡ºC2PSAæœºåˆ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªC2ï¼ˆC2fçš„å‰èº«ï¼‰æœºåˆ¶å†…éƒ¨åµŒå…¥äº†ä¸€ä¸ªå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­æˆ‘è¿˜å‘ç°ä½œè€…å°è¯•äº†C2fPSAæœºåˆ¶ä½†æ˜¯ä¼°è®¡æ•ˆæœä¸å¦‚C2PSAï¼Œæœ‰çš„æ—¶å€™æœºåˆ¶æœ‰æ²¡æœ‰æ•ˆæœç†è®ºä¸ŠçœŸçš„å¾ˆéš¾è§£é‡Šé€šï¼Œä¸‹å›¾ä¸ºC2PSAæœºåˆ¶çš„åŸç†å›¾ï¼Œä»”ç»†è§‚å¯ŸæŠŠAttentionå“ªé‡Œå»æ‰åˆ™C2PSAæœºåˆ¶å°±å˜ä¸ºäº†C2æ‰€ä»¥æˆ‘ä¸Šé¢è¯´C2PSAå°±æ˜¯C2é‡Œé¢åµŒå…¥äº†ä¸€ä¸ªPSAæœºåˆ¶ã€‚\n3. ç¬¬ä¸‰ä¸ªåˆ›æ–°ç‚¹å¯ä»¥è¯´æ˜¯åŸå…ˆçš„è§£è€¦å¤´ä¸­çš„åˆ†ç±»æ£€æµ‹å¤´å¢åŠ äº†ä¸¤ä¸ªDWConvï¼Œå…·ä½“çš„å¯¹æ¯”å¤§å®¶å¯ä»¥çœ‹ä¸‹é¢ä¸¤ä¸ªå›¾ä¸‹é¢çš„æ˜¯YOLOv11çš„è§£è€¦å¤´ï¼Œä¸Šé¢çš„æ˜¯YOLOv8çš„è§£è€¦å¤´.\næˆ‘ä»¬ä¸Šé¢çœ‹åˆ°äº†åœ¨åˆ†ç±»æ£€æµ‹å¤´ä¸­YOLOv11æ’å…¥äº†ä¸¤ä¸ªDWConvè¿™æ ·çš„åšæ³•å¯ä»¥å¤§å¹…åº¦å‡å°‘å‚æ•°é‡å’Œè®¡ç®—é‡ï¼ˆåŸå…ˆä¸¤ä¸ªæ™®é€šçš„Convå¤§å®¶è¦æ³¨æ„åˆ°å·ç§¯å’Œæ˜¯ç”±3å˜ä¸ºäº†1çš„ï¼Œè¿™æ˜¯å½¢æˆäº†ä¸¤ä¸ªæ·±åº¦å¯åˆ†ç¦»Convï¼‰ï¼Œå¤§å®¶å¯èƒ½ä¸å¤ªç†è§£ä¸ºä»€ä¹ˆåŠ å…¥äº†ä¸¤ä¸ªDWConvè¿˜èƒ½å¤Ÿå‡å°‘è®¡ç®—é‡ï¼Œä»¥åŠä»€ä¹ˆæ˜¯æ·±åº¦å¯åˆ†ç¦»Convï¼Œä¸‹é¢æˆ‘æ¥è§£é‡Šä¸€ä¸‹ã€‚\nDWConv ä»£è¡¨ Depthwise Convolutionï¼ˆæ·±åº¦å·ç§¯ï¼‰ï¼Œæ˜¯ä¸€ç§åœ¨å·ç§¯ç¥ç»ç½‘ç»œä¸­å¸¸ç”¨çš„é«˜æ•ˆå·ç§¯æ“ä½œã€‚å®ƒä¸»è¦ç”¨äºå‡å°‘è®¡ç®—å¤æ‚åº¦å’Œå‚æ•°é‡ï¼Œå°¤å…¶åœ¨ç§»åŠ¨ç«¯æˆ–è½»é‡åŒ–ç½‘ç»œï¼ˆå¦‚ MobileNetï¼‰ä¸­ååˆ†å¸¸è§ã€‚\n1. æ ‡å‡†å·ç§¯çš„è®¡ç®—è¿‡ç¨‹\nåœ¨æ ‡å‡†å·ç§¯æ“ä½œä¸­ï¼Œå¯¹äºä¸€ä¸ªè¾“å…¥å¼ é‡ï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªå¤šé€šé“çš„ç‰¹å¾å›¾ï¼‰ï¼Œå·ç§¯æ ¸çš„å°ºå¯¸æ˜¯ (h, w, C_in)ï¼Œå…¶ä¸­ h å’Œ w æ˜¯å·ç§¯æ ¸çš„ç©ºé—´å°ºå¯¸ï¼ŒC_in æ˜¯è¾“å…¥é€šé“çš„æ•°é‡ã€‚è€Œå·ç§¯æ ¸ä¸è¾“å…¥å¼ é‡åšçš„æ˜¯å®Œæ•´çš„å·ç§¯è¿ç®—ï¼Œæ¯ä¸ªè¾“å‡ºé€šé“éƒ½ä¸æ‰€æœ‰è¾“å…¥é€šé“ç›¸è¿å¹¶å‚ä¸å·ç§¯æ“ä½œï¼Œå¯¼è‡´è®¡ç®—é‡æ¯”è¾ƒå¤§ã€‚\næ ‡å‡†å·ç§¯çš„è®¡ç®—è¿‡ç¨‹æ˜¯è¿™æ ·çš„ï¼š\næ¯ä¸ªè¾“å‡ºé€šé“æ˜¯æ‰€æœ‰è¾“å…¥é€šé“çš„ç»„åˆï¼ˆåŠ æƒæ±‚å’Œï¼‰ï¼Œå·ç§¯æ ¸åœ¨æ¯ä¸ªä½ç½®éƒ½ä¼šè®¡ç®—ä¸æ‰€æœ‰è¾“å…¥é€šé“çš„ç‚¹ç§¯ã€‚ å‡è®¾æœ‰ C_in ä¸ªè¾“å…¥é€šé“å’Œ C_out ä¸ªè¾“å‡ºé€šé“ï¼Œé‚£ä¹ˆå·ç§¯æ ¸çš„æ€»å‚æ•°é‡æ˜¯ C_in * C_out * h * wã€‚ 2. Depthwise Convolutionï¼ˆDWConvï¼‰\nä¸æ ‡å‡†å·ç§¯ä¸åŒï¼Œ æ·±åº¦å·ç§¯ å°†è¾“å…¥çš„æ¯ä¸ªé€šé“å•ç‹¬å¤„ç†ï¼Œå³ æ¯ä¸ªé€šé“éƒ½æœ‰è‡ªå·±çš„å·ç§¯æ ¸è¿›è¡Œå·ç§¯ ï¼Œä¸ä¸å…¶ä»–é€šé“è¿›è¡Œäº¤äº’ã€‚å®ƒå¯ä»¥è¢«çœ‹ä½œæ˜¯æ ‡å‡†å·ç§¯çš„ä¸€éƒ¨åˆ†ï¼Œä¸“æ³¨äºç©ºé—´ç»´åº¦ä¸Šçš„å·ç§¯è¿ç®—ã€‚\næ·±åº¦å·ç§¯çš„è®¡ç®—è¿‡ç¨‹ï¼š\nå‡è®¾è¾“å…¥å¼ é‡æœ‰ C_in ä¸ªé€šé“ï¼Œæ¯ä¸ªé€šé“ä¼šä½¿ç”¨ä¸€ä¸ª h Ã— w çš„å·ç§¯æ ¸è¿›è¡Œå·ç§¯æ“ä½œã€‚è¿™ä¸ªè¿‡ç¨‹ç§°ä¸ºâ€œæ·±åº¦å·ç§¯â€ï¼Œå› ä¸ºæ¯ä¸ªé€šé“ç‹¬ç«‹è¿›è¡Œå·ç§¯è¿ç®—ã€‚ è¾“å‡ºçš„é€šé“æ•°ä¸è¾“å…¥é€šé“æ•°ä¸€è‡´ï¼Œæ¯ä¸ªè¾“å‡ºé€šé“åªå’Œå¯¹åº”çš„è¾“å…¥é€šé“è¿›è¡Œå·ç§¯ï¼Œæ²¡æœ‰è·¨é€šé“çš„ç»„åˆã€‚ å‚æ•°é‡å’Œè®¡ç®—é‡ç›¸æ¯”æ ‡å‡†å·ç§¯å¤§å¤§å‡å°‘ï¼Œå·ç§¯æ ¸çš„å‚æ•°é‡æ˜¯ C_in * h * wã€‚ æ·±åº¦å·ç§¯çš„ä¼˜ç‚¹ï¼š\nè®¡ç®—æ•ˆç‡é«˜ ï¼šç›¸å¯¹äºæ ‡å‡†å·ç§¯ï¼Œæ·±åº¦å·ç§¯æ˜¾è‘—å‡å°‘äº†è®¡ç®—é‡ã€‚å®ƒåªå¤„ç†ç©ºé—´ç»´åº¦ä¸Šçš„å·ç§¯ï¼Œä¸å†å¤„ç†é€šé“é—´çš„å·ç§¯ã€‚ å‚æ•°é‡å‡å°‘ ï¼šç”±äºæ¯ä¸ªå·ç§¯æ ¸åªå¯¹å•ä¸ªé€šé“è¿›è¡Œå·ç§¯ï¼Œå‚æ•°é‡å¤§å¹…å‡å°‘ã€‚ä¾‹å¦‚ï¼Œæ ‡å‡†å·ç§¯çš„å‚æ•°é‡ä¸º C_in * C_out * h * wï¼Œè€Œæ·±åº¦å·ç§¯çš„å‚æ•°é‡ä¸º C_in * h * wã€‚ ç»“åˆç‚¹å·ç§¯å¯æå‡æ•ˆæœ ï¼šä¸ºäº†å¼¥è¡¥æ·±åº¦å·ç§¯ç¼ºä¹è·¨é€šé“ä¿¡æ¯æ•´åˆçš„é—®é¢˜ï¼Œé€šå¸¸æ·±åº¦å·ç§¯åä¼šé…åˆ 1x1 çš„ç‚¹å·ç§¯ï¼ˆPointwise Convolutionï¼‰ä½¿ç”¨ï¼Œé€šè¿‡ 1x1 çš„å·ç§¯æ ¸æ•´åˆè·¨é€šé“çš„ä¿¡æ¯ã€‚è¿™ç§ç»„åˆè¢«ç§°ä¸º æ·±åº¦å¯åˆ†ç¦»å·ç§¯ ï¼ˆDepthwise Separable Convolutionï¼‰ | è¿™ä¹Ÿæ˜¯æˆ‘ä»¬æœ¬æ–‡YOLOv11ä¸­çš„åšæ³• ã€‚ 3. æ·±åº¦å·ç§¯ä¸æ ‡å‡†å·ç§¯çš„åŒºåˆ«\næ“ä½œç±»å‹ å·ç§¯æ ¸å¤§å° è¾“å…¥é€šé“æ•° è¾“å‡ºé€šé“æ•° å‚æ•°é‡ æ ‡å‡†å·ç§¯ h Ã— w C_in C_out C_in * C_out * h * w æ·±åº¦å·ç§¯ï¼ˆDWConvï¼‰ h Ã— w C_in C_in C_in * h * w å¯ä»¥çœ‹å‡ºï¼Œæ·±åº¦å·ç§¯åœ¨ç›¸åŒçš„å·ç§¯æ ¸å¤§å°ä¸‹ï¼Œå‚æ•°é‡å‡å°‘äº†çº¦ C_out å€ ï¼ˆç»†å¿ƒçš„äººå¯ä»¥å‘ç°ç”¨æœ€æ–°ç‰ˆæœ¬çš„ultralyticsä»“åº“è¿è¡ŒYOLOv8å‚æ•°é‡ç›¸æ¯”äºä¹‹å‰çš„YOLOv8ä»¥åŠå¤§å¹…åº¦å‡å°‘äº†è¿™å°±æ˜¯å› ä¸ºæ£€æµ‹å¤´æ”¹äº†çš„åŸå› ä½†æ˜¯åå­—è¿˜æ˜¯Detectï¼Œæ‰€ä»¥å¦‚æœä½ æƒ³ç»§ç»­ç”¨YOLOv8å‘è¡¨è®ºæ–‡åšå®éªŒé‚£ä¹ˆä¸è¦æ›´æ–°æœ€è¿‘çš„ultralyticsä»“åº“ï¼‰ã€‚\n4. æ·±åº¦å¯åˆ†ç¦»å·ç§¯ (Depthwise Separable Convolution)\næ·±åº¦å·ç§¯å¸¸ä¸ 1x1 çš„ç‚¹å·ç§¯é…åˆä½¿ç”¨ï¼Œè¿™ç§°ä¸ºæ·±åº¦å¯åˆ†ç¦»å·ç§¯ã€‚å…¶è¿‡ç¨‹å¦‚ä¸‹ï¼š\nå…ˆå¯¹è¾“å…¥å¼ é‡è¿›è¡Œæ·±åº¦å·ç§¯ï¼Œå¯¹æ¯ä¸ªé€šé“ç‹¬ç«‹è¿›è¡Œç©ºé—´å·ç§¯ã€‚ ç„¶åé€šè¿‡ 1x1 ç‚¹å·ç§¯ï¼Œå¯¹é€šé“ç»´åº¦è¿›è¡Œæ··åˆï¼Œæ•´åˆä¸åŒé€šé“çš„ä¿¡æ¯ã€‚ è¿™æ ·æ—¢å¯ä»¥ä¿è¯è®¡ç®—é‡çš„å‡å°‘ï¼Œåˆå¯ä»¥ä¿æŒè·¨é€šé“çš„ä¿¡æ¯æµåŠ¨ã€‚\n5. æ€»ç»“\nDWConv æ˜¯ä¸€ç§é«˜æ•ˆçš„å·ç§¯æ–¹å¼ï¼Œé€šè¿‡å•ç‹¬å¤„ç†æ¯ä¸ªé€šé“æ¥å‡å°‘è®¡ç®—é‡ï¼Œç»“åˆ 1x1 çš„ç‚¹å·ç§¯ï¼Œå½¢æˆæ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼Œå¯ä»¥åœ¨ä¿æŒç½‘ç»œæ€§èƒ½çš„åŒæ—¶æå¤§åœ°å‡å°‘æ¨¡å‹çš„è®¡ç®—å¤æ‚åº¦å’Œå‚æ•°é‡ã€‚\nçœ‹åˆ°è¿™é‡Œå¤§å®¶åº”è¯¥æ˜ç™½äº†ä¸ºä»€ä¹ˆåŠ å…¥äº†ä¸¤ä¸ªDWConvè¿˜èƒ½å‡å°‘å‚æ•°é‡ä»¥åŠYOLOv11çš„æ£€æµ‹å¤´åˆ›æ–°ç‚¹åœ¨å“ªé‡Œã€‚\n4.YOLOv11å’ŒYOLOv8è¿˜æœ‰ä¸€ä¸ªä¸åŒçš„ç‚¹å°±æ˜¯å…¶å„ä¸ªç‰ˆæœ¬çš„æ¨¡å‹ï¼ˆN - S - M- L - Xï¼‰ç½‘ç»œæ·±åº¦å’Œå®½åº¦å˜äº† å¯ä»¥çœ‹åˆ°åœ¨æ·±åº¦ï¼ˆdepthï¼‰å’Œå®½åº¦ ï¼ˆwidthï¼‰ä¸¤ä¸ªåœ°æ–¹YOLOv8å’ŒYOLOv11æ˜¯åŸºæœ¬ä¸Šå®Œå…¨ä¸åŒäº†ï¼Œè¿™é‡Œæˆ‘ç†è§£è¿™ä¹ˆåšçš„å«ä¹‰å°±æ˜¯æ¨¡å‹ç½‘ç»œå˜å°äº†ï¼Œæ‰€ä»¥éœ€è¦åŠ æ·±ä¸€äº›æ¨¡å‹çš„æ”¾ç¼©å€æ•°æ¥å¼¥è¡¥æ¨¡å‹ä¹‹å‰ä¸§å¤±çš„èƒ½åŠ›ä»è€Œæ¥è¾¾åˆ°ä¸€ä¸ªå¹³è¡¡ã€‚\næœ¬ç« æ€»ç»“ï¼š YOLOv11çš„æ”¹è¿›ç‚¹å…¶å®å¹¶ä¸å¤šæ›´å¤šçš„éƒ½æ˜¯ä¸€äº›å°çš„ç»“æ„ä¸Šçš„åˆ›æ–°ï¼Œç›¸å¯¹äºä¹‹å‰çš„YOLOv5åˆ°YOLOv8çš„åˆ›æ–°ï¼Œå…¶å®YOLOv11çš„åˆ›æ–°ç‚¹ä¸ç®—å¤šï¼Œä½†æ˜¯å…¶æ˜¯ultralyticså…¬å¸çš„å‡ºå“ï¼ŒåŒæ—¶ultralyticsä»“åº“çš„ä½¿ç”¨é‡æ˜¯éå¸¸å¤šçš„ï¼ˆä¸åƒYOLOv9å’ŒYOLOv10ï¼‰æ‰€ä»¥åœ¨æœªæ¥çš„å¾ˆé•¿ä¸€æ®µæ—¶é—´å†…å…¶å®YOLOç³»åˆ—ä¼°è®¡ä¸ä¼šå†æ›´æ–°äº†ï¼ŒYOLOv11ä½œä¸ºæœ€æ–°çš„SOTAè‚¯å®šæ˜¯ååˆ†é€‚åˆå¤§å®¶æ¥å‘è¡¨è®ºæ–‡å’Œåˆ›æ–°çš„ã€‚\næœ€åå¼ºè°ƒï¼š æœ¬æ–‡åªæ˜¯å¯¹YOLOv11çš„åˆ›æ–°éƒ¨åˆ†è¿›è¡Œäº†éƒ¨åˆ†è§£æï¼Œå…¶ä½™éƒ¨åˆ†å…¶å®å’ŒYOLOv8ä¿æŒä¸€è‡´å¤§å®¶æœ‰éœ€è¦çš„å¯ä»¥è‡ªè¡ŒæŸ¥é˜…å…¶å®ƒèµ„æ–™ï¼ŒåŒæ—¶æœ‰è§£æä¸å¯¹çš„åœ°æ–¹æ¬¢è¿å¤§å®¶è¯„è®ºåŒºæŒ‡å‡ºå’Œè®¨è®ºã€‚\nå››ã€YOLOv11ä¸‹è½½ã€ç¯å¢ƒå®‰è£…ã€æ•°æ®é›†è·å– YOLOv11çš„ä¸‹è½½å¤§å®¶å¯ä»¥é€šè¿‡ç‚¹å‡»ä¸‹é¢çš„é“¾æ¥è¿›è¡Œä¸‹è½½-\u0026gt;\nå®˜æ–¹ä¸‹è½½åœ°å€ï¼šYOLOv11å®˜æ–¹Githubä¸‹è½½åœ°å€ç‚¹å‡»æ­¤å¤„å³å¯è·³è½¬.\nç‚¹è¿›å»ä¹‹åæŒ‰ç…§å¦‚ä¸‹å›¾æ‰€ç¤ºçš„æ“ä½œå³å¯ä¸‹è½½ultralyticsä»“åº“åˆ°æœ¬åœ°.\nä¸‹è½½åˆ°æœ¬åœ°ä¹‹åå¤§å®¶è§£å‹ç¼©åˆ©ç”¨è‡ªå·±çš„IDEAæ‰“å¼€å³å¯äº†ï¼Œç¯å¢ƒæ­å»ºå¤§å®¶å¯ä»¥çœ‹æˆ‘å¦ä¸€ç¯‡æ–‡ç« ï¼Œè¿™é‡Œç”±äºç¯‡å¹…åŸå› å°±ä¸å¤šä»‹ç»äº†ï¼Œå¦‚æœä½ è‡ªå·±æœ‰ç¯å¢ƒäº†è·³è¿‡æ­¤æ­¥å³å¯.\nç¯å¢ƒå®‰è£…ä¸‹è½½ ï¼šç¯å¢ƒå®‰è£…æ•™ç¨‹ç‚¹å‡»æ­¤å¤„å³å¯è·³è½¬.\næ•°æ®é›†è·å–æ–¹æ³•å¯ä»¥çœ‹ä»¥ä¸‹æ–‡ç« å†…å®¹ï¼Œåˆ©ç”¨roboflowè·å–å¤§é‡æ•°æ®é›†ï¼ˆ1000w+æ•°æ®é›†ä»»ä½ æŒ‘é€‰ï¼‰\næ•°æ®é›†ä¸‹è½½æ•™ç¨‹ï¼šroboflowä¸€é”®å¯¼å‡ºVocã€COCOã€Yoloã€Csvã€yoloç­‰æ ¼å¼æ•°æ®é›†æ•™ç¨‹\näº”ã€æ¨¡å‹è®­ç»ƒ ä¸Šé¢ç»™å¤§å®¶è®²å®Œäº†ç½‘ç»œçš„åˆ›æ–°ä¸‹é¢ç»™å¤§å®¶è®²ä¸€ä¸‹YOLOv11å¦‚ä½•è¿›è¡Œè®­ç»ƒé¢„æµ‹éªŒè¯ç­‰æ“ä½œã€‚\næˆ‘é—¨æ‰“å¼€ultralytics/cfg/default.yamlæ–‡ä»¶å¯ä»¥é…ç½®æ¨¡å‹çš„å‚æ•°ï¼Œ åœ¨å…¶ä¸­å’Œæ¨¡å‹è®­ç»ƒæœ‰å…³çš„å‚æ•°åŠå…¶è§£é‡Šå¦‚ä¸‹:\nå‚æ•°å è¾“å…¥ç±»å‹ å‚æ•°è§£é‡Š 0 task str YOLOæ¨¡å‹çš„ä»»åŠ¡é€‰æ‹©ï¼Œé€‰æ‹©ä½ æ˜¯è¦è¿›è¡Œæ£€æµ‹ã€åˆ†ç±»ç­‰æ“ä½œ 1 mode str YOLOæ¨¡å¼çš„é€‰æ‹©ï¼Œé€‰æ‹©è¦è¿›è¡Œè®­ç»ƒã€æ¨ç†ã€è¾“å‡ºã€éªŒè¯ç­‰æ“ä½œ 2 model str/optional æ¨¡å‹çš„æ–‡ä»¶ï¼Œå¯ä»¥æ˜¯å®˜æ–¹çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œä¹Ÿå¯ä»¥æ˜¯è®­ç»ƒè‡ªå·±æ¨¡å‹çš„yamlæ–‡ä»¶ 3 data str/optional æ¨¡å‹çš„åœ°å€ï¼Œå¯ä»¥æ˜¯æ–‡ä»¶çš„åœ°å€ï¼Œä¹Ÿå¯ä»¥æ˜¯é…ç½®å¥½åœ°å€çš„yamlæ–‡ä»¶ 4 epochs int è®­ç»ƒçš„è½®æ¬¡ï¼Œå°†ä½ çš„æ•°æ®è¾“å…¥åˆ°æ¨¡å‹é‡Œè¿›è¡Œè®­ç»ƒçš„æ¬¡æ•° 5 patience int æ—©åœæœºåˆ¶ï¼Œå½“ä½ çš„æ¨¡å‹ç²¾åº¦æ²¡æœ‰æ”¹è¿›äº†å°±æå‰åœæ­¢è®­ç»ƒ 6 batch int æˆ‘ä»¬è¾“å…¥çš„æ•°æ®é›†ä¼šåˆ†è§£ä¸ºå¤šä¸ªå­é›†ï¼Œä¸€æ¬¡å‘æ¨¡å‹é‡Œè¾“å…¥å¤šå°‘ä¸ªå­é›† 7 imgsz int/list è¾“å…¥çš„å›¾ç‰‡çš„å¤§å°ï¼Œå¯ä»¥æ˜¯æ•´æ•°å°±ä»£è¡¨å›¾ç‰‡å°ºå¯¸ä¸ºint*intï¼Œæˆ–è€…liståˆ†åˆ«ä»£è¡¨å®½å’Œé«˜[wï¼Œh] 8 save bool æ˜¯å¦ä¿å­˜æ¨¡å‹ä»¥åŠé¢„æµ‹ç»“æœ 9 save_period int åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¤šå°‘æ¬¡ä¿å­˜ä¸€æ¬¡æ¨¡å‹æ–‡ä»¶,å°±æ˜¯ç”Ÿæˆçš„ptæ–‡ä»¶ 10 cache bool å‚æ•°cacheç”¨äºæ§åˆ¶æ˜¯å¦å¯ç”¨ç¼“å­˜æœºåˆ¶ã€‚ 11 device int/str/list/optional GPUè®¾å¤‡çš„é€‰æ‹©ï¼šcuda device=0 or device=0,1,2,3 or device=cpu 12 workers int å·¥ä½œçš„çº¿ç¨‹ï¼ŒWindowsç³»ç»Ÿä¸€å®šè¦è®¾ç½®ä¸º0å¦åˆ™å¾ˆå¯èƒ½ä¼šå¼•èµ·çº¿ç¨‹æŠ¥é”™ 13 name str/optional æ¨¡å‹ä¿å­˜çš„åå­—ï¼Œç»“æœä¼šä¿å­˜åˆ°\u0026rsquo;project/name\u0026rsquo; ç›®å½•ä¸‹ 14 exist_ok bool å¦‚æœæ¨¡å‹å­˜åœ¨çš„æ—¶å€™æ˜¯å¦è¿›è¡Œè¦†ç›–æ“ä½œ 15 prepetrained bool\n| å‚æ•°pretrainedç”¨äºæ§åˆ¶æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ã€‚\n16| optimizer| str| ä¼˜åŒ–å™¨çš„é€‰æ‹©choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]\n17| verbose| bool| ç”¨äºæ§åˆ¶åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­æ˜¯å¦è¾“å‡ºè¯¦ç»†çš„ä¿¡æ¯å’Œæ—¥å¿—ã€‚\n18| seed| int| éšæœºæ•°ç§å­ï¼Œæ¨¡å‹ä¸­æ¶‰åŠåˆ°éšæœºçš„æ—¶å€™ï¼Œæ ¹æ®éšæœºæ•°ç§å­è¿›è¡Œç”Ÿæˆ\n19| deterministic| bool| ç”¨äºæ§åˆ¶æ˜¯å¦å¯ç”¨ç¡®å®šæ€§æ¨¡å¼ï¼Œåœ¨ç¡®å®šæ€§æ¨¡å¼ä¸‹ï¼Œç®—æ³•çš„æ‰§è¡Œå°†å˜å¾—å¯é‡å¤ï¼Œå³ç›¸åŒçš„è¾“å…¥å°†äº§ç”Ÿç›¸åŒçš„è¾“å‡º\n20| single_cls| bool| æ˜¯å¦æ˜¯å•æ ‡ç­¾è®­ç»ƒ\n21| rect| bool| å½“ rect è®¾ç½®ä¸º True æ—¶ï¼Œè¡¨ç¤ºå¯ç”¨çŸ©å½¢è®­ç»ƒæˆ–éªŒè¯ã€‚çŸ©å½¢è®­ç»ƒæˆ–éªŒè¯æ˜¯ä¸€ç§æ•°æ®å¤„ç†æŠ€æœ¯ï¼Œå…¶ä¸­åœ¨è®­ç»ƒæˆ–éªŒè¯è¿‡ç¨‹ä¸­ï¼Œè¾“å…¥æ•°æ®ä¼šè¢«è°ƒæ•´ä¸ºå…·æœ‰ç›¸åŒå®½é«˜æ¯”çš„çŸ©å½¢å½¢çŠ¶ã€‚\n22|\ncos_lr\n| bool| æ§åˆ¶æ˜¯å¦ä½¿ç”¨ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦å™¨\n23| close_mosaic| int| æ§åˆ¶åœ¨æœ€åå‡ ä¸ª epochs ä¸­æ˜¯å¦ç¦ç”¨é©¬èµ›å…‹æ•°æ®å¢å¼º\n24| resume| bool| ç”¨äºä»å…ˆå‰çš„è®­ç»ƒæ£€æŸ¥ç‚¹ï¼ˆcheckpointï¼‰ä¸­æ¢å¤æ¨¡å‹çš„è®­ç»ƒã€‚\n25| amp| bool| ç”¨äºæ§åˆ¶æ˜¯å¦è¿›è¡Œè‡ªåŠ¨æ··åˆç²¾åº¦\n26| fraction| float| ç”¨äºæŒ‡å®šè®­ç»ƒæ•°æ®é›†çš„ä¸€éƒ¨åˆ†è¿›è¡Œè®­ç»ƒçš„æ¯”ä¾‹ã€‚é»˜è®¤å€¼ä¸º 1.0\n27| profile| bool| ç”¨äºæ§åˆ¶æ˜¯å¦åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ç”¨ ONNX å’Œ TensorRT çš„æ€§èƒ½åˆ†æ\n28| freeze| int/list/optinal| ç”¨äºæŒ‡å®šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å†»ç»“å‰ n å±‚æˆ–æŒ‡å®šå±‚ç´¢å¼•çš„åˆ—è¡¨ï¼Œä»¥é˜²æ­¢å®ƒä»¬çš„æƒé‡æ›´æ–°ã€‚è¿™å¯¹äºè¿ç§»å­¦ä¹ æˆ–ç‰¹å®šå±‚çš„å¾®è°ƒå¾ˆæœ‰ç”¨ã€‚\n5.1 è®­ç»ƒçš„ä¸‰ç§æ–¹å¼ 5.1.1 æ–¹å¼ä¸€ æˆ‘ä»¬å¯ä»¥é€šè¿‡å‘½ä»¤ç›´æ¥è¿›è¡Œè®­ç»ƒåœ¨å…¶ä¸­æŒ‡å®šå‚æ•°ï¼Œä½†æ˜¯è¿™æ ·çš„æ–¹å¼ï¼Œæˆ‘ä»¬æ¯ä¸ªå‚æ•°éƒ½è¦åœ¨å…¶ä¸­æ‰“å‡ºæ¥ã€‚å‘½ä»¤å¦‚ä¸‹:\nyolo task=detect mode=train model=yolov11n.pt data=data.yaml batch=16 epochs=100 imgsz=640 workers=0 device=0\réœ€è¦æ³¨æ„çš„æ˜¯å¦‚æœä½ æ˜¯Windowsç³»ç»Ÿçš„ç”µè„‘å…¶ä¸­çš„Workersæœ€å¥½è®¾ç½®æˆ0å¦åˆ™å®¹æ˜“æŠ¥çº¿ç¨‹çš„é”™è¯¯ã€‚\n5.1.2 æ–¹å¼äºŒ é€šè¿‡æŒ‡å®šcfgç›´æ¥è¿›è¡Œè®­ç»ƒï¼Œæˆ‘ä»¬é…ç½®å¥½ultralytics/cfg/default.yamlè¿™ä¸ªæ–‡ä»¶ä¹‹åï¼Œå¯ä»¥ç›´æ¥æ‰§è¡Œè¿™ä¸ªæ–‡ä»¶è¿›è¡Œè®­ç»ƒï¼Œè¿™æ ·å°±ä¸ç”¨åœ¨å‘½ä»¤è¡Œè¾“å…¥å…¶å®ƒçš„å‚æ•°äº†ã€‚\nyolo cfg=ultralytics/cfg/default.yaml\r5.1.3 æ–¹å¼ä¸‰ ï¼ˆæ¨èï¼Œé¿å…keyErroré”™è¯¯.ï¼‰ æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆ›å»ºpyæ–‡ä»¶æ¥è¿›è¡Œè®­ç»ƒï¼Œè¿™æ ·çš„å¥½å¤„å°±æ˜¯ä¸ç”¨åœ¨ç»ˆç«¯ä¸Šæ‰“å‘½ä»¤ï¼Œè¿™ä¹Ÿèƒ½çœå»ä¸€äº›å·¥ä½œé‡ï¼Œæˆ‘ä»¬åœ¨æ ¹ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªåå­—ä¸ºtrain.pyçš„æ–‡ä»¶ï¼Œåœ¨å…¶ä¸­è¾“å…¥ä»£ç \nimport warnings\rwarnings.filterwarnings('ignore')\rfrom ultralytics import YOLO\rif __name__ == '__main__':\rmodel = YOLO('yolo11.yaml')\r# å¦‚ä½•åˆ‡æ¢æ¨¡å‹ç‰ˆæœ¬, ä¸Šé¢çš„ymalæ–‡ä»¶å¯ä»¥æ”¹ä¸º yolov11s.yamlå°±æ˜¯ä½¿ç”¨çš„v11s,\r# ç±»ä¼¼æŸä¸ªæ”¹è¿›çš„yamlæ–‡ä»¶åç§°ä¸ºyolov11-XXX.yamlé‚£ä¹ˆå¦‚æœæƒ³ä½¿ç”¨å…¶å®ƒç‰ˆæœ¬å°±æŠŠä¸Šé¢çš„åç§°æ”¹ä¸ºyolov11l-XXX.yamlå³å¯ï¼ˆæ”¹çš„æ˜¯ä¸Šé¢YOLOä¸­é—´çš„åå­—ä¸æ˜¯é…ç½®æ–‡ä»¶çš„ï¼‰ï¼\r# model.load('yolov11n.pt') # æ˜¯å¦åŠ è½½é¢„è®­ç»ƒæƒé‡,ç§‘ç ”ä¸å»ºè®®å¤§å®¶åŠ è½½å¦åˆ™å¾ˆéš¾æå‡ç²¾åº¦\rmodel.train(data=r\u0026quot;å¡«å†™ä½ æ•°æ®é›†data.yamlæ–‡ä»¶çš„åœ°å€\u0026quot;,\r# å¦‚æœå¤§å®¶ä»»åŠ¡æ˜¯å…¶å®ƒçš„'ultralytics/cfg/default.yaml'æ‰¾åˆ°è¿™é‡Œä¿®æ”¹taskå¯ä»¥æ”¹æˆdetect, segment, classify, pose\rcache=False,\rimgsz=640,\repochs=100,\rsingle_cls=False, # æ˜¯å¦æ˜¯å•ç±»åˆ«æ£€æµ‹\rbatch=4,\rclose_mosaic=0,\rworkers=0,\rdevice='0',\roptimizer='SGD', # using SGD ä¼˜åŒ–å™¨ é»˜è®¤ä¸ºautoå»ºè®®å¤§å®¶ä½¿ç”¨å›ºå®šçš„.\r# resume=, # ç»­è®­çš„è¯è¿™é‡Œå¡«å†™True, yamlæ–‡ä»¶çš„åœ°æ–¹æ”¹ä¸ºlats.ptçš„åœ°å€,éœ€è¦æ³¨æ„çš„æ˜¯å¦‚æœä½ è®¾ç½®è®­ç»ƒ200è½®æ¬¡æ¨¡å‹è®­ç»ƒäº†200è½®æ¬¡æ˜¯æ²¡æœ‰åŠæ³•è¿›è¡Œç»­è®­çš„.\ramp=True, # å¦‚æœå‡ºç°è®­ç»ƒæŸå¤±ä¸ºNanå¯ä»¥å…³é—­amp\rproject='runs/train',\rname='exp',\r)\ræ— è®ºé€šè¿‡ä¸Šè¿°çš„å“ªä¸€ç§æ–¹å¼åœ¨æ§åˆ¶å°è¾“å‡ºå¦‚ä¸‹å›¾ç‰‡çš„å†…å®¹å°±ä»£è¡¨ç€å¼€å§‹è®­ç»ƒæˆåŠŸäº†ï¼\nå…­ã€æ¨¡å‹éªŒè¯/æµ‹è¯• å‚æ•°å ç±»å‹ å‚æ•°è®²è§£ 1 val bool ç”¨äºæ§åˆ¶æ˜¯å¦åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡ŒéªŒè¯/æµ‹è¯•ã€‚ 2 split str ç”¨äºæŒ‡å®šç”¨äºéªŒè¯/æµ‹è¯•çš„æ•°æ®é›†åˆ’åˆ†ã€‚å¯ä»¥é€‰æ‹© \u0026lsquo;val\u0026rsquo;ã€\u0026rsquo;test\u0026rsquo; æˆ– \u0026rsquo;train\u0026rsquo; ä¸­çš„ä¸€ä¸ªä½œä¸ºéªŒè¯/æµ‹è¯•æ•°æ®é›† 3 save_json bool ç”¨äºæ§åˆ¶æ˜¯å¦å°†ç»“æœä¿å­˜ä¸º JSON æ–‡ä»¶ 4 save_hybird bool ç”¨äºæ§åˆ¶æ˜¯å¦ä¿å­˜æ ‡ç­¾å’Œé™„åŠ é¢„æµ‹ç»“æœçš„æ··åˆç‰ˆæœ¬ 5 conf float/optional ç”¨äºè®¾ç½®æ£€æµ‹æ—¶çš„ç›®æ ‡ç½®ä¿¡åº¦é˜ˆå€¼ 6 iou float ç”¨äºè®¾ç½®éæå¤§å€¼æŠ‘åˆ¶ï¼ˆNMSï¼‰çš„äº¤å¹¶æ¯”ï¼ˆIoUï¼‰é˜ˆå€¼ã€‚ 7 max_det int ç”¨äºè®¾ç½®æ¯å¼ å›¾åƒçš„æœ€å¤§æ£€æµ‹æ•°ã€‚ 8 half bool ç”¨äºæ§åˆ¶æ˜¯å¦ä½¿ç”¨åŠç²¾åº¦ï¼ˆFP16ï¼‰è¿›è¡Œæ¨æ–­ã€‚ 9 dnn bool ï¼Œç”¨äºæ§åˆ¶æ˜¯å¦ä½¿ç”¨ OpenCV DNN è¿›è¡Œ ONNX æ¨æ–­ã€‚ 10 plots bool ç”¨äºæ§åˆ¶åœ¨è®­ç»ƒ/éªŒè¯è¿‡ç¨‹ä¸­æ˜¯å¦ä¿å­˜ç»˜å›¾ç»“æœã€‚ éªŒè¯æˆ‘ä»¬åˆ’åˆ†çš„éªŒè¯é›†/æµ‹è¯•é›†çš„æƒ…å†µï¼Œä¹Ÿå°±æ˜¯è¯„ä¼°æˆ‘ä»¬è®­ç»ƒå‡ºæ¥çš„best.ptæ¨¡å‹å¥½ä¸å\nå‘½ä»¤è¡Œå‘½ä»¤å¦‚ä¸‹:\nyolo task=detect mode=val model=best.pt data=data.yaml device=0\rä¸ƒã€æ¨¡å‹æ¨ç† æˆ‘ä»¬è®­ç»ƒå¥½è‡ªå·±çš„æ¨¡å‹ä¹‹åï¼Œéƒ½ä¼šç”Ÿæˆä¸€ä¸ªæ¨¡å‹æ–‡ä»¶,ä¿å­˜åœ¨ä½ è®¾ç½®çš„ç›®å½•ä¸‹,å½“æˆ‘ä»¬å†æ¬¡æƒ³è¦å®éªŒè¯¥æ¨¡å‹çš„æ•ˆæœä¹‹åå°±å¯ä»¥è°ƒç”¨è¯¥æ¨¡å‹è¿›è¡Œæ¨ç†äº†ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨å®˜æ–¹çš„é¢„è®­ç»ƒæƒé‡æ¥è¿›è¡Œæ¨ç†ã€‚\næ¨ç†çš„æ–¹å¼å’Œè®­ç»ƒä¸€æ ·æˆ‘ä»¬è¿™é‡Œå°±é€‰ä¸€ç§æ¥è¿›è¡Œä¸¾ä¾‹å…¶å®ƒçš„ä¸¤ç§æ–¹å¼éƒ½æ˜¯ä¸€æ ·çš„æ“ä½œåªæ˜¯éœ€è¦æ”¹ä¸€ä¸‹å…¶ä¸­çš„ä¸€äº›å‚æ•°å³å¯:\nå‚æ•°è®²è§£\nå‚æ•°å ç±»å‹ å‚æ•°è®²è§£ 0 source str/optinal ç”¨äºæŒ‡å®šå›¾åƒæˆ–è§†é¢‘çš„ç›®å½• 1 show bool ç”¨äºæ§åˆ¶æ˜¯å¦åœ¨å¯èƒ½çš„æƒ…å†µä¸‹æ˜¾ç¤ºç»“æœ 2 save_txt bool ç”¨äºæ§åˆ¶æ˜¯å¦å°†ç»“æœä¿å­˜ä¸º .txt æ–‡ä»¶ 3 save_conf bool ç”¨äºæ§åˆ¶æ˜¯å¦åœ¨ä¿å­˜ç»“æœæ—¶åŒ…å«ç½®ä¿¡åº¦åˆ†æ•° 4 save_crop bool ç”¨äºæ§åˆ¶æ˜¯å¦å°†å¸¦æœ‰ç»“æœçš„è£å‰ªå›¾åƒä¿å­˜ä¸‹æ¥ 5 show_labels bool ç”¨äºæ§åˆ¶åœ¨ç»˜å›¾ç»“æœä¸­æ˜¯å¦æ˜¾ç¤ºç›®æ ‡æ ‡ç­¾ 6 show_conf bool ç”¨äºæ§åˆ¶åœ¨ç»˜å›¾ç»“æœä¸­æ˜¯å¦æ˜¾ç¤ºç›®æ ‡ç½®ä¿¡åº¦åˆ†æ•° 7 vid_stride int/optional ç”¨äºè®¾ç½®è§†é¢‘çš„å¸§ç‡æ­¥é•¿ 8 stream_buffer bool ç”¨äºæ§åˆ¶æ˜¯å¦ç¼“å†²æ‰€æœ‰æµå¼å¸§ï¼ˆTrueï¼‰æˆ–è¿”å›æœ€æ–°çš„å¸§ï¼ˆFalseï¼‰ 9 line_width int/list[int]/optional ç”¨äºè®¾ç½®è¾¹ç•Œæ¡†çš„çº¿å®½åº¦ï¼Œå¦‚æœç¼ºå¤±åˆ™è‡ªåŠ¨è®¾ç½® 10 visualize bool ç”¨äºæ§åˆ¶æ˜¯å¦å¯è§†åŒ–æ¨¡å‹çš„ç‰¹å¾ 11 augment bool ç”¨äºæ§åˆ¶æ˜¯å¦å¯¹é¢„æµ‹æºåº”ç”¨å›¾åƒå¢å¼º 12 agnostic_nms bool ç”¨äºæ§åˆ¶æ˜¯å¦ä½¿ç”¨æ— å…³ç±»åˆ«çš„éæå¤§å€¼æŠ‘åˆ¶ï¼ˆNMSï¼‰ 13 classes int/list[int]/optional ç”¨äºæŒ‰ç±»åˆ«ç­›é€‰ç»“æœ 14 retina_masks bool ç”¨äºæ§åˆ¶æ˜¯å¦ä½¿ç”¨é«˜åˆ†è¾¨ç‡åˆ†å‰²æ©ç  15 boxes bool ç”¨äºæ§åˆ¶æ˜¯å¦åœ¨åˆ†å‰²é¢„æµ‹ä¸­æ˜¾ç¤ºè¾¹ç•Œæ¡†ã€‚ å‘½ä»¤è¡Œå‘½ä»¤å¦‚ä¸‹:\nyolo task=detect mode=predict model=best.pt source=images device=0\rè¿™é‡Œéœ€è¦éœ€è¦æ³¨æ„çš„æ˜¯æˆ‘ä»¬ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†çš„æ—¶å€™å¯ä»¥é€‰æ‹©ç…§ç‰‡ä¹Ÿå¯ä»¥é€‰æ‹©ä¸€ä¸ªè§†é¢‘çš„æ ¼å¼éƒ½å¯ä»¥ã€‚æ”¯æŒçš„è§†é¢‘æ ¼å¼æœ‰\nMP4ï¼ˆ.mp4ï¼‰ï¼šè¿™æ˜¯ä¸€ç§å¸¸è§çš„è§†é¢‘æ–‡ä»¶æ ¼å¼ï¼Œé€šå¸¸å…·æœ‰è¾ƒé«˜çš„å‹ç¼©ç‡å’Œè‰¯å¥½çš„è§†é¢‘è´¨é‡\nAVIï¼ˆ.aviï¼‰ï¼šè¿™æ˜¯ä¸€ç§è¾ƒæ—§ä½†ä»å¹¿æ³›ä½¿ç”¨çš„è§†é¢‘æ–‡ä»¶æ ¼å¼ã€‚å®ƒé€šå¸¸å…·æœ‰è¾ƒå¤§çš„æ–‡ä»¶å¤§å°\nMOVï¼ˆ.movï¼‰ï¼šè¿™æ˜¯ä¸€ç§å¸¸è§çš„è§†é¢‘æ–‡ä»¶æ ¼å¼ï¼Œé€šå¸¸ä¸è‹¹æœè®¾å¤‡å’ŒQuickTimeæ’­æ”¾å™¨ç›¸å…³\nMKVï¼ˆ.mkvï¼‰ï¼šè¿™æ˜¯ä¸€ç§å¼€æ”¾çš„å¤šåª’ä½“å®¹å™¨æ ¼å¼ï¼Œå¯ä»¥å®¹çº³å¤šä¸ªè§†é¢‘ã€éŸ³é¢‘å’Œå­—å¹•è½¨é“\nFLVï¼ˆ.flvï¼‰ï¼šè¿™æ˜¯ä¸€ç§ç”¨äºåœ¨çº¿è§†é¢‘ä¼ è¾“çš„æµå¼è§†é¢‘æ–‡ä»¶æ ¼å¼\nå…«ã€æ¨¡å‹è¾“å‡º å½“æˆ‘ä»¬è¿›è¡Œéƒ¨ç½²çš„æ—¶å€™å¯ä»¥è¿›è¡Œæ–‡ä»¶å¯¼å‡ºï¼Œç„¶ååœ¨è¿›è¡Œéƒ¨ç½²ã€‚\nYOLOv8æ”¯æŒçš„è¾“å‡ºæ ¼å¼æœ‰å¦‚ä¸‹\n1. ONNXï¼ˆOpen Neural Network Exchangeï¼‰ï¼šONNX æ˜¯ä¸€ä¸ªå¼€æ”¾çš„æ·±åº¦å­¦ä¹ æ¨¡å‹è¡¨ç¤ºå’Œè½¬æ¢çš„æ ‡å‡†ã€‚å®ƒå…è®¸åœ¨ä¸åŒçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ä¹‹é—´å…±äº«æ¨¡å‹ï¼Œå¹¶æ”¯æŒè·¨å¹³å°éƒ¨ç½²ã€‚å¯¼å‡ºä¸º ONNX æ ¼å¼çš„æ¨¡å‹å¯ä»¥åœ¨æ”¯æŒ ONNX çš„æ¨ç†å¼•æ“ä¸­è¿›è¡Œéƒ¨ç½²å’Œæ¨ç†ã€‚\n2. TensorFlow SavedModelï¼šTensorFlow SavedModel æ˜¯ TensorFlow æ¡†æ¶çš„æ ‡å‡†æ¨¡å‹ä¿å­˜æ ¼å¼ã€‚å®ƒåŒ…å«äº†æ¨¡å‹çš„ç½‘ç»œç»“æ„å’Œå‚æ•°ï¼Œå¯ä»¥æ–¹ä¾¿åœ°åœ¨ TensorFlow çš„æ¨ç†ç¯å¢ƒä¸­åŠ è½½å’Œä½¿ç”¨ã€‚\n3. PyTorch JITï¼ˆJust-In-Timeï¼‰ï¼šPyTorch JIT æ˜¯ PyTorch çš„å³æ—¶ç¼–è¯‘å™¨ï¼Œå¯ä»¥å°† PyTorch æ¨¡å‹å¯¼å‡ºä¸ºä¼˜åŒ–çš„ Torch è„šæœ¬æˆ– Torch è„šæœ¬æ¨¡å‹ã€‚è¿™ç§æ ¼å¼å¯ä»¥åœ¨æ²¡æœ‰ PyTorch ç¯å¢ƒçš„æƒ…å†µä¸‹è¿›è¡Œæ¨ç†ï¼Œå¹¶ä¸”å…·æœ‰æ›´é«˜çš„æ€§èƒ½ã€‚\n4. Caffe Modelï¼šCaffe æ˜¯ä¸€ä¸ªæµè¡Œçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå®ƒä½¿ç”¨è‡ªå·±çš„æ¨¡å‹è¡¨ç¤ºæ ¼å¼ã€‚å¯¼å‡ºä¸º Caffe æ¨¡å‹çš„æ–‡ä»¶å¯ä»¥åœ¨ Caffe æ¡†æ¶ä¸­è¿›è¡Œéƒ¨ç½²å’Œæ¨ç†ã€‚\n5. TFLiteï¼ˆTensorFlow Liteï¼‰ï¼šTFLite æ˜¯ TensorFlow çš„ç§»åŠ¨å’ŒåµŒå…¥å¼è®¾å¤‡æ¨ç†æ¡†æ¶ï¼Œæ”¯æŒåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šè¿›è¡Œé«˜æ•ˆæ¨ç†ã€‚æ¨¡å‹å¯ä»¥å¯¼å‡ºä¸º TFLite æ ¼å¼ï¼Œä»¥ä¾¿åœ¨ç§»åŠ¨è®¾å¤‡æˆ–åµŒå…¥å¼ç³»ç»Ÿä¸­è¿›è¡Œéƒ¨ç½²ã€‚\n6. Core MLï¼ˆCore Machine Learningï¼‰ï¼šCore ML æ˜¯è‹¹æœçš„æœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºåœ¨ iOS å’Œ macOS ä¸Šè¿›è¡Œæ¨ç†ã€‚æ¨¡å‹å¯ä»¥å¯¼å‡ºä¸º Core ML æ ¼å¼ï¼Œä»¥ä¾¿åœ¨è‹¹æœè®¾å¤‡ä¸Šè¿›è¡Œéƒ¨ç½²ã€‚\nè¿™äº›æ ¼å¼éƒ½æä¾›äº†ä¸åŒçš„ä¼˜åŠ¿å’Œé€‚ç”¨åœºæ™¯ã€‚é€‰æ‹©åˆé€‚çš„å¯¼å‡ºæ ¼å¼åº”è¯¥è€ƒè™‘åˆ°ç›®æ ‡å¹³å°å’Œéƒ¨ç½²ç¯å¢ƒçš„è¦æ±‚ï¼Œä»¥åŠæ‰€ä½¿ç”¨çš„æ·±åº¦å­¦ä¹ æ¡†æ¶çš„æ”¯æŒæƒ…å†µã€‚\næ¨¡å‹è¾“å‡ºçš„å‚æ•°æœ‰å¦‚ä¸‹\nå‚æ•°å ç±»å‹ å‚æ•°è§£é‡Š 0 format str å¯¼å‡ºæ¨¡å‹çš„æ ¼å¼ 1 keras bool è¡¨ç¤ºæ˜¯å¦ä½¿ç”¨Keras 2 optimize bool ç”¨äºåœ¨å¯¼å‡ºTorchScriptæ¨¡å‹æ—¶è¿›è¡Œä¼˜åŒ–ï¼Œä»¥ä¾¿åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šè·å¾—æ›´å¥½çš„æ€§èƒ½ 3 int8 bool ç”¨äºåœ¨å¯¼å‡ºCoreMLæˆ–TensorFlowæ¨¡å‹æ—¶è¿›è¡ŒINT8é‡åŒ– 4 dynamic bool ç”¨äºåœ¨å¯¼å‡ºCoreMLæˆ–TensorFlowæ¨¡å‹æ—¶è¿›è¡ŒINT8é‡åŒ– 5 simplify bool ç”¨äºåœ¨å¯¼å‡ºONNXæ¨¡å‹æ—¶è¿›è¡Œæ¨¡å‹ç®€åŒ– 6 opset int/optional ç”¨äºæŒ‡å®šå¯¼å‡ºONNXæ¨¡å‹æ—¶çš„opsetç‰ˆæœ¬ 7 workspace int ç”¨äºæŒ‡å®šTensorRTæ¨¡å‹çš„å·¥ä½œç©ºé—´å¤§å°ï¼Œä»¥GBä¸ºå•ä½ 8 nms bool ç”¨äºåœ¨å¯¼å‡ºCoreMLæ¨¡å‹æ—¶æ·»åŠ éæå¤§å€¼æŠ‘åˆ¶ï¼ˆNMSï¼‰ å‘½ä»¤è¡Œå‘½ä»¤å¦‚ä¸‹:\nyolo task=detect mode=export model=best.pt format=onnx åˆ°æ­¤ä¸ºæ­¢æœ¬æ–‡çš„è®²è§£å°±ç»“æŸäº†,å¸Œæœ›å¯¹å¤§å®¶å¯¹äºYOLOv11æ¨¡å‹ç†è§£æœ‰å¸®åŠ©ï¼Œå¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©åˆ°å¤§å®¶ã€‚\n","date":"0001-01-01T00:00:00Z","permalink":"https://nickk111.github.io/p/","title":""},{"content":"\rYOLOv11æ”¹è¿› | ä¸»å¹²/Backboneç¯‡ | ç›®æ ‡æ£€æµ‹ç½‘ç»œFasterNeTè½»é‡åŒ–ç½‘ç»œåŠ©åŠ›yolov11æ”¹è¿›ï¼ˆæé«˜FPSå’Œæ£€æµ‹æ•ˆç‡ï¼‰-CSDNåšå®¢\rYOLOv11æ”¹è¿› | ä¸»å¹²/Backboneç¯‡ | ç›®æ ‡æ£€æµ‹ç½‘ç»œFasterNeTè½»é‡åŒ–ç½‘ç»œåŠ©åŠ›yolov11æ”¹è¿›ï¼ˆæé«˜FPSå’Œæ£€æµ‹æ•ˆç‡ï¼‰\rSnu77\rå·²äºÂ 2024-11-01 11:02:19Â ä¿®æ”¹\ré˜…è¯»é‡1k\ræ”¶è—\r19\rç‚¹èµæ•°\r13\råˆ†ç±»ä¸“æ ï¼š\rYOLOv11æœ‰æ•ˆæ¶¨ç‚¹ä¸“æ \ræ–‡ç« æ ‡ç­¾ï¼š\rYOLO\rç›®æ ‡æ£€æµ‹\ræ·±åº¦å­¦ä¹ \rè®¡ç®—æœºè§†è§‰\räººå·¥æ™ºèƒ½\rpython\rYOLOv11\räºÂ 2024-11-01 11:02:09Â é¦–æ¬¡å‘å¸ƒ\rç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºåšä¸»åŸåˆ›æ–‡ç« ï¼Œéµå¾ª\rCC 4.0 BY-SA\rç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥å’Œæœ¬å£°æ˜ã€‚\ræœ¬æ–‡é“¾æ¥ï¼š\rhttps://blog.csdn.net/java1314777/article/details/143419794\rç‰ˆæƒ\rYOLOv11æœ‰æ•ˆæ¶¨ç‚¹ä¸“æ \rä¸“æ æ”¶å½•è¯¥å†…å®¹\r100 ç¯‡æ–‡ç« \r0 è®¢é˜…\rÂ¥159.90\rÂ¥299.90\rå·²è®¢é˜…\r8æŠ˜ç»­è´¹\ræ‚¨å·²æ˜¯è¶…çº§ä¼šå‘˜ï¼Œæ­£åœ¨å…è´¹é˜…è¯»ä¼šå‘˜ä¸“äº«å†…å®¹\ræŸ¥çœ‹æ›´å¤šè¶…çº§ä¼šå‘˜æƒç›Š\rä¸€ã€æœ¬æ–‡ä»‹ç»\ræœ¬æ–‡ç»™å¤§å®¶å¸¦æ¥çš„æ”¹è¿›æœºåˆ¶æ˜¯FasterNetç½‘ç»œï¼Œå°†å…¶ç”¨æ¥æ›¿æ¢æˆ‘ä»¬çš„\rç‰¹å¾æå–ç½‘ç»œ\rï¼Œå…¶æ—¨åœ¨\ræé«˜è®¡ç®—é€Ÿåº¦è€Œä¸ç‰ºç‰²å‡†ç¡®æ€§\rï¼Œç‰¹åˆ«æ˜¯åœ¨è§†è§‰ä»»åŠ¡ä¸­ã€‚å®ƒé€šè¿‡ä¸€ç§ç§°ä¸º\réƒ¨åˆ†å·ç§¯ï¼ˆPConvï¼‰\rçš„æ–°æŠ€æœ¯æ¥å‡å°‘å†—ä½™è®¡ç®—å’Œå†…å­˜è®¿é—®ã€‚è¿™ç§æ–¹æ³•ä½¿å¾—FasterNetåœ¨å¤šç§è®¾å¤‡ä¸Šè¿è¡Œé€Ÿåº¦æ¯”å…¶ä»–ç½‘ç»œå¿«å¾—å¤šï¼ŒåŒæ—¶åœ¨å„ç§è§†è§‰ä»»åŠ¡ä¸­ä¿æŒé«˜å‡†ç¡®ç‡ã€‚ç»è¿‡æˆ‘çš„å®éªŒè¯¥ä¸»å¹²ç½‘ç»œç¡®å®èƒ½å¤Ÿæ¶¨ç‚¹åœ¨å¤§ä¸­å°ä¸‰ç§ç‰©ä½“æ£€æµ‹ä¸Šï¼Œå¤§å®¶å¯ä»¥åœ¨æºä»£ç ä¸­è¿›è¡Œä¿®æ”¹ç‰ˆæœ¬çš„ä½¿ç”¨ã€‚\ræœ¬æ–‡é€šè¿‡ä»‹ç»å…¶ä¸»è¦æ¡†æ¶åŸç†ï¼Œç„¶åæ•™å¤§å®¶å¦‚ä½•æ·»åŠ è¯¥ç½‘ç»œç»“æ„åˆ°ç½‘ç»œæ¨¡å‹ä¸­ã€‚\rï¼ˆæœ¬æ–‡å†…å®¹å¯æ ¹æ®yolov11çš„Nã€Sã€Mã€Lã€Xè¿›è¡ŒäºŒæ¬¡ç¼©æ”¾ï¼Œè½»é‡åŒ–æ›´ä¸Šä¸€å±‚ï¼‰ã€‚\rä¸“æ å›é¡¾ï¼š\rYOLOv11æ”¹è¿›ç³»åˆ—ä¸“æ â€”â€”æœ¬ä¸“æ æŒç»­å¤ä¹ å„ç§é¡¶ä¼šå†…å®¹â€”â€”ç§‘ç ”å¿…å¤‡\räºŒã€FasterNetåŸç†\râ€‹\rè®ºæ–‡åœ°å€ï¼š\rå®˜æ–¹è®ºæ–‡åœ°å€\rä»£ç åœ°å€ï¼š\rå®˜æ–¹ä»£ç åœ°å€\râ€‹\r2.1 FasterNetçš„åŸºæœ¬åŸç†\rFasterNet\ræ˜¯ä¸€ç§é«˜æ•ˆçš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œæ—¨åœ¨\ræé«˜è®¡ç®—é€Ÿåº¦è€Œä¸ç‰ºç‰²å‡†ç¡®æ€§\rï¼Œç‰¹åˆ«æ˜¯åœ¨è§†è§‰ä»»åŠ¡ä¸­ã€‚å®ƒé€šè¿‡ä¸€ç§ç§°ä¸º\réƒ¨åˆ†å·ç§¯ï¼ˆPConvï¼‰\rçš„æ–°æŠ€æœ¯æ¥å‡å°‘å†—ä½™è®¡ç®—å’Œå†…å­˜è®¿é—®ã€‚è¿™ç§æ–¹æ³•ä½¿å¾—FasterNetåœ¨å¤šç§è®¾å¤‡ä¸Šè¿è¡Œé€Ÿåº¦æ¯”å…¶ä»–ç½‘ç»œå¿«å¾—å¤šï¼ŒåŒæ—¶åœ¨å„ç§è§†è§‰ä»»åŠ¡ä¸­ä¿æŒé«˜å‡†ç¡®ç‡ã€‚ä¾‹å¦‚ï¼ŒFasterNetåœ¨ImageNet-1kæ•°æ®é›†ä¸Šçš„è¡¨ç°è¶…è¿‡äº†å…¶ä»–æ¨¡å‹ï¼Œå¦‚\rMobileViT-XXS\rï¼Œå±•ç°äº†å…¶åœ¨é€Ÿåº¦å’Œå‡†ç¡®åº¦æ–¹é¢çš„ä¼˜åŠ¿ã€‚\rFasterNetçš„åŸºæœ¬åŸç†å¯ä»¥æ€»ç»“ä¸ºä»¥ä¸‹å‡ ç‚¹ï¼š\r1. éƒ¨åˆ†å·ç§¯ï¼ˆPConvï¼‰:\rFasterNetå¼•å…¥äº†éƒ¨åˆ†å·ç§¯ï¼ˆPConvï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å·ç§¯æ–¹æ³•ï¼Œå®ƒé€šè¿‡åªå¤„ç†è¾“å…¥é€šé“çš„ä¸€éƒ¨åˆ†æ¥å‡å°‘è®¡ç®—é‡å’Œå†…å­˜è®¿é—®ã€‚\r2. åŠ é€Ÿç¥ç»ç½‘ç»œ\r: FasterNetåˆ©ç”¨PConvçš„ä¼˜åŠ¿ï¼Œå®ç°äº†åœ¨å¤šç§è®¾å¤‡ä¸Šæ¯”å…¶ä»–ç°æœ‰ç¥ç»ç½‘ç»œæ›´å¿«çš„è¿è¡Œé€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒé«˜çš„å‡†ç¡®åº¦ã€‚\rä¸‹é¢ä¸ºå¤§å®¶å±•ç¤ºçš„æ˜¯\rFasterNetçš„æ•´ä½“æ¶æ„\rã€‚\râ€‹\rå®ƒåŒ…æ‹¬å››ä¸ªå±‚æ¬¡åŒ–çš„é˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µç”±ä¸€ç³»åˆ—FasterNetå—ç»„æˆï¼Œå¹¶ç”±åµŒå…¥æˆ–åˆå¹¶å±‚å¼€å¤´ã€‚æœ€åä¸‰å±‚ç”¨äºç‰¹å¾åˆ†ç±»ã€‚åœ¨æ¯ä¸ªFasterNetå—ä¸­ï¼ŒPConvå±‚ä¹‹åæ˜¯ä¸¤ä¸ªç‚¹çŠ¶å·ç§¯ï¼ˆPWConvï¼‰å±‚ã€‚ä¸ºäº†ä¿æŒç‰¹å¾å¤šæ ·æ€§å¹¶å®ç°æ›´ä½çš„å»¶è¿Ÿï¼Œä»…åœ¨ä¸­é—´å±‚ä¹‹åæ”¾ç½®äº†\rå½’ä¸€åŒ–å’Œæ¿€æ´»å±‚\rã€‚\r2.2\réƒ¨åˆ†å·ç§¯\réƒ¨åˆ†å·ç§¯ï¼ˆPConvï¼‰\ræ˜¯ä¸€ç§\rå·ç§¯ç¥ç»ç½‘ç»œä¸­çš„æ“ä½œ\rï¼Œæ—¨åœ¨æé«˜è®¡ç®—æ•ˆç‡ã€‚å®ƒé€šè¿‡\råªåœ¨è¾“å…¥ç‰¹å¾å›¾çš„ä¸€éƒ¨åˆ†ä¸Šæ‰§è¡Œå·ç§¯æ“ä½œ\rï¼Œè€Œéä¼ ç»Ÿå·ç§¯æ“ä½œä¸­çš„å…¨é¢åº”ç”¨ã€‚è¿™æ ·ï¼ŒPConvå¯ä»¥å‡å°‘ä¸å¿…è¦çš„è®¡ç®—å’Œå†…å­˜è®¿é—®ï¼Œå› ä¸ºå®ƒå¿½ç•¥äº†è¾“å…¥ä¸­è®¤ä¸ºæ˜¯å†—ä½™çš„éƒ¨åˆ†ã€‚è¿™ç§æ–¹æ³•ç‰¹åˆ«é€‚åˆåœ¨èµ„æºæœ‰é™çš„è®¾å¤‡ä¸Šè¿è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå› ä¸ºå®ƒå¯ä»¥åœ¨ä¸ç‰ºç‰²å¤ªå¤šæ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—é™ä½è®¡ç®—éœ€æ±‚ã€‚\rä¸‹é¢æˆ‘ä¸ºå¤§å®¶å±•ç¤ºäº†FasterNetä¸­çš„\réƒ¨åˆ†å·ç§¯ï¼ˆPConvï¼‰ä¸ä¼ ç»Ÿå·ç§¯å’Œæ·±åº¦å·ç§¯/åˆ†ç»„å·ç§¯çš„æ¯”è¾ƒ\rï¼š\râ€‹\rPConvé€šè¿‡ä»…å¯¹è¾“å…¥é€šé“çš„ä¸€å°éƒ¨åˆ†åº”ç”¨æ»¤æ³¢å™¨ï¼ŒåŒæ—¶ä¿æŒå…¶ä½™é€šé“ä¸å˜ï¼Œå®ç°äº†å¿«é€Ÿå’Œé«˜æ•ˆçš„ç‰¹æ€§æå–ã€‚PConvçš„è®¡ç®—å¤æ‚åº¦\rï¼ˆFLOPsï¼‰\rä½äºå¸¸è§„å·ç§¯ï¼Œä½†é«˜äºæ·±åº¦å·ç§¯/åˆ†ç»„å·ç§¯ï¼Œè¿™æ ·åœ¨å‡å°‘è®¡ç®—èµ„æºçš„åŒæ—¶æé«˜äº†è¿ç®—æ€§èƒ½ã€‚\r2.3\råŠ é€Ÿç¥ç»ç½‘ç»œ\råŠ é€Ÿç¥ç»ç½‘ç»œ\rä¸»è¦é€šè¿‡ä¼˜åŒ–è®¡ç®—è·¯å¾„ã€å‡å°‘æ¨¡å‹å¤§å°å’Œå¤æ‚æ€§ã€æé«˜æ“ä½œæ•ˆç‡ï¼Œä»¥åŠä½¿ç”¨é«˜æ•ˆçš„ç¡¬ä»¶å®ç°ç­‰æ–¹å¼æ¥é™ä½æ¨¡å‹çš„æ¨ç†æ—¶é—´ã€‚è¿™äº›æ–¹æ³•åŒ…æ‹¬\rç®€åŒ–ç½‘ç»œå±‚\rã€\rä½¿ç”¨æ›´å¿«çš„æ¿€æ´»å‡½æ•°\rã€\ré‡‡ç”¨é‡åŒ–æŠ€æœ¯\rå°†\ræµ®ç‚¹è¿ç®—è½¬æ¢ä¸ºæ•´æ•°è¿ç®—\rï¼Œä»¥åŠä½¿ç”¨ç‰¹æ®Šçš„ç®—æ³•æ¥å‡å°‘å†…å­˜è®¿é—®æ¬¡æ•°ç­‰ã€‚é€šè¿‡è¿™äº›ç­–ç•¥ï¼Œå¯ä»¥åœ¨ä¸æŸå®³æ¨¡å‹å‡†ç¡®æ€§çš„å‰æä¸‹ï¼Œä½¿ç¥ç»ç½‘ç»œèƒ½å¤Ÿæ›´å¿«åœ°å¤„ç†æ•°æ®å’Œåšå‡ºé¢„æµ‹ã€‚\rä¸‰ã€FasterNetçš„æ ¸å¿ƒä»£ç \r# Copyright (c) Microsoft Corporation.# Licensed under the MIT License.import torchimport torch.nn as nnfrom timm.models.layers import DropPath, trunc_normal_from functools import partialfrom typing import Listfrom torch import Tensorimport copyimport os class Partial_conv3(nn.Module): def __init__(self, dim, n_div, forward): super().__init__() self.dim_conv3 = dim // n_div self.dim_untouched = dim - self.dim_conv3 self.partial_conv3 = nn.Conv2d(self.dim_conv3, self.dim_conv3, 3, 1, 1, bias=False) if forward == 'slicing': self.forward = self.forward_slicing elif forward == 'split_cat': self.forward = self.forward_split_cat else: raise NotImplementedError def forward_slicing(self, x: Tensor) -\u0026gt; Tensor: # only for inference x = x.clone() # !!! Keep the original input intact for the residual connection later x[:, :self.dim_conv3, :, :] = self.partial_conv3(x[:, :self.dim_conv3, :, :]) return x def forward_split_cat(self, x: Tensor) -\u0026gt; Tensor: # for training/inference x1, x2 = torch.split(x, [self.dim_conv3, self.dim_untouched], dim=1) x1 = self.partial_conv3(x1) x = torch.cat((x1, x2), 1) return x class MLPBlock(nn.Module): def __init__(self, dim, n_div, mlp_ratio, drop_path, layer_scale_init_value, act_layer, norm_layer, pconv_fw_type ): super().__init__() self.dim = dim self.mlp_ratio = mlp_ratio self.drop_path = DropPath(drop_path) if drop_path \u0026gt; 0. else nn.Identity() self.n_div = n_div mlp_hidden_dim = int(dim * mlp_ratio) mlp_layer: List[nn.Module] = [ nn.Conv2d(dim, mlp_hidden_dim, 1, bias=False), norm_layer(mlp_hidden_dim), act_layer(), nn.Conv2d(mlp_hidden_dim, dim, 1, bias=False) ] self.mlp = nn.Sequential(*mlp_layer) self.spatial_mixing = Partial_conv3( dim, n_div, pconv_fw_type ) if layer_scale_init_value \u0026gt; 0: self.layer_scale = nn.Parameter(layer_scale_init_value * torch.ones((dim)), requires_grad=True) self.forward = self.forward_layer_scale else: self.forward = self.forward def forward(self, x: Tensor) -\u0026gt; Tensor: shortcut = x x = self.spatial_mixing(x) x = shortcut + self.drop_path(self.mlp(x)) return x def forward_layer_scale(self, x: Tensor) -\u0026gt; Tensor: shortcut = x x = self.spatial_mixing(x) x = shortcut + self.drop_path( self.layer_scale.unsqueeze(-1).unsqueeze(-1) * self.mlp(x)) return x class BasicStage(nn.Module): def __init__(self, dim, depth, n_div, mlp_ratio, drop_path, layer_scale_init_value, norm_layer, act_layer, pconv_fw_type ): super().__init__() blocks_list = [ MLPBlock( dim=dim, n_div=n_div, mlp_ratio=mlp_ratio, drop_path=drop_path[i], layer_scale_init_value=layer_scale_init_value, norm_layer=norm_layer, act_layer=act_layer, pconv_fw_type=pconv_fw_type ) for i in range(depth) ] self.blocks = nn.Sequential(*blocks_list) def forward(self, x: Tensor) -\u0026gt; Tensor: x = self.blocks(x) return x class PatchEmbed(nn.Module): def __init__(self, patch_size, patch_stride, in_chans, embed_dim, norm_layer): super().__init__() self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_stride, bias=False) if norm_layer is not None: self.norm = norm_layer(embed_dim) else: self.norm = nn.Identity() def forward(self, x: Tensor) -\u0026gt; Tensor: x = self.norm(self.proj(x)) return x class PatchMerging(nn.Module): def __init__(self, patch_size2, patch_stride2, dim, norm_layer): super().__init__() self.reduction = nn.Conv2d(dim, 2 * dim, kernel_size=patch_size2, stride=patch_stride2, bias=False) if norm_layer is not None: self.norm = norm_layer(2 * dim) else: self.norm = nn.Identity() def forward(self, x: Tensor) -\u0026gt; Tensor: x = self.norm(self.reduction(x)) return x class FasterNet(nn.Module): def __init__(self, in_chans=3, num_classes=1000, embed_dim=96, depths=(1, 2, 8, 2), mlp_ratio=2., n_div=4, patch_size=4, patch_stride=4, patch_size2=2, # for subsequent layers patch_stride2=2, patch_norm=True, feature_dim=1280, drop_path_rate=0.1, layer_scale_init_value=0, norm_layer='BN', act_layer='RELU', fork_feat=True, init_cfg=None, pretrained=None, pconv_fw_type='split_cat', **kwargs): super().__init__() if norm_layer == 'BN': norm_layer = nn.BatchNorm2d else: raise NotImplementedError if act_layer == 'GELU': act_layer = nn.GELU elif act_layer == 'RELU': act_layer = partial(nn.ReLU, inplace=True) else: raise NotImplementedError if not fork_feat: self.num_classes = num_classes self.num_stages = len(depths) self.embed_dim = embed_dim self.patch_norm = patch_norm self.num_features = int(embed_dim * 2 ** (self.num_stages - 1)) self.mlp_ratio = mlp_ratio self.depths = depths # split image into non-overlapping patches self.patch_embed = PatchEmbed( patch_size=patch_size, patch_stride=patch_stride, in_chans=in_chans, embed_dim=embed_dim, norm_layer=norm_layer if self.patch_norm else None ) # stochastic depth decay rule dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] # build layers stages_list = [] for i_stage in range(self.num_stages): stage = BasicStage(dim=int(embed_dim * 2 ** i_stage), n_div=n_div, depth=depths[i_stage], mlp_ratio=self.mlp_ratio, drop_path=dpr[sum(depths[:i_stage]):sum(depths[:i_stage + 1])], layer_scale_init_value=layer_scale_init_value, norm_layer=norm_layer, act_layer=act_layer, pconv_fw_type=pconv_fw_type ) stages_list.append(stage) # patch merging layer if i_stage \u0026lt; self.num_stages - 1: stages_list.append( PatchMerging(patch_size2=patch_size2, patch_stride2=patch_stride2, dim=int(embed_dim * 2 ** i_stage), norm_layer=norm_layer) ) self.stages = nn.Sequential(*stages_list) self.fork_feat = fork_feat self.forward = self.forward_det # add a norm layer for each output self.out_indices = [0, 2, 4, 6] for i_emb, i_layer in enumerate(self.out_indices): if i_emb == 0 and os.environ.get('FORK_LAST3', None): raise NotImplementedError else: layer = norm_layer(int(embed_dim * 2 ** i_emb)) layer_name = f'norm{i_layer}' self.add_module(layer_name, layer) self.apply(self.cls_init_weights) self.init_cfg = copy.deepcopy(init_cfg) if self.fork_feat and (self.init_cfg is not None or pretrained is not None): self.init_weights() self.width_list = [i.size(1) for i in self.forward(torch.randn(1, 3, 640, 640))] def cls_init_weights(self, m): if isinstance(m, nn.Linear): trunc_normal_(m.weight, std=.02) if isinstance(m, nn.Linear) and m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, (nn.Conv1d, nn.Conv2d)): trunc_normal_(m.weight, std=.02) if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, (nn.LayerNorm, nn.GroupNorm)): nn.init.constant_(m.bias, 0) nn.init.constant_(m.weight, 1.0) def forward_det(self, x: Tensor) -\u0026gt; Tensor: # output the features of four stages for dense prediction x = self.patch_embed(x) outs = [] for idx, stage in enumerate(self.stages): x = stage(x) if self.fork_feat and idx in self.out_indices: norm_layer = getattr(self, f'norm{idx}') x_out = norm_layer(x) outs.append(x_out) return outs if __name__ == \"__main__\": # Generating Sample image image_size = (1, 3, 640, 640) image = torch.rand(*image_size) # Model model = FasterNet() out = model(image) print(len(out))\rå››ã€æ‰‹æŠŠæ‰‹æ•™ä½ æ·»åŠ FasterNetæœºåˆ¶\r4.1 ä¿®æ”¹ä¸€\rç¬¬ä¸€æ­¥è¿˜æ˜¯å»ºç«‹æ–‡ä»¶ï¼Œæˆ‘ä»¬æ‰¾åˆ°å¦‚ä¸‹ultralytics/nnæ–‡ä»¶å¤¹ä¸‹å»ºç«‹ä¸€ä¸ªç›®å½•åå­—å‘¢å°±æ˜¯'Addmodules'æ–‡ä»¶å¤¹(\rç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€æ–°å»º)\rï¼ç„¶ååœ¨å…¶å†…éƒ¨å»ºç«‹ä¸€ä¸ªæ–°çš„pyæ–‡ä»¶å°†æ ¸å¿ƒä»£ç å¤åˆ¶ç²˜è´´è¿›å»å³å¯\r4.2 ä¿®æ”¹äºŒ\rç¬¬äºŒæ­¥æˆ‘ä»¬åœ¨è¯¥ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªæ–°çš„pyæ–‡ä»¶åå­—ä¸º'__init__.py'(\rç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€æ–°å»º)\rï¼Œç„¶ååœ¨å…¶å†…éƒ¨å¯¼å…¥æˆ‘ä»¬çš„æ£€æµ‹å¤´å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\r4.3 ä¿®æ”¹ä¸‰\rç¬¬ä¸‰æ­¥æˆ‘é—¨ä¸­åˆ°å¦‚ä¸‹æ–‡ä»¶'ultralytics/nn/tasks.py'è¿›è¡Œå¯¼å…¥å’Œæ³¨å†Œæˆ‘ä»¬çš„æ¨¡å—(\rç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€é‡æ–°å¯¼å…¥ç›´æ¥å¼€å§‹ç¬¬å››æ­¥å³å¯)\rï¼\rä»ä»Šå¤©å¼€å§‹ä»¥åçš„æ•™ç¨‹å°±éƒ½ç»Ÿä¸€æˆè¿™ä¸ªæ ·å­äº†ï¼Œå› ä¸ºæˆ‘é»˜è®¤å¤§å®¶ç”¨äº†æˆ‘ç¾¤å†…çš„æ–‡ä»¶æ¥è¿›è¡Œä¿®æ”¹ï¼ï¼\r4.4 ä¿®æ”¹å››\ræ·»åŠ å¦‚ä¸‹ä¸¤è¡Œä»£ç ï¼ï¼ï¼\râ€‹\r4.5 ä¿®æ”¹äº”\ræ‰¾åˆ°ä¸ƒç™¾å¤šè¡Œå¤§æ¦‚æŠŠå…·ä½“çœ‹å›¾ç‰‡ï¼ŒæŒ‰ç…§å›¾ç‰‡æ¥ä¿®æ”¹å°±è¡Œï¼Œæ·»åŠ çº¢æ¡†å†…çš„éƒ¨åˆ†ï¼Œæ³¨æ„æ²¡æœ‰()åªæ˜¯å‡½æ•°åã€‚\relif m in {è‡ªè¡Œæ·»åŠ å¯¹åº”çš„æ¨¡å‹å³å¯ï¼Œä¸‹é¢éƒ½æ˜¯ä¸€æ ·çš„}: m = m(*args) c2 = m.width_list # è¿”å›é€šé“åˆ—è¡¨ backbone = True\r4.6 ä¿®æ”¹å…­\rä¸‹é¢çš„ä¸¤ä¸ªçº¢æ¡†å†…éƒ½æ˜¯éœ€è¦æ”¹åŠ¨çš„ã€‚\râ€‹\rif isinstance(c2, list): m_ = m m_.backbone = True else: m_ = nn.Sequential(*(m(*args) for _ in range(n))) if n \u0026gt; 1 else m(*args) # module t = str(m)[8:-2].replace('__main__.', '') # module type m.np = sum(x.numel() for x in m_.parameters()) # number params m_.i, m_.f, m_.type = i + 4 if backbone else i, f, t # attach index, 'from' index, type\r4.7 ä¿®æ”¹ä¸ƒ\rå¦‚ä¸‹çš„ä¹Ÿéœ€è¦ä¿®æ”¹ï¼Œå…¨éƒ¨æŒ‰ç…§æˆ‘çš„æ¥ã€‚\râ€‹\rä»£ç å¦‚ä¸‹æŠŠåŸå…ˆçš„ä»£ç æ›¿æ¢äº†å³å¯ã€‚\rif verbose: LOGGER.info(f'{i:\u0026gt;3}{str(f):\u0026gt;20}{n_:\u0026gt;3}{m.np:10.0f} {t:\u0026lt;45}{str(args):\u0026lt;30}') # print save.extend(x % (i + 4 if backbone else i) for x in ([f] if isinstance(f, int) else f) if x != -1) # append to savelist layers.append(m_) if i == 0: ch = [] if isinstance(c2, list): ch.extend(c2) if len(c2) != 5: ch.insert(0, 0) else: ch.append(c2)\r4.8 ä¿®æ”¹å…«\rä¿®æ”¹å…«å’Œå‰é¢çš„éƒ½ä¸å¤ªä¸€æ ·ï¼Œéœ€è¦ä¿®æ”¹å‰å‘ä¼ æ’­ä¸­çš„ä¸€ä¸ªéƒ¨åˆ†ï¼ŒÂ å·²ç»ç¦»å¼€äº†parse_modelæ–¹æ³•äº†ã€‚\rå¯ä»¥åœ¨å›¾ç‰‡ä¸­å¼€ä»£ç è¡Œæ•°ï¼Œæ²¡æœ‰ç¦»å¼€task.pyæ–‡ä»¶éƒ½æ˜¯åŒä¸€ä¸ªæ–‡ä»¶ã€‚ åŒæ—¶è¿™ä¸ªéƒ¨åˆ†æœ‰å¥½å‡ ä¸ªå‰å‘ä¼ æ’­éƒ½å¾ˆç›¸ä¼¼ï¼Œå¤§å®¶ä¸è¦çœ‹é”™äº†ï¼Œ\ræ˜¯70å¤šè¡Œå·¦å³çš„ï¼ï¼ï¼ï¼ŒåŒæ—¶æˆ‘åé¢æä¾›äº†ä»£ç ï¼Œå¤§å®¶ç›´æ¥å¤åˆ¶ç²˜è´´å³å¯ï¼Œæœ‰æ—¶é—´æˆ‘é’ˆå¯¹è¿™é‡Œä¼šå‡ºä¸€ä¸ªè§†é¢‘ã€‚\râ€‹â€‹\rä»£ç å¦‚ä¸‹-\u0026gt;\rdef _predict_once(self, x, profile=False, visualize=False, embed=None): \"\"\" Perform a forward pass through the network. Args: x (torch.Tensor): The input tensor to the model. profile (bool): Print the computation time of each layer if True, defaults to False. visualize (bool): Save the feature maps of the model if True, defaults to False. embed (list, optional): A list of feature vectors/embeddings to return. Returns: (torch.Tensor): The last output of the model. \"\"\" y, dt, embeddings = [], [], [] # outputs for m in self.model: if m.f != -1: # if not from previous layer x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f] # from earlier layers if profile: self._profile_one_layer(m, x, dt) if hasattr(m, 'backbone'): x = m(x) if len(x) != 5: # 0 - 5 x.insert(0, None) for index, i in enumerate(x): if index in self.save: y.append(i) else: y.append(None) x = x[-1] # æœ€åä¸€ä¸ªè¾“å‡ºä¼ ç»™ä¸‹ä¸€å±‚ else: x = m(x) # run y.append(x if m.i in self.save else None) # save output if visualize: feature_visualization(x, m.type, m.i, save_dir=visualize) if embed and m.i in embed: embeddings.append(nn.functional.adaptive_avg_pool2d(x, (1, 1)).squeeze(-1).squeeze(-1)) # flatten if m.i == max(embed): return torch.unbind(torch.cat(embeddings, 1), dim=0) return x\råˆ°è¿™é‡Œå°±å®Œæˆäº†ä¿®æ”¹éƒ¨åˆ†ï¼Œä½†æ˜¯è¿™é‡Œé¢ç»†èŠ‚å¾ˆå¤šï¼Œå¤§å®¶åƒä¸‡è¦æ³¨æ„ä¸è¦æ›¿æ¢å¤šä½™çš„ä»£ç ï¼Œå¯¼è‡´æŠ¥é”™ï¼Œä¹Ÿä¸è¦æ‹‰ä¸‹ä»»ä½•ä¸€éƒ¨ï¼Œéƒ½ä¼šå¯¼è‡´è¿è¡Œå¤±è´¥ï¼Œè€Œä¸”æŠ¥é”™å¾ˆéš¾æ’æŸ¥ï¼ï¼ï¼å¾ˆéš¾æ’æŸ¥ï¼ï¼ï¼\ræ³¨æ„ï¼ï¼ï¼ é¢å¤–çš„ä¿®æ”¹ï¼\rå…³æ³¨æˆ‘çš„å…¶å®éƒ½çŸ¥é“ï¼Œæˆ‘å¤§éƒ¨åˆ†çš„ä¿®æ”¹éƒ½æ˜¯ä¸€æ ·çš„ï¼Œè¿™ä¸ªç½‘ç»œéœ€è¦é¢å¤–çš„ä¿®æ”¹ä¸€æ­¥ï¼Œå°±æ˜¯sä¸€ä¸ªå‚æ•°ï¼Œå°†ä¸‹é¢çš„sæ”¹ä¸º640ï¼ï¼ï¼å³å¯å®Œç¾è¿è¡Œï¼ï¼\ræ‰“å°è®¡ç®—é‡é—®é¢˜è§£å†³æ–¹æ¡ˆ\ræˆ‘ä»¬æ‰¾åˆ°å¦‚ä¸‹æ–‡ä»¶'ultralytics/utils/torch_utils.py'æŒ‰ç…§å¦‚ä¸‹çš„å›¾ç‰‡è¿›è¡Œä¿®æ”¹ï¼Œå¦åˆ™å®¹æ˜“æ‰“å°ä¸å‡ºæ¥è®¡ç®—é‡ã€‚\râ€‹\ræ³¨æ„äº‹é¡¹ï¼ï¼ï¼\rå¦‚æœå¤§å®¶åœ¨éªŒè¯çš„æ—¶å€™æŠ¥é”™å½¢çŠ¶ä¸åŒ¹é…çš„é”™è¯¯å¯ä»¥å›ºå®šéªŒè¯é›†çš„å›¾ç‰‡å°ºå¯¸ï¼Œæ–¹æ³•å¦‚ä¸‹Â -\u0026gt;\ræ‰¾åˆ°ä¸‹é¢è¿™ä¸ªæ–‡ä»¶ultralytics/models/yolo/detect/train.pyç„¶åå…¶ä¸­æœ‰ä¸€ä¸ªç±»æ˜¯DetectionTrainer classä¸­çš„build_datasetå‡½æ•°ä¸­çš„ä¸€ä¸ªå‚æ•°rect=mode == 'val'æ”¹ä¸ºrect=False\räº”ã€FasterNetçš„yamlæ–‡ä»¶\r5.1 FasterNetçš„yamlæ–‡ä»¶\rè®­ç»ƒä¿¡æ¯ï¼šYOLO11-FasterNet summary: 351 layers, 2,384,163 parameters, 2,384,147 gradients, 5.6 GFLOPs\rä½¿ç”¨è¯´æ˜ï¼š\r# ä¸‹é¢ [-1, 1, FasterNet, [0.25]] å‚æ•°ä½ç½®çš„0.25æ˜¯é€šé“æ”¾ç¼©çš„ç³»æ•°, YOLOv11Næ˜¯0.25 YOLOv11Sæ˜¯0.5 YOLOv11Mæ˜¯1. YOLOv11læ˜¯1 YOLOv11æ˜¯1.5å¤§å®¶æ ¹æ®è‡ªå·±è®­ç»ƒçš„YOLOç‰ˆæœ¬è®¾å®šå³å¯.\r# Ultralytics YOLO ğŸš€, AGPL-3.0 license# YOLO11 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect # Parametersnc: 80 # number of classesscales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n' # [depth, width, max_channels] n: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs s: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs m: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs l: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs x: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs # ä¸‹é¢ [-1, 1, FasterNet, [0.25]] å‚æ•°ä½ç½®çš„0.25æ˜¯é€šé“æ”¾ç¼©çš„ç³»æ•°, YOLOv11Næ˜¯0.25 YOLOv11Sæ˜¯0.5 YOLOv11Mæ˜¯1. YOLOv11læ˜¯1 YOLOv11æ˜¯1.5å¤§å®¶æ ¹æ®è‡ªå·±è®­ç»ƒçš„YOLOç‰ˆæœ¬è®¾å®šå³å¯.# YOLO11n backbonebackbone: # [from, repeats, module, args] - [-1, 1, FasterNet, [0.25]] # 0-4 P1/2 è¿™é‡Œæ˜¯å››å±‚å¤§å®¶ä¸è¦è¢«yamlæ–‡ä»¶é™åˆ¶ä½äº†æ€ç»´ï¼Œä¸ä¼šç”»å›¾è¿›ç¾¤çœ‹è§†é¢‘. - [-1, 1, SPPF, [1024, 5]] # 5 - [-1, 2, C2PSA, [1024]] # 6 # YOLO11n headhead: - [-1, 1, nn.Upsample, [None, 2, \"nearest\"]] - [[-1, 3], 1, Concat, [1]] # cat backbone P4 - [-1, 2, C3k2, [512, False]] # 9 - [-1, 1, nn.Upsample, [None, 2, \"nearest\"]] - [[-1, 2], 1, Concat, [1]] # cat backbone P3 - [-1, 2, C3k2, [256, False]] # 12 (P3/8-small) - [-1, 1, Conv, [256, 3, 2]] - [[-1, 9], 1, Concat, [1]] # cat head P4 - [-1, 2, C3k2, [512, False]] # 15 (P4/16-medium) - [-1, 1, Conv, [512, 3, 2]] - [[-1, 6], 1, Concat, [1]] # cat head P5 - [-1, 2, C3k2, [1024, True]] # 18 (P5/32-large) - [[12, 15, 18], 1, Detect, [nc]] # Detect(P3, P4, P5)\r5.2 è®­ç»ƒæ–‡ä»¶çš„ä»£ç \rå¯ä»¥å¤åˆ¶æˆ‘çš„è¿è¡Œæ–‡ä»¶è¿›è¡Œè¿è¡Œã€‚\rimport warningswarnings.filterwarnings('ignore')from ultralytics import YOLO if __name__ == '__main__': model = YOLO('yolov8-MLLA.yaml') # å¦‚ä½•åˆ‡æ¢æ¨¡å‹ç‰ˆæœ¬, ä¸Šé¢çš„ymalæ–‡ä»¶å¯ä»¥æ”¹ä¸º yolov8s.yamlå°±æ˜¯ä½¿ç”¨çš„v8s, # ç±»ä¼¼æŸä¸ªæ”¹è¿›çš„yamlæ–‡ä»¶åç§°ä¸ºyolov8-XXX.yamlé‚£ä¹ˆå¦‚æœæƒ³ä½¿ç”¨å…¶å®ƒç‰ˆæœ¬å°±æŠŠä¸Šé¢çš„åç§°æ”¹ä¸ºyolov8l-XXX.yamlå³å¯ï¼ˆæ”¹çš„æ˜¯ä¸Šé¢YOLOä¸­é—´çš„åå­—ä¸æ˜¯é…ç½®æ–‡ä»¶çš„ï¼‰ï¼ # model.load('yolov8n.pt') # æ˜¯å¦åŠ è½½é¢„è®­ç»ƒæƒé‡,ç§‘ç ”ä¸å»ºè®®å¤§å®¶åŠ è½½å¦åˆ™å¾ˆéš¾æå‡ç²¾åº¦ model.train(data=r\"C:\\Users\\Administrator\\PycharmProjects\\yolov5-master\\yolov5-master\\Construction Site Safety.v30-raw-images_latestversion.yolov8\\data.yaml\", # å¦‚æœå¤§å®¶ä»»åŠ¡æ˜¯å…¶å®ƒçš„'ultralytics/cfg/default.yaml'æ‰¾åˆ°è¿™é‡Œä¿®æ”¹taskå¯ä»¥æ”¹æˆdetect, segment, classify, pose cache=False, imgsz=640, epochs=150, single_cls=False, # æ˜¯å¦æ˜¯å•ç±»åˆ«æ£€æµ‹ batch=16, close_mosaic=0, workers=0, device='0', optimizer='SGD', # using SGD # resume='runs/train/exp21/weights/last.pt', # å¦‚è¿‡æƒ³ç»­è®­å°±è®¾ç½®last.ptçš„åœ°å€ amp=True, # å¦‚æœå‡ºç°è®­ç»ƒæŸå¤±ä¸ºNanå¯ä»¥å…³é—­amp project='runs/train', name='exp', )\rå…­ã€æˆåŠŸè¿è¡Œè®°å½•\rä¸‹é¢æ˜¯æˆåŠŸè¿è¡Œçš„æˆªå›¾ï¼Œå·²ç»å®Œæˆäº†æœ‰1ä¸ªepochsçš„è®­ç»ƒï¼Œå›¾ç‰‡å¤ªå¤§æˆªä¸å…¨ç¬¬2ä¸ªepochsäº†ã€‚\râ€‹\rä¸ƒã€æœ¬æ–‡æ€»ç»“\råˆ°æ­¤æœ¬æ–‡çš„æ­£å¼åˆ†äº«å†…å®¹å°±ç»“æŸäº†ï¼Œåœ¨è¿™é‡Œç»™å¤§å®¶æ¨èæˆ‘çš„YOLOv11æ”¹è¿›æœ‰æ•ˆæ¶¨ç‚¹ä¸“æ ï¼Œæœ¬ä¸“æ ç›®å‰ä¸ºæ–°å¼€çš„å¹³å‡è´¨é‡åˆ†98åˆ†ï¼ŒåæœŸæˆ‘ä¼šæ ¹æ®å„ç§æœ€æ–°çš„å‰æ²¿é¡¶ä¼šè¿›è¡Œè®ºæ–‡å¤ç°ï¼Œä¹Ÿä¼šå¯¹ä¸€äº›è€çš„æ”¹è¿›æœºåˆ¶è¿›è¡Œè¡¥å……\rï¼Œ\rå¦‚æœå¤§å®¶è§‰å¾—æœ¬æ–‡å¸®åŠ©åˆ°ä½ äº†ï¼Œè®¢é˜…æœ¬ä¸“æ ï¼Œå…³æ³¨åç»­æ›´å¤šçš„æ›´æ–°~\rä¸“æ å›é¡¾ï¼š\rYOLOv11æ”¹è¿›ç³»åˆ—ä¸“æ â€”â€”æœ¬ä¸“æ æŒç»­å¤ä¹ å„ç§é¡¶ä¼šå†…å®¹â€”â€”ç§‘ç ”å¿…å¤‡\râ€‹â€‹\ræ–‡ç« çŸ¥è¯†ç‚¹ä¸å®˜æ–¹çŸ¥è¯†æ¡£æ¡ˆåŒ¹é…ï¼Œå¯è¿›ä¸€æ­¥å­¦ä¹ ç›¸å…³çŸ¥è¯†\rOpenCVæŠ€èƒ½æ ‘\rOpenCVä¸­çš„æ·±åº¦å­¦ä¹ \rå›¾åƒåˆ†ç±»\r29518\räººæ­£åœ¨ç³»ç»Ÿå­¦ä¹ ä¸­\rç¡®å®šè¦æ”¾å¼ƒæœ¬æ¬¡æœºä¼šï¼Ÿ\rç¦åˆ©å€’è®¡æ—¶\r:\r:\rç«‹å‡ Â¥\ræ™®é€šVIPå¹´å¡å¯ç”¨\rç«‹å³ä½¿ç”¨\rç›®å½•\rä¸€ã€æœ¬æ–‡ä»‹ç»\räºŒã€FasterNetåŸç†\r2.1 FasterNetçš„åŸºæœ¬åŸç†\r2.2Â éƒ¨åˆ†å·ç§¯\r2.3Â åŠ é€Ÿç¥ç»ç½‘ç»œ\rä¸‰ã€FasterNetçš„æ ¸å¿ƒä»£ç \rå››ã€æ‰‹æŠŠæ‰‹æ•™ä½ æ·»åŠ FasterNetæœºåˆ¶\r4.1 ä¿®æ”¹ä¸€\r4.2 ä¿®æ”¹äºŒ\r4.3 ä¿®æ”¹ä¸‰\r4.4 ä¿®æ”¹å››\r4.5 ä¿®æ”¹äº”\r4.6 ä¿®æ”¹å…­\r4.7 ä¿®æ”¹ä¸ƒ\r4.8 ä¿®æ”¹å…«\ræ³¨æ„ï¼ï¼ï¼ é¢å¤–çš„ä¿®æ”¹ï¼\ræ‰“å°è®¡ç®—é‡é—®é¢˜è§£å†³æ–¹æ¡ˆ\ræ³¨æ„äº‹é¡¹ï¼ï¼ï¼\räº”ã€FasterNetçš„yamlæ–‡ä»¶\r5.1 FasterNetçš„yamlæ–‡ä»¶\r5.2 è®­ç»ƒæ–‡ä»¶çš„ä»£ç \rå…­ã€æˆåŠŸè¿è¡Œè®°å½•\rä¸ƒã€æœ¬æ–‡æ€»ç»“\rç¡®å®š\rå–æ¶ˆ\rä¸¾æŠ¥\ré€‰æ‹©ä½ æƒ³è¦ä¸¾æŠ¥çš„å†…å®¹ï¼ˆå¿…é€‰ï¼‰\rå†…å®¹æ¶‰é»„\ræ”¿æ²»ç›¸å…³\rå†…å®¹æŠ„è¢­\ræ¶‰å«Œå¹¿å‘Š\rå†…å®¹ä¾µæƒ\rä¾®è¾±è°©éª‚\ræ ·å¼é—®é¢˜\rå…¶ä»–\råŸæ–‡é“¾æ¥ï¼ˆå¿…å¡«ï¼‰\rè¯·é€‰æ‹©å…·ä½“åŸå› ï¼ˆå¿…é€‰ï¼‰\råŒ…å«ä¸å®ä¿¡æ¯\ræ¶‰åŠä¸ªäººéšç§\rè¯·é€‰æ‹©å…·ä½“åŸå› ï¼ˆå¿…é€‰ï¼‰\rä¾®è¾±è°©éª‚\rè¯½è°¤\rè¯·é€‰æ‹©å…·ä½“åŸå› ï¼ˆå¿…é€‰ï¼‰\ræ¬å®¶æ ·å¼\råšæ–‡æ ·å¼\rè¡¥å……è¯´æ˜ï¼ˆé€‰å¡«ï¼‰\rå–æ¶ˆ\rç¡®å®š\r","date":"0001-01-01T00:00:00Z","permalink":"https://nickk111.github.io/p/","title":""},{"content":"\rYOLOv11æ”¹è¿› | ä¸»å¹²/Backboneç¯‡ | è§†è§‰å˜æ¢å™¨SwinTransformerç›®æ ‡æ£€æµ‹ç½‘ç»œï¼ˆ é€‚é…yolov11å…¨ç³»åˆ—æ¨¡å‹ï¼‰_yolo11ä»£ç ä¸­transformeråœ¨æ¡†æ¶ä¸­çš„å“ªä¸ªéƒ¨åˆ†-CSDNåšå®¢\rYOLOv11æ”¹è¿› | ä¸»å¹²/Backboneç¯‡ | è§†è§‰å˜æ¢å™¨SwinTransformerç›®æ ‡æ£€æµ‹ç½‘ç»œï¼ˆ é€‚é…yolov11å…¨ç³»åˆ—æ¨¡å‹ï¼‰\rSnu77\rå·²äºÂ 2024-11-02 19:55:43Â ä¿®æ”¹\ré˜…è¯»é‡1.2k\ræ”¶è—\r32\rç‚¹èµæ•°\r24\råˆ†ç±»ä¸“æ ï¼š\rYOLOv11æœ‰æ•ˆæ¶¨ç‚¹ä¸“æ \ræ–‡ç« æ ‡ç­¾ï¼š\rYOLO\rç›®æ ‡æ£€æµ‹\ræ·±åº¦å­¦ä¹ \rè®¡ç®—æœºè§†è§‰\räººå·¥æ™ºèƒ½\rpython\rYOLOv11\r1024ç¨‹åºå‘˜èŠ‚\räºÂ 2024-10-24 22:45:32Â é¦–æ¬¡å‘å¸ƒ\rç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºåšä¸»åŸåˆ›æ–‡ç« ï¼Œéµå¾ª\rCC 4.0 BY-SA\rç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥å’Œæœ¬å£°æ˜ã€‚\ræœ¬æ–‡é“¾æ¥ï¼š\rhttps://blog.csdn.net/java1314777/article/details/143100866\rç‰ˆæƒ\rYOLOv11æœ‰æ•ˆæ¶¨ç‚¹ä¸“æ \rä¸“æ æ”¶å½•è¯¥å†…å®¹\r100 ç¯‡æ–‡ç« \r7 è®¢é˜…\rÂ¥159.90\rÂ¥299.90\rå·²è®¢é˜…\r8æŠ˜ç»­è´¹\ræ‚¨å·²æ˜¯è¶…çº§ä¼šå‘˜ï¼Œæ­£åœ¨å…è´¹é˜…è¯»ä¼šå‘˜ä¸“äº«å†…å®¹\ræŸ¥çœ‹æ›´å¤šè¶…çº§ä¼šå‘˜æƒç›Š\rä¸€ã€æœ¬æ–‡ä»‹ç»\ræœ¬æ–‡ç»™å¤§å®¶å¸¦æ¥çš„æ”¹è¿›æœºåˆ¶æ˜¯åˆ©ç”¨\rSwin Transformer\ræ›¿æ¢\rYOLOv11ä¸­çš„éª¨å¹²ç½‘ç»œ\rå…¶æ˜¯ä¸€ä¸ªå¼€åˆ›æ€§çš„è§†è§‰\rå˜æ¢å™¨\ræ¨¡å‹ï¼Œå®ƒé€šè¿‡ä½¿ç”¨ä½ç§»çª—å£æ¥æ„å»ºåˆ†å±‚çš„ç‰¹å¾å›¾ï¼Œæœ‰æ•ˆåœ°é€‚åº”äº†è®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚ä¸ä¼ ç»Ÿçš„å˜æ¢å™¨æ¨¡å‹ä¸åŒï¼ŒSwin Transformerçš„è‡ªæ³¨æ„åŠ›è®¡ç®—ä»…é™äºå±€éƒ¨çª—å£å†…ï¼Œä½¿å¾—\rè®¡ç®—å¤æ‚åº¦ä¸å›¾åƒå¤§å°æˆçº¿æ€§å…³ç³»ï¼Œè€ŒéäºŒæ¬¡æ–¹\rã€‚è¿™ç§è®¾è®¡ä¸ä»…æé«˜äº†æ¨¡å‹çš„æ•ˆç‡ï¼Œè¿˜ä¿æŒäº†å¼ºå¤§çš„ç‰¹å¾æå–èƒ½åŠ›ã€‚Swin Transformerçš„åˆ›æ–°åœ¨äºå…¶èƒ½å¤Ÿåœ¨ä¸åŒå±‚æ¬¡ä¸Šæ•æ‰å›¾åƒçš„ç»†èŠ‚å’Œå…¨å±€ä¿¡æ¯ï¼Œä½¿å…¶æˆä¸ºå„ç§è§†è§‰ä»»åŠ¡çš„å¼ºå¤§é€šç”¨éª¨å¹²ç½‘ç»œã€‚\räº²æµ‹åœ¨å°ç›®æ ‡æ£€æµ‹å’Œå¤§å°ºåº¦ç›®æ ‡æ£€æµ‹çš„æ•°æ®é›†ä¸Šéƒ½æœ‰æ¶¨ç‚¹æ•ˆæœã€‚\rï¼ˆæœ¬æ–‡å†…å®¹å¯æ ¹æ®yolov11çš„Nã€Sã€Mã€Lã€Xè¿›è¡ŒäºŒæ¬¡ç¼©æ”¾ï¼Œè½»é‡åŒ–æ›´ä¸Šä¸€å±‚ï¼‰\rä¸“æ å›é¡¾ï¼š\rYOLOv11æ”¹è¿›ç³»åˆ—ä¸“æ â€”â€”æœ¬ä¸“æ æŒç»­å¤ä¹ å„ç§é¡¶ä¼šå†…å®¹â€”â€”ç§‘ç ”å¿…å¤‡\rç›®å½•\rä¸€ã€æœ¬æ–‡ä»‹ç»\räºŒã€Swin TransformeråŸç†\r2.1Â Swin Transformerçš„åŸºæœ¬åŸç†\r2.2Â å±‚æ¬¡åŒ–ç‰¹å¾æ˜ å°„\r2.3Â å±€éƒ¨è‡ªæ³¨æ„åŠ›è®¡ç®—\r2.4Â ç§»åŠ¨çª—å£è‡ªæ³¨æ„åŠ›\r2.5Â ç§»åŠ¨çª—å£åˆ†åŒº\rä¸‰ã€Â Swin Transformerçš„å®Œæ•´ä»£ç \rå››ã€æ‰‹æŠŠæ‰‹æ•™ä½ æ·»åŠ Swin Transformerç½‘ç»œç»“æ„\rä¿®æ”¹ä¸€\rä¿®æ”¹äºŒ\rä¿®æ”¹ä¸‰\rä¿®æ”¹å››\rä¿®æ”¹äº”\rä¿®æ”¹å…­\rä¿®æ”¹ä¸ƒ\rä¿®æ”¹å…«\räº”ã€Swin Transformerçš„yamlæ–‡ä»¶\rå…­ã€æˆåŠŸè¿è¡Œè®°å½•\rä¸ƒã€æœ¬æ–‡æ€»ç»“\räºŒã€Swin TransformeråŸç†\rè®ºæ–‡åœ°å€ï¼š\rå®˜æ–¹è®ºæ–‡åœ°å€\rä»£ç åœ°å€ï¼š\rå®˜æ–¹ä»£ç ã€åœ°å€\r2.1\rSwin Transformerçš„åŸºæœ¬åŸç†\rSwin Transformer\ræ˜¯ä¸€ä¸ªæ–°çš„è§†è§‰å˜æ¢å™¨ï¼Œèƒ½å¤Ÿä½œä¸ºé€šç”¨çš„è®¡ç®—æœºè§†è§‰éª¨å¹²ç½‘ç»œã€‚è¿™ä¸ªæ¨¡å‹è§£å†³äº†å°†Transformerä»è¯­è¨€å¤„ç†é¢†åŸŸé€‚åº”åˆ°è§†è§‰ä»»åŠ¡ä¸­çš„æŒ‘æˆ˜ï¼Œä¸»è¦æ˜¯å› ä¸ºè¿™ä¸¤ä¸ªé¢†åŸŸä¹‹é—´å­˜åœ¨å·®å¼‚ï¼Œä¾‹å¦‚è§†è§‰å®ä½“çš„å°ºåº¦å˜åŒ–å¤§ï¼Œä»¥åŠå›¾åƒä¸­åƒç´ çš„é«˜åˆ†è¾¨ç‡ä¸æ–‡æœ¬ä¸­çš„å•è¯ç›¸æ¯”ã€‚ä¸‹å›¾å¯¹æ¯”å±•ç¤ºäº†Swin Transformerä¸Vision Transformer (ViT)çš„ä¸åŒä¹‹å¤„ï¼Œæ¸…æ¥šåœ°å±•ç¤ºäº†Swin Transformeråœ¨\ræ„å»ºç‰¹å¾æ˜ å°„å’Œå¤„ç†è®¡ç®—å¤æ‚åº¦æ–¹é¢\rçš„åˆ›æ–°ä¼˜åŠ¿ã€‚\r(a) Swin Transformerï¼š\ræå‡ºçš„Swin Transformeré€šè¿‡åœ¨æ›´æ·±å±‚æ¬¡åˆå¹¶å›¾åƒå°å—ï¼ˆç°è‰²éƒ¨åˆ†æ‰€ç¤ºï¼‰æ¥æ„å»ºå±‚æ¬¡åŒ–çš„ç‰¹å¾æ˜ å°„ã€‚åœ¨æ¯ä¸ªå±€éƒ¨çª—å£ï¼ˆçº¢è‰²éƒ¨åˆ†æ‰€ç¤ºï¼‰å†…åªè®¡ç®—è‡ªæ³¨æ„åŠ›ï¼Œå› æ­¤å®ƒå¯¹è¾“å…¥å›¾åƒå¤§å°æœ‰çº¿æ€§çš„è®¡ç®—å¤æ‚åº¦ã€‚å®ƒå¯ä»¥ä½œä¸ºé€šç”¨çš„éª¨å¹²ç½‘ç»œï¼Œç”¨äºå›¾åƒåˆ†ç±»å’Œå¯†é›†è¯†åˆ«ä»»åŠ¡ï¼Œå¦‚åˆ†å‰²å’Œæ£€æµ‹ã€‚\r(b) Vision Transformer (ViT)ï¼š\rä»¥å‰çš„è§†è§‰Transformeræ¨¡å‹ï¼ˆå¦‚ViTï¼‰äº§ç”Ÿå•ä¸€ä½åˆ†è¾¨ç‡çš„ç‰¹å¾æ˜ å°„ï¼Œå¹¶ä¸”ç”±äºå…¨å±€è‡ªæ³¨æ„åŠ›çš„è®¡ç®—ï¼Œå…¶è®¡ç®—å¤æ‚åº¦ä¸è¾“å…¥å›¾åƒå¤§å°å‘ˆäºŒæ¬¡æ–¹å…³ç³»ã€‚\ræˆ‘ä»¬å¯ä»¥å°†Swin Transformerçš„åŸºæœ¬åŸç†åˆ†ä¸ºä»¥ä¸‹å‡ ç‚¹ï¼š\r1. å±‚æ¬¡åŒ–ç‰¹å¾æ˜ å°„ï¼š\rSwin Transformeré€šè¿‡åˆå¹¶å›¾åƒçš„ç›¸é‚»å°å—ï¼ˆpatchesï¼‰ï¼Œåœ¨æ›´æ·±çš„Transformerå±‚æ¬¡ä¸­é€æ­¥æ„å»ºå±‚æ¬¡åŒ–çš„ç‰¹å¾æ˜ å°„ã€‚è¿™æ ·çš„å±‚æ¬¡åŒ–ç‰¹å¾æ˜ å°„å¯ä»¥æ–¹ä¾¿åœ°åˆ©ç”¨å¯†é›†é¢„æµ‹çš„é«˜çº§æŠ€æœ¯ï¼Œå¦‚ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œï¼ˆFeature Pyramid Networks, FPNï¼‰æˆ–U-Netã€‚\r2. å±€éƒ¨è‡ªæ³¨æ„åŠ›è®¡ç®—ï¼š\rä¸ºäº†å®ç°çº¿æ€§è®¡ç®—å¤æ‚æ€§ï¼ŒSwin Transformeråœ¨éé‡å çš„å±€éƒ¨çª—å£å†…è®¡ç®—è‡ªæ³¨æ„åŠ›ï¼Œè¿™äº›çª—å£æ˜¯é€šè¿‡åˆ’åˆ†å›¾åƒæ¥åˆ›å»ºçš„ã€‚æ¯ä¸ªçª—å£å†…çš„å°å—æ•°é‡æ˜¯å›ºå®šçš„ï¼Œå› æ­¤è®¡ç®—å¤æ‚æ€§ä¸å›¾åƒå¤§å°æˆçº¿æ€§å…³ç³»ã€‚\r3. ç§»åŠ¨çª—å£è‡ªæ³¨æ„åŠ›ï¼ˆShifted Window based Self-Attentionï¼‰ï¼š\ræ ‡å‡†çš„Transformeræ¶æ„åœ¨å…¨å±€èŒƒå›´å†…è®¡ç®—è‡ªæ³¨æ„åŠ›ï¼Œå³è®¡ç®—ä¸€ä¸ªæ ‡è®°ä¸æ‰€æœ‰å…¶ä»–æ ‡è®°ä¹‹é—´çš„å…³ç³»ã€‚è¿™ç§å…¨å±€è®¡ç®—å¯¼è‡´ä¸æ ‡è®°æ•°é‡æˆäºŒæ¬¡æ–¹çš„è®¡ç®—å¤æ‚æ€§ï¼Œä¸é€‚ç”¨äºè®¸å¤šéœ€è¦å¤„ç†å¤§è§„æ¨¡é«˜ç»´æ•°æ®çš„è§†è§‰é—®é¢˜ã€‚Swin Transformeré€šè¿‡ä¸€ä¸ªåŸºäºç§»åŠ¨çª—å£çš„å¤šå¤´è‡ªæ³¨æ„åŠ›ï¼ˆMSAï¼‰æ¨¡å—å–ä»£äº†ä¼ ç»Ÿçš„MSAæ¨¡å—ã€‚æ¯ä¸ªSwin Transformerå—ç”±ä¸€ä¸ªåŸºäºç§»åŠ¨çª—å£çš„MSAæ¨¡å—ç»„æˆï¼Œç„¶åæ˜¯ä¸¤å±‚å¸¦æœ‰GELUéçº¿æ€§çš„MLPï¼Œä¹‹å‰æ˜¯LayerNormï¼ˆLNï¼‰å±‚ï¼Œä¹‹åæ˜¯æ®‹å·®è¿æ¥ã€‚\r4. ç§»åŠ¨çª—å£åˆ†åŒºï¼š\rä¸ºäº†åœ¨è¿ç»­çš„Swin Transformerå—ä¸­å¼•å…¥è·¨çª—å£è¿æ¥çš„åŒæ—¶ä¿æŒéé‡å çª—å£çš„æœ‰æ•ˆè®¡ç®—ï¼Œæå‡ºäº†ä¸€ç§ç§»åŠ¨çª—å£åˆ†åŒºæ–¹æ³•ã€‚è¿™ç§æ–¹æ³•åœ¨è¿ç»­çš„å—ä¹‹é—´äº¤æ›¿ä½¿ç”¨ä¸¤ç§åˆ†åŒºé…ç½®ã€‚ç¬¬ä¸€ä¸ªæ¨¡å—ä½¿ç”¨å¸¸è§„çš„çª—å£åˆ†åŒºç­–ç•¥ï¼Œç„¶åä¸‹ä¸€ä¸ªæ¨¡å—é‡‡ç”¨çš„çª—å£é…ç½®ä¸å‰ä¸€å±‚ç›¸æ¯”ï¼Œé€šè¿‡ç§»åŠ¨çª—å£åç§»äº†ä¸€å®šè·ç¦»ï¼Œä»è€Œå®ç°çª—å£çš„äº¤æ›¿ã€‚\rä¸‹å›¾è¯¦ç»†å±•ç¤ºäº†\rSwin Transformerçš„æ¶æ„å’Œä¸¤ä¸ªè¿ç»­Swin Transformerå—çš„è®¾è®¡\rã€‚å›¾ä¸­çš„W-MSAå’ŒSW-MSAåˆ†åˆ«ä»£è¡¨å¸¦æœ‰å¸¸è§„å’Œç§»åŠ¨çª—å£é…ç½®çš„å¤šå¤´è‡ªæ³¨æ„åŠ›æ¨¡å—ã€‚è¿™ä¸¤ç§ç±»å‹çš„æ³¨æ„åŠ›æ¨¡å—äº¤æ›¿ä½¿ç”¨ï¼Œå…è®¸æ¨¡å‹åœ¨ä¿æŒå±€éƒ¨è®¡ç®—çš„åŒæ—¶ï¼Œä¹Ÿèƒ½å¤Ÿæ•æ‰æ›´å¹¿æ³›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\r(a) æ¶æ„ï¼ˆArchitectureï¼‰ï¼š\rå›¾å±•ç¤ºäº†Swin Transformerçš„å››ä¸ªé˜¶æ®µã€‚æ¯ä¸ªé˜¶æ®µéƒ½åŒ…å«è‹¥å¹²Swin Transformerå—ã€‚è¾“å…¥å›¾åƒé¦–å…ˆé€šè¿‡â€œPatch Partitionâ€è¢«åˆ’åˆ†æˆå°å—ï¼Œå¹¶é€šè¿‡â€œLinear Embeddingâ€è½¬æ¢æˆå‘é‡åºåˆ—ã€‚å„ä¸ªé˜¶æ®µé€šè¿‡â€œPatch Mergingâ€æ“ä½œé™ä½\rç‰¹å¾å›¾\rçš„åˆ†è¾¨ç‡ï¼ŒåŒæ—¶å¢åŠ ç‰¹å¾ç»´æ•°ï¼ˆä¾‹å¦‚ï¼Œç¬¬ä¸€é˜¶æ®µè¾“å‡ºçš„ç‰¹å¾ç»´æ•°ä¸ºCï¼Œç¬¬äºŒé˜¶æ®µä¸º2Cï¼Œä¾æ­¤ç±»æ¨ï¼‰ã€‚\r(b) ä¸¤ä¸ªè¿ç»­çš„Swin Transformerå—ï¼ˆTwo Successive Swin Transformer Blocksï¼‰ï¼š\ræ¯ä¸ªSwin Transformerå—ç”±å¤šå¤´è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼ˆW-MSAå’ŒSW-MSAï¼‰å’Œå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ç»„æˆï¼Œå…¶ä¸­W-MSAä½¿ç”¨å¸¸è§„çª—å£é…ç½®ï¼Œè€ŒSW-MSAä½¿ç”¨ç§»åŠ¨çª—å£é…ç½®ã€‚æ¯ä¸ªå—å†…éƒ¨ï¼Œå…ˆæ˜¯LayerNormï¼ˆLNï¼‰å±‚ï¼Œç„¶åæ˜¯è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œå†æ˜¯å¦ä¸€ä¸ªLayerNormå±‚ï¼Œæœ€åæ˜¯MLPã€‚å—ä¹‹é—´é€šè¿‡æ®‹å·®è¿æ¥è¿›è¡Œè¿æ¥ï¼Œè¿™æ ·çš„è®¾è®¡å¯ä»¥é¿å…æ·±å±‚ç½‘ç»œä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œå¹¶å…è®¸ä¿¡æ¯åœ¨ç½‘ç»œä¸­æ›´æœ‰æ•ˆåœ°æµåŠ¨ã€‚\r2.2\rå±‚æ¬¡åŒ–ç‰¹å¾æ˜ å°„\rå±‚æ¬¡åŒ–ç‰¹å¾æ˜ å°„å¯ä»¥ä½¿\rSwin Transformeræœ‰æ•ˆåœ°å¤„ç†ä¸åŒåˆ†è¾¨ç‡çš„ç‰¹å¾\rï¼Œå¹¶é€‚ç”¨äºå„ç§è§†è§‰ä»»åŠ¡ï¼Œå¦‚å›¾åƒåˆ†ç±»ã€å¯¹è±¡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ã€‚è¿™ç§å±‚æ¬¡åŒ–è®¾è®¡ä½¿Swin Transformerä¸ä»¥å¾€åŸºäºTransformerçš„æ¶æ„ï¼ˆè¿™äº›æ¶æ„äº§ç”Ÿå•ä¸€åˆ†è¾¨ç‡çš„ç‰¹å¾å›¾å¹¶å…·æœ‰äºŒæ¬¡æ–¹å¤æ‚åº¦ï¼‰å½¢æˆå¯¹æ¯”ï¼Œåè€…ä¸é€‚åˆéœ€è¦åœ¨åƒç´ çº§è¿›è¡Œå¯†é›†é¢„æµ‹çš„è§†è§‰ä»»åŠ¡ã€‚Swin Transformerçš„\rå±‚æ¬¡åŒ–ç‰¹å¾æ˜ å°„\rä¸»è¦é€šè¿‡ä»¥ä¸‹æ­¥éª¤å®ç°ï¼š\r1. åˆ†å—å’Œçº¿æ€§åµŒå…¥ï¼š\ré¦–å…ˆï¼Œè¾“å…¥å›¾åƒè¢«åˆ†å‰²æˆå°å—ï¼ˆé€šå¸¸æ˜¯4x4åƒç´ å¤§å°ï¼‰ï¼Œæ¯ä¸ªå°å—è¢«è§†ä¸ºä¸€ä¸ªâ€œæ ‡è®°â€ï¼Œå…¶ç‰¹å¾æ˜¯åŸå§‹åƒç´ RGBå€¼çš„ä¸²è”ã€‚ç„¶åï¼Œä¸€ä¸ªçº¿æ€§åµŒå…¥å±‚è¢«åº”ç”¨äºè¿™äº›åŸå§‹å€¼ç‰¹å¾ï¼Œå°†å…¶æŠ•å½±åˆ°ä»»æ„ç»´åº¦ï¼ˆè¡¨ç¤ºä¸ºCï¼‰ã€‚è¿™äº›æ­¥éª¤æ„æˆäº†æ‰€è°“çš„â€œç¬¬1é˜¶æ®µâ€ã€‚\r2. åˆ†å—åˆå¹¶ï¼š\réšç€ç½‘ç»œæ·±å…¥ï¼Œé€šè¿‡åˆå¹¶å±‚å‡å°‘æ ‡è®°çš„æ•°é‡ï¼Œä»è€Œé™ä½ç‰¹å¾å›¾çš„åˆ†è¾¨ç‡ã€‚ä¾‹å¦‚ï¼Œç¬¬ä¸€ä¸ªåˆå¹¶å±‚å°†æ¯ç»„2x2ç›¸é‚»å°å—çš„ç‰¹å¾åˆå¹¶ï¼Œå¹¶åº”ç”¨ä¸€ä¸ªçº¿æ€§å±‚åˆ°è¿™äº›4Cç»´åº¦çš„ä¸²è”ç‰¹å¾ä¸Šï¼Œè¿™æ ·åšå°†æ ‡è®°çš„æ•°é‡å‡å°‘äº†4å€ï¼ˆåˆ†è¾¨ç‡é™ä½äº†2å€ï¼‰ï¼Œå¹¶å°†è¾“å‡ºç»´åº¦è®¾ä¸º2Cã€‚è¿™ä¸ªè¿‡ç¨‹åœ¨åç»­çš„â€œç¬¬2é˜¶æ®µâ€ã€â€œç¬¬3é˜¶æ®µâ€å’Œâ€œç¬¬4é˜¶æ®µâ€ä¸­é‡å¤ï¼Œåˆ†åˆ«äº§ç”Ÿæ›´ä½åˆ†è¾¨ç‡çš„è¾“å‡ºã€‚\r3. å±‚æ¬¡åŒ–ç‰¹å¾å›¾ï¼š\ré€šè¿‡åœ¨æ›´æ·±çš„Transformerå±‚åˆå¹¶ç›¸é‚»å°å—ï¼ŒSwin Transformeræ„å»ºäº†å±‚æ¬¡åŒ–çš„ç‰¹å¾æ˜ å°„ã€‚è¿™äº›å±‚æ¬¡åŒ–ç‰¹å¾æ˜ å°„å…è®¸æ¨¡å‹æ–¹ä¾¿åœ°ä½¿ç”¨å¯†é›†é¢„æµ‹çš„é«˜çº§æŠ€æœ¯ï¼Œä¾‹å¦‚ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œï¼ˆFPNï¼‰æˆ–U-Netã€‚\r4. è®¡ç®—æ•ˆç‡ï¼š\rSwin Transformeråœ¨éé‡å çš„å±€éƒ¨çª—å£å†…å±€éƒ¨è®¡ç®—è‡ªæ³¨æ„åŠ›ï¼Œä»è€Œå®ç°äº†çº¿æ€§çš„è®¡ç®—å¤æ‚åº¦ã€‚æ¯ä¸ªçª—å£ä¸­çš„å°å—æ•°é‡æ˜¯å›ºå®šçš„ï¼Œå› æ­¤å¤æ‚åº¦ä¸å›¾åƒå¤§å°æˆçº¿æ€§å…³ç³»ã€‚\r2.3\rå±€éƒ¨è‡ªæ³¨æ„åŠ›è®¡ç®—\rSwin Transformerçš„å±€éƒ¨è‡ªæ³¨æ„åŠ›è®¡ç®—é€šè¿‡\råœ¨å°çª—å£å†…è®¡ç®—è‡ªæ³¨æ„åŠ›ä»¥åŠé€šè¿‡ç§»åŠ¨çª—å£åœ¨è¿ç»­å±‚ä¹‹é—´å¼•å…¥è·¨çª—å£çš„ä¿¡æ¯æµé€šï¼Œä½¿å¾—è®¡ç®—æ›´åŠ é«˜æ•ˆï¼ŒåŒæ—¶ä¿ç•™äº†æ¨¡å‹æ•æ‰é•¿è·ç¦»ä¾èµ–çš„èƒ½åŠ›ã€‚Swin Transformerä¸­çš„å±€éƒ¨è‡ªæ³¨æ„åŠ›è®¡ç®—æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å®ç°ï¼š\r1. æ›¿ä»£æ ‡å‡†å¤šå¤´è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼š\rSwin Transformerä½¿ç”¨åŸºäºç§»åŠ¨çª—å£çš„å¤šå¤´è‡ªæ³¨æ„åŠ›ï¼ˆMSAï¼‰æ¨¡å—æ›¿ä»£äº†ä¼ ç»ŸTransformerå—ä¸­çš„æ ‡å‡†å¤šå¤´è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œå…¶ä»–å±‚ä¿æŒä¸å˜ã€‚æ¯ä¸ªSwin Transformerå—ç”±ä¸€ä¸ªåŸºäºç§»åŠ¨çª—å£çš„MSAæ¨¡å—ç»„æˆï¼Œåè·Ÿä¸€ä¸ªä¸¤å±‚çš„MLPï¼Œä¸­é—´åŒ…å«GELUéçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚åœ¨æ¯ä¸ªMSAæ¨¡å—å’ŒMLPä¹‹å‰éƒ½ä¼šåº”ç”¨ä¸€ä¸ªLayerNormï¼ˆLNï¼‰å±‚ï¼Œæ¯ä¸ªæ¨¡å—ä¹‹åéƒ½ä¼šåº”ç”¨æ®‹å·®è¿æ¥ã€‚\r2. åœ¨å„ä¸ªçª—å£å†…è®¡ç®—è‡ªæ³¨æ„åŠ›ï¼š\råœ¨æ¯ä¸€å±‚ä¸­ï¼Œé‡‡ç”¨å¸¸è§„çš„çª—å£åˆ†åŒºæ–¹æ¡ˆï¼Œæ¯ä¸ªçª—å£å†…éƒ¨ç‹¬ç«‹è®¡ç®—è‡ªæ³¨æ„åŠ›ã€‚åœ¨ä¸‹ä¸€å±‚ä¸­ï¼Œçª—å£åˆ†åŒºä¼šå‘ç”Ÿç§»åŠ¨ï¼Œå½¢æˆæ–°çš„çª—å£ã€‚æ–°çª—å£ä¸­çš„è‡ªæ³¨æ„åŠ›è®¡ç®—ä¼šè·¨è¶Šä¹‹å‰å±‚ä¸­çª—å£çš„è¾¹ç•Œï¼Œå»ºç«‹å®ƒä»¬ä¹‹é—´çš„è¿æ¥ã€‚\r3. éé‡å çª—å£ä¸­çš„è‡ªæ³¨æ„åŠ›ï¼š\rä¸ºäº†æœ‰æ•ˆçš„å»ºæ¨¡ï¼ŒSwin Transformeråœ¨éé‡å çš„å±€éƒ¨çª—å£å†…è®¡ç®—è‡ªæ³¨æ„åŠ›ã€‚è¿™äº›çª—å£è¢«å®‰æ’ä»¥å‡åŒ€éé‡å çš„æ–¹å¼åˆ†å‰²å›¾åƒã€‚å‡è®¾æ¯ä¸ªçª—å£åŒ…å«MÃ—Mä¸ªå°å—ï¼Œå…¨å±€MSAæ¨¡å—å’ŒåŸºäºçª—å£çš„MSAæ¨¡å—çš„è®¡ç®—å¤æ‚åº¦åˆ†åˆ«ä¸ºäºŒæ¬¡æ–¹å’Œçº¿æ€§ï¼Œå½“Må›ºå®šæ—¶ï¼ˆé»˜è®¤è®¾ä¸º7ï¼‰ã€‚\r4. å¾ªç¯ä½ç§»å’Œæ©ç æœºåˆ¶ï¼š\ræå‡ºäº†ä¸€ç§é€šè¿‡å¾ªç¯ä½ç§»æ¥æé«˜æ‰¹é‡è®¡ç®—çš„æ•ˆç‡çš„æ–¹æ³•ã€‚é€šè¿‡è¿™ç§ä½ç§»ï¼Œä¸€ä¸ªæ‰¹æ¬¡çš„çª—å£å¯èƒ½ç”±å‡ ä¸ªåœ¨ç‰¹å¾å›¾ä¸­ä¸ç›¸é‚»çš„å­çª—å£ç»„æˆï¼Œå› æ­¤é‡‡ç”¨æ©ç æœºåˆ¶é™åˆ¶åœ¨æ¯ä¸ªå­çª—å£å†…è®¡ç®—è‡ªæ³¨æ„åŠ›ã€‚è¿™ç§å¾ªç¯ä½ç§»ä¿æŒäº†æ‰¹æ¬¡çª—å£çš„æ•°é‡ä¸å¸¸è§„çª—å£åˆ†åŒºç›¸åŒã€‚\r5. çª—å£é—´çš„ä½ç§»ï¼š\rä¸ºäº†åœ¨è¿ç»­å±‚ä¹‹é—´å®ç°æ›´é«˜æ•ˆçš„ç¡¬ä»¶å®ç°ï¼ŒSwin Transformeræå‡ºåœ¨è¿ç»­å±‚ä¹‹é—´ä½ç§»çª—å£ï¼Œè¿™æ ·çš„ä½ç§»å…è®¸è·¨çª—å£çš„è¿æ¥ï¼ŒåŒæ—¶ç»´æŒè®¡ç®—çš„é«˜æ•ˆæ€§ã€‚\r6. ç›¸å¯¹ä½ç½®åç½®ï¼š\råœ¨è®¡ç®—è‡ªæ³¨æ„åŠ›æ—¶ï¼ŒSwin TransformeråŒ…æ‹¬äº†ç›¸å¯¹ä½ç½®åç½®Bï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹ä¸åŒä½ç½®ä¹‹é—´å…³ç³»çš„å­¦ä¹ èƒ½åŠ›ã€‚\r2.4\rç§»åŠ¨çª—å£è‡ªæ³¨æ„åŠ›\rç§»åŠ¨çª—å£è‡ªæ³¨æ„åŠ›æ˜¯Swin Transformerè®¾è®¡çš„æ ¸å¿ƒå…ƒç´ ï¼Œå®ƒ\ré€šè¿‡åœ¨å±€éƒ¨çª—å£å†…è®¡ç®—è‡ªæ³¨æ„åŠ›\rå¹¶åœ¨è¿ç»­å±‚ä¹‹é—´å¼•å…¥çª—å£ä½ç§»ï¼Œä»¥å®ç°é«˜æ•ˆçš„è®¡ç®—å’Œå¼ºå¤§çš„å»ºæ¨¡èƒ½åŠ›ã€‚åœ¨Swin Transformerè®ºæ–‡ä¸­ï¼Œç§»åŠ¨çª—å£è‡ªæ³¨æ„åŠ›ï¼ˆshifted window self-attentionï¼‰çš„\rä¸»è¦ç‰¹ç‚¹\råŒ…æ‹¬ï¼š\r1. æ›¿ä»£å¤šå¤´è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼š\råœ¨Swin Transformerå—ä¸­ï¼Œæ ‡å‡†çš„\rå¤šå¤´è‡ªæ³¨æ„åŠ›ï¼ˆMSAï¼‰æ¨¡å—\rè¢«åŸºäºç§»åŠ¨çª—å£çš„MSAæ¨¡å—æ›¿æ¢ã€‚è¿™ç§åŸºäºç§»åŠ¨çª—å£çš„MSAæ¨¡å—åè·Ÿä¸€ä¸ªä¸¤å±‚çš„MLPï¼Œä¸­é—´æœ‰GELUéçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚æ¯ä¸ªMSAæ¨¡å—å’ŒMLPä¹‹å‰éƒ½ä¼šåº”ç”¨ä¸€ä¸ªLayerNormï¼ˆLNï¼‰å±‚ï¼Œæ¯ä¸ªæ¨¡å—ä¹‹åéƒ½ä¼šåº”ç”¨æ®‹å·®è¿æ¥ã€‚\r2. ç§»åŠ¨çª—å£åˆ†åŒºï¼š\råœ¨è¿ç»­çš„Swin Transformerå—ä¸­ï¼Œçª—å£åˆ†åŒºç­–ç•¥åœ¨æ¯ä¸€å±‚ä¹‹é—´äº¤æ›¿ã€‚åœ¨æŸä¸€å±‚ä¸­ï¼Œé‡‡ç”¨å¸¸è§„çª—å£åˆ†åŒºï¼Œè€Œåœ¨ä¸‹ä¸€å±‚ä¸­ï¼Œçª—å£åˆ†åŒºä¼šå‘ç”Ÿç§»åŠ¨ï¼Œä»è€Œå½¢æˆæ–°çš„çª—å£ã€‚è¿™ç§ç§»åŠ¨çª—å£åˆ†åŒºæ–¹æ³•èƒ½å¤Ÿè·¨è¶Šå‰ä¸€å±‚ä¸­çª—å£çš„è¾¹ç•Œï¼Œæä¾›çª—å£é—´çš„è¿æ¥ã€‚\r3. äº¤æ›¿åˆ†åŒºé…ç½®ï¼š\rç§»åŠ¨çª—å£åˆ†åŒºæ–¹æ³•åœ¨è¿ç»­çš„Swin Transformerå—ä¸­äº¤æ›¿ä½¿ç”¨ä¸¤ç§åˆ†åŒºé…ç½®ã€‚ä¾‹å¦‚ï¼Œç¬¬ä¸€ä¸ªæ¨¡å—ä»å·¦ä¸Šè§’åƒç´ å¼€å§‹ä½¿ç”¨å¸¸è§„çª—å£åˆ†åŒºç­–ç•¥ï¼Œæ¥ç€ä¸‹ä¸€ä¸ªæ¨¡å—é‡‡ç”¨çš„çª—å£é…ç½®å°†ä¸å‰ä¸€å±‚ç›¸æ¯”ç§»åŠ¨ä¸€å®šè·ç¦»ã€‚\r4. ç§»åŠ¨çª—å£è‡ªæ³¨æ„åŠ›çš„è®¡ç®—ï¼š\rç§»åŠ¨çª—å£è‡ªæ³¨æ„åŠ›è®¡ç®—çš„æœ‰æ•ˆæ€§ä¸ä»…åœ¨å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸­å¾—åˆ°äº†éªŒè¯ï¼Œè€Œä¸”å®ƒçš„å®ç°ä¹Ÿè¢«è¯æ˜åœ¨æ‰€æœ‰MLPæ¶æ„ä¸­æœ‰ç›Šã€‚\r5. æ•ˆç‡ï¼š\rç›¸æ¯”äºæ»‘åŠ¨çª—å£æ–¹æ³•ï¼Œç§»åŠ¨çª—å£æ–¹æ³•å…·æœ‰æ›´ä½çš„å»¶è¿Ÿï¼Œä½†åœ¨å»ºæ¨¡èƒ½åŠ›ä¸Šå´ç›¸ä¼¼ã€‚æ­¤å¤–ï¼Œç§»åŠ¨çª—å£æ–¹æ³•ä¹Ÿæœ‰åŠ©äºæé«˜æ‰¹é‡è®¡ç®—çš„æ•ˆç‡ã€‚\r6. è¿ç»­å—çš„è®¡ç®—ï¼š\råœ¨ç§»åŠ¨çª—å£åˆ†åŒºæ–¹æ³•ä¸­ï¼Œè¿ç»­çš„Swin Transformerå—çš„\rè®¡ç®—æ–¹å¼\rå¦‚ä¸‹ï¼š\rï¼Œç„¶åæ˜¯MLPå±‚ï¼Œä¹‹åæ˜¯\rã€‚è¿™é‡Œï¼Œ\rå’Œ\råˆ†åˆ«ä»£è¡¨å—lçš„(S)W-MSAæ¨¡å—å’ŒMLPæ¨¡å—çš„è¾“å‡ºç‰¹å¾ã€‚\rä¸‹é¢æˆ‘ç»™å¤§å®¶å±•ç¤ºäº†æ‰€æå‡ºçš„Swin Transformeræ¶æ„ä¸­ç”¨äº\rè®¡ç®—è‡ªæ³¨æ„åŠ›çš„ç§»åŠ¨çª—å£æ–¹æ³•\rã€‚\råœ¨ç¬¬lå±‚ï¼ˆå·¦ä¾§ï¼‰ï¼Œé‡‡ç”¨äº†å¸¸è§„çª—å£åˆ’åˆ†æ–¹æ¡ˆï¼Œå¹¶ä¸”åœ¨æ¯ä¸ªçª—å£å†…è®¡ç®—è‡ªæ³¨æ„åŠ›ã€‚åœ¨æ¥ä¸‹æ¥çš„ç¬¬l+1å±‚ï¼ˆå³ä¾§ï¼‰ï¼Œçª—å£åˆ’åˆ†è¢«ç§»åŠ¨ï¼Œç»“æœåœ¨æ–°çš„çª—å£ä¸­è¿›è¡Œäº†è‡ªæ³¨æ„åŠ›è®¡ç®—ã€‚è¿™äº›æ–°çª—å£ä¸­çš„è‡ªæ³¨æ„åŠ›è®¡ç®—è·¨è¶Šäº†lå±‚ä¸­ä¹‹å‰çª—å£çš„è¾¹ç•Œï¼Œæä¾›äº†å®ƒä»¬ä¹‹é—´çš„è¿æ¥ã€‚è¿™ç§ç§»åŠ¨çª—å£æ–¹æ³•æé«˜äº†æ•ˆç‡ï¼Œ\rå› ä¸ºå®ƒé™åˆ¶äº†è‡ªæ³¨æ„åŠ›è®¡ç®—åœ¨éé‡å çš„å±€éƒ¨çª—å£å†…ï¼ŒåŒæ—¶å…è®¸çª—å£é—´çš„äº¤å‰è¿æ¥ã€‚\r2.5\rç§»åŠ¨çª—å£åˆ†åŒº\rç§»åŠ¨çª—å£åˆ†åŒºæ˜¯Swin Transformerä¸­ä¸€é¡¹å…³é”®çš„åˆ›æ–°ï¼Œå®ƒ\ré€šè¿‡åœ¨è¿ç»­å±‚ä¹‹é—´äº¤æ›¿çª—å£çš„åˆ†åŒºæ–¹å¼\rï¼Œ\ræœ‰æ•ˆåœ°ä¿ƒè¿›äº†ä¿¡æ¯åœ¨çª—å£ä¹‹é—´çš„æµåŠ¨ï¼ŒåŒæ—¶ä¿æŒäº†å¤„ç†é«˜åˆ†è¾¨ç‡å›¾åƒæ—¶çš„è®¡ç®—æ•ˆç‡ã€‚ä¸‹é¢æˆ‘å°†é€šè¿‡å›¾ç‰‡\rè§£é‡Šå¦‚ä½•ä½¿ç”¨å¾ªç¯ä½ç§»æ¥è®¡ç®—åœ¨ç§»åŠ¨çª—å£ä¸­çš„è‡ªæ³¨æ„åŠ›ï¼Œä»¥åŠå¦‚ä½•é«˜æ•ˆåœ°å®æ–½è¿™ä¸€è®¡ç®—\rã€‚\rï¼ˆ1ï¼‰çª—å£åˆ†åŒºï¼ˆWindow partitionï¼‰ï¼š\ré¦–å…ˆï¼Œå›¾åƒè¢«åˆ†æˆå¤šä¸ªçª—å£ã€‚\rï¼ˆ2ï¼‰å¾ªç¯ä½ç§»ï¼ˆCyclic shiftï¼‰ï¼š\ræ¥ç€ï¼Œä¸ºäº†è®¡ç®—è‡ªæ³¨æ„åŠ›ï¼Œçª—å£å†…çš„åƒç´ æˆ–ç‰¹å¾ä¼šè¿›è¡Œå¾ªç¯ä½ç§»ã€‚è¿™æ ·å¯ä»¥å°†æœ¬æ¥ä¸ç›¸é‚»çš„åƒç´ æˆ–ç‰¹å¾æš‚æ—¶æ€§åœ°æ’åˆ—åˆ°åŒä¸€ä¸ªçª—å£å†…ï¼Œä½¿å¾—å¯ä»¥åœ¨å±€éƒ¨çª—å£ä¸­è®¡ç®—åŸæœ¬è·¨çª—å£çš„è‡ªæ³¨æ„åŠ›ã€‚\rï¼ˆ3ï¼‰æ©ç å¤šå¤´è‡ªæ³¨æ„åŠ›ï¼ˆMasked MSAï¼‰ï¼š\råœ¨ç»è¿‡å¾ªç¯ä½ç§»åï¼Œå¯ä»¥åœ¨è¿™äº›ä¸´æ—¶å½¢æˆçš„çª—å£ä¸Šæ‰§è¡Œæ©ç å¤šå¤´è‡ªæ³¨æ„åŠ›æ“ä½œï¼Œä»¥æ­¤è®¡ç®—æ³¨æ„åŠ›å¾—åˆ†å’Œæ›´æ–°ç‰¹å¾ã€‚\rï¼ˆ4ï¼‰é€†å¾ªç¯ä½ç§»ï¼ˆReverse cyclic shiftï¼‰ï¼š\rå®Œæˆè‡ªæ³¨æ„åŠ›è®¡ç®—åï¼Œç‰¹å¾ä¼šè¿›è¡Œé€†å¾ªç¯ä½ç§»ï¼Œæ¢å¤åˆ°å®ƒä»¬åŸæ¥åœ¨å›¾åƒä¸­çš„ä½ç½®ã€‚\rä¸‰ã€Â Swin Transformerçš„å®Œæ•´ä»£ç \rimport torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.utils.checkpoint as checkpointimport numpy as npfrom timm.models.layers import DropPath, to_2tuple, trunc_normal_ __all__ = ['SwinTransformer'] class Mlp(nn.Module): \"\"\" Multilayer perceptron.\"\"\" def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.): super().__init__() out_features = out_features or in_features hidden_features = hidden_features or in_features self.fc1 = nn.Linear(in_features, hidden_features) self.act = act_layer() self.fc2 = nn.Linear(hidden_features, out_features) self.drop = nn.Dropout(drop) def forward(self, x): x = self.fc1(x) x = self.act(x) x = self.drop(x) x = self.fc2(x) x = self.drop(x) return x def window_partition(x, window_size): \"\"\" Args: x: (B, H, W, C) window_size (int): window size Returns: windows: (num_windows*B, window_size, window_size, C) \"\"\" B, H, W, C = x.shape x = x.view(B, H // window_size, window_size, W // window_size, window_size, C) windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C) return windows def window_reverse(windows, window_size, H, W): \"\"\" Args: windows: (num_windows*B, window_size, window_size, C) window_size (int): Window size H (int): Height of image W (int): Width of image Returns: x: (B, H, W, C) \"\"\" B = int(windows.shape[0] / (H * W / window_size / window_size)) x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1) x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1) return x class WindowAttention(nn.Module): \"\"\" Window based multi-head self attention (W-MSA) module with relative position bias. It supports both of shifted and non-shifted window. Args: dim (int): Number of input channels. window_size (tuple[int]): The height and width of the window. num_heads (int): Number of attention heads. qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0 proj_drop (float, optional): Dropout ratio of output. Default: 0.0 \"\"\" def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.): super().__init__() self.dim = dim self.window_size = window_size # Wh, Ww self.num_heads = num_heads head_dim = dim // num_heads self.scale = qk_scale or head_dim ** -0.5 # define a parameter table of relative position bias self.relative_position_bias_table = nn.Parameter( torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads)) # 2*Wh-1 * 2*Ww-1, nH # get pair-wise relative position index for each token inside the window coords_h = torch.arange(self.window_size[0]) coords_w = torch.arange(self.window_size[1]) coords = torch.stack(torch.meshgrid([coords_h, coords_w])) # 2, Wh, Ww coords_flatten = torch.flatten(coords, 1) # 2, Wh*Ww relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :] # 2, Wh*Ww, Wh*Ww relative_coords = relative_coords.permute(1, 2, 0).contiguous() # Wh*Ww, Wh*Ww, 2 relative_coords[:, :, 0] += self.window_size[0] - 1 # shift to start from 0 relative_coords[:, :, 1] += self.window_size[1] - 1 relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1 relative_position_index = relative_coords.sum(-1) # Wh*Ww, Wh*Ww self.register_buffer(\"relative_position_index\", relative_position_index) self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias) self.attn_drop = nn.Dropout(attn_drop) self.proj = nn.Linear(dim, dim) self.proj_drop = nn.Dropout(proj_drop) trunc_normal_(self.relative_position_bias_table, std=.02) self.softmax = nn.Softmax(dim=-1) def forward(self, x, mask=None): \"\"\" Forward function. Args: x: input features with shape of (num_windows*B, N, C) mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None \"\"\" B_, N, C = x.shape qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4) q, k, v = qkv[0], qkv[1], qkv[2] # make torchscript happy (cannot use tensor as tuple) q = q * self.scale attn = (q @ k.transpose(-2, -1)) relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view( self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1) # Wh*Ww,Wh*Ww,nH relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous() # nH, Wh*Ww, Wh*Ww attn = attn + relative_position_bias.unsqueeze(0) if mask is not None: nW = mask.shape[0] attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0) attn = attn.view(-1, self.num_heads, N, N) attn = self.softmax(attn) else: attn = self.softmax(attn) attn = self.attn_drop(attn) x = (attn @ v).transpose(1, 2).reshape(B_, N, C) x = self.proj(x) x = self.proj_drop(x) return x class SwinTransformerBlock(nn.Module): \"\"\" Swin Transformer Block. Args: dim (int): Number of input channels. num_heads (int): Number of attention heads. window_size (int): Window size. shift_size (int): Shift size for SW-MSA. mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set. drop (float, optional): Dropout rate. Default: 0.0 attn_drop (float, optional): Attention dropout rate. Default: 0.0 drop_path (float, optional): Stochastic depth rate. Default: 0.0 act_layer (nn.Module, optional): Activation layer. Default: nn.GELU norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm \"\"\" def __init__(self, dim, num_heads, window_size=7, shift_size=0, mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm): super().__init__() self.dim = dim self.num_heads = num_heads self.window_size = window_size self.shift_size = shift_size self.mlp_ratio = mlp_ratio assert 0 \u0026lt;= self.shift_size \u0026lt; self.window_size, \"shift_size must in 0-window_size\" self.norm1 = norm_layer(dim) self.attn = WindowAttention( dim, window_size=to_2tuple(self.window_size), num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop) self.drop_path = DropPath(drop_path) if drop_path \u0026gt; 0. else nn.Identity() self.norm2 = norm_layer(dim) mlp_hidden_dim = int(dim * mlp_ratio) self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop) self.H = None self.W = None def forward(self, x, mask_matrix): \"\"\" Forward function. Args: x: Input feature, tensor size (B, H*W, C). H, W: Spatial resolution of the input feature. mask_matrix: Attention mask for cyclic shift. \"\"\" B, L, C = x.shape H, W = self.H, self.W assert L == H * W, \"input feature has wrong size\" shortcut = x x = self.norm1(x) x = x.view(B, H, W, C) # pad feature maps to multiples of window size pad_l = pad_t = 0 pad_r = (self.window_size - W % self.window_size) % self.window_size pad_b = (self.window_size - H % self.window_size) % self.window_size x = F.pad(x, (0, 0, pad_l, pad_r, pad_t, pad_b)) _, Hp, Wp, _ = x.shape # cyclic shift if self.shift_size \u0026gt; 0: shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2)) attn_mask = mask_matrix.type(x.dtype) else: shifted_x = x attn_mask = None # partition windows x_windows = window_partition(shifted_x, self.window_size) # nW*B, window_size, window_size, C x_windows = x_windows.view(-1, self.window_size * self.window_size, C) # nW*B, window_size*window_size, C # W-MSA/SW-MSA attn_windows = self.attn(x_windows, mask=attn_mask) # nW*B, window_size*window_size, C # merge windows attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C) shifted_x = window_reverse(attn_windows, self.window_size, Hp, Wp) # B H' W' C # reverse cyclic shift if self.shift_size \u0026gt; 0: x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2)) else: x = shifted_x if pad_r \u0026gt; 0 or pad_b \u0026gt; 0: x = x[:, :H, :W, :].contiguous() x = x.view(B, H * W, C) # FFN x = shortcut + self.drop_path(x) x = x + self.drop_path(self.mlp(self.norm2(x))) return x class PatchMerging(nn.Module): \"\"\" Patch Merging Layer Args: dim (int): Number of input channels. norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm \"\"\" def __init__(self, dim, norm_layer=nn.LayerNorm): super().__init__() self.dim = dim self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False) self.norm = norm_layer(4 * dim) def forward(self, x, H, W): \"\"\" Forward function. Args: x: Input feature, tensor size (B, H*W, C). H, W: Spatial resolution of the input feature. \"\"\" B, L, C = x.shape assert L == H * W, \"input feature has wrong size\" x = x.view(B, H, W, C) # padding pad_input = (H % 2 == 1) or (W % 2 == 1) if pad_input: x = F.pad(x, (0, 0, 0, W % 2, 0, H % 2)) x0 = x[:, 0::2, 0::2, :] # B H/2 W/2 C x1 = x[:, 1::2, 0::2, :] # B H/2 W/2 C x2 = x[:, 0::2, 1::2, :] # B H/2 W/2 C x3 = x[:, 1::2, 1::2, :] # B H/2 W/2 C x = torch.cat([x0, x1, x2, x3], -1) # B H/2 W/2 4*C x = x.view(B, -1, 4 * C) # B H/2*W/2 4*C x = self.norm(x) x = self.reduction(x) return x class BasicLayer(nn.Module): \"\"\" A basic Swin Transformer layer for one stage. Args: dim (int): Number of feature channels depth (int): Depths of this stage. num_heads (int): Number of attention head. window_size (int): Local window size. Default: 7. mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4. qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set. drop (float, optional): Dropout rate. Default: 0.0 attn_drop (float, optional): Attention dropout rate. Default: 0.0 drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0 norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False. \"\"\" def __init__(self, dim, depth, num_heads, window_size=7, mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0., norm_layer=nn.LayerNorm, downsample=None, use_checkpoint=False): super().__init__() self.window_size = window_size self.shift_size = window_size // 2 self.depth = depth self.use_checkpoint = use_checkpoint # build blocks self.blocks = nn.ModuleList([ SwinTransformerBlock( dim=dim, num_heads=num_heads, window_size=window_size, shift_size=0 if (i % 2 == 0) else window_size // 2, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale, drop=drop, attn_drop=attn_drop, drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path, norm_layer=norm_layer) for i in range(depth)]) # patch merging layer if downsample is not None: self.downsample = downsample(dim=dim, norm_layer=norm_layer) else: self.downsample = None def forward(self, x, H, W): \"\"\" Forward function. Args: x: Input feature, tensor size (B, H*W, C). H, W: Spatial resolution of the input feature. \"\"\" # calculate attention mask for SW-MSA Hp = int(np.ceil(H / self.window_size)) * self.window_size Wp = int(np.ceil(W / self.window_size)) * self.window_size img_mask = torch.zeros((1, Hp, Wp, 1), device=x.device) # 1 Hp Wp 1 h_slices = (slice(0, -self.window_size), slice(-self.window_size, -self.shift_size), slice(-self.shift_size, None)) w_slices = (slice(0, -self.window_size), slice(-self.window_size, -self.shift_size), slice(-self.shift_size, None)) cnt = 0 for h in h_slices: for w in w_slices: img_mask[:, h, w, :] = cnt cnt += 1 mask_windows = window_partition(img_mask, self.window_size) # nW, window_size, window_size, 1 mask_windows = mask_windows.view(-1, self.window_size * self.window_size) attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2) attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0)) for blk in self.blocks: blk.H, blk.W = H, W if self.use_checkpoint: x = checkpoint.checkpoint(blk, x, attn_mask) else: x = blk(x, attn_mask) if self.downsample is not None: x_down = self.downsample(x, H, W) Wh, Ww = (H + 1) // 2, (W + 1) // 2 return x, H, W, x_down, Wh, Ww else: return x, H, W, x, H, W class PatchEmbed(nn.Module): \"\"\" Image to Patch Embedding Args: patch_size (int): Patch token size. Default: 4. in_chans (int): Number of input image channels. Default: 3. embed_dim (int): Number of linear projection output channels. Default: 96. norm_layer (nn.Module, optional): Normalization layer. Default: None \"\"\" def __init__(self, patch_size=4, in_chans=3, embed_dim=96, norm_layer=None): super().__init__() patch_size = to_2tuple(patch_size) self.patch_size = patch_size self.in_chans = in_chans self.embed_dim = embed_dim self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size) if norm_layer is not None: self.norm = norm_layer(embed_dim) else: self.norm = None def forward(self, x): \"\"\"Forward function.\"\"\" # padding _, _, H, W = x.size() if W % self.patch_size[1] != 0: x = F.pad(x, (0, self.patch_size[1] - W % self.patch_size[1])) if H % self.patch_size[0] != 0: x = F.pad(x, (0, 0, 0, self.patch_size[0] - H % self.patch_size[0])) x = self.proj(x) # B C Wh Ww if self.norm is not None: Wh, Ww = x.size(2), x.size(3) x = x.flatten(2).transpose(1, 2) x = self.norm(x) x = x.transpose(1, 2).view(-1, self.embed_dim, Wh, Ww) return x class SwinTransformer(nn.Module): \"\"\" Swin Transformer backbone. A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows` - https://arxiv.org/pdf/2103.14030 Args: pretrain_img_size (int): Input image size for training the pretrained model, used in absolute postion embedding. Default 224. patch_size (int | tuple(int)): Patch size. Default: 4. in_chans (int): Number of input image channels. Default: 3. embed_dim (int): Number of linear projection output channels. Default: 96. depths (tuple[int]): Depths of each Swin Transformer stage. num_heads (tuple[int]): Number of attention head of each stage. window_size (int): Window size. Default: 7. mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4. qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True qk_scale (float): Override default qk scale of head_dim ** -0.5 if set. drop_rate (float): Dropout rate. attn_drop_rate (float): Attention dropout rate. Default: 0. drop_path_rate (float): Stochastic depth rate. Default: 0.2. norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm. ape (bool): If True, add absolute position embedding to the patch embedding. Default: False. patch_norm (bool): If True, add normalization after patch embedding. Default: True. out_indices (Sequence[int]): Output from which stages. frozen_stages (int): Stages to be frozen (stop grad and set eval mode). -1 means not freezing any parameters. use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False. \"\"\" def __init__(self, factor=0.5, depth_factor=0.5, pretrain_img_size=224, patch_size=4, in_chans=3, embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24], window_size=7, mlp_ratio=4., qkv_bias=True, qk_scale=None, drop_rate=0., attn_drop_rate=0., drop_path_rate=0.2, norm_layer=nn.LayerNorm, ape=False, patch_norm=True, out_indices=(0, 1, 2, 3), frozen_stages=-1, use_checkpoint=False): super().__init__() embed_dim = int(embed_dim * factor) depths = [max(1, int(dim * depth_factor)) for dim in depths] self.pretrain_img_size = pretrain_img_size self.num_layers = len(depths) self.embed_dim = embed_dim self.ape = ape self.patch_norm = patch_norm self.out_indices = out_indices self.frozen_stages = frozen_stages # split image into non-overlapping patches self.patch_embed = PatchEmbed( patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim, norm_layer=norm_layer if self.patch_norm else None) # absolute position embedding if self.ape: pretrain_img_size = to_2tuple(pretrain_img_size) patch_size = to_2tuple(patch_size) patches_resolution = [pretrain_img_size[0] // patch_size[0], pretrain_img_size[1] // patch_size[1]] self.absolute_pos_embed = nn.Parameter(torch.zeros(1, embed_dim, patches_resolution[0], patches_resolution[1])) trunc_normal_(self.absolute_pos_embed, std=.02) self.pos_drop = nn.Dropout(p=drop_rate) # stochastic depth dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] # stochastic depth decay rule # build layers self.layers = nn.ModuleList() for i_layer in range(self.num_layers): layer = BasicLayer( dim=int(embed_dim * 2 ** i_layer), depth=depths[i_layer], num_heads=num_heads[i_layer], window_size=window_size, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale, drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[sum(depths[:i_layer]):sum(depths[:i_layer + 1])], norm_layer=norm_layer, downsample=PatchMerging if (i_layer \u0026lt; self.num_layers - 1) else None, use_checkpoint=use_checkpoint) self.layers.append(layer) num_features = [int(embed_dim * 2 ** i) for i in range(self.num_layers)] self.num_features = num_features # add a norm layer for each output for i_layer in out_indices: layer = norm_layer(num_features[i_layer]) layer_name = f'norm{i_layer}' self.add_module(layer_name, layer) self.width_list = [i.size(1) for i in self.forward(torch.randn(1, 3, 640, 640))] def forward(self, x): \"\"\"Forward function.\"\"\" x = self.patch_embed(x) Wh, Ww = x.size(2), x.size(3) if self.ape: # interpolate the position embedding to the corresponding size absolute_pos_embed = F.interpolate(self.absolute_pos_embed, size=(Wh, Ww), mode='bicubic') x = (x + absolute_pos_embed).flatten(2).transpose(1, 2) # B Wh*Ww C else: x = x.flatten(2).transpose(1, 2) x = self.pos_drop(x) outs = [] for i in range(self.num_layers): layer = self.layers[i] x_out, H, W, x, Wh, Ww = layer(x, Wh, Ww) if i in self.out_indices: norm_layer = getattr(self, f'norm{i}') x_out = norm_layer(x_out) out = x_out.view(-1, H, W, self.num_features[i]).permute(0, 3, 1, 2).contiguous() outs.append(out) return outs\rå››ã€æ‰‹æŠŠæ‰‹æ•™ä½ æ·»åŠ Swin Transformerç½‘ç»œç»“æ„\rè¿™ä¸ªä¸»å¹²çš„ç½‘ç»œç»“æ„æ·»åŠ èµ·æ¥ç®—æ˜¯æ‰€æœ‰çš„æ”¹è¿›æœºåˆ¶é‡Œæœ€éº»çƒ¦çš„äº†ï¼Œå› ä¸ºæœ‰ä¸€äº›ç½‘ç•¥ç»“æ„å¯ä»¥ç”¨yamlæ–‡ä»¶æ­å»ºå‡ºæ¥ï¼Œæœ‰ä¸€äº›ç½‘ç»œç»“æ„å…¶ä¸­çš„ä¸€äº›ç»†èŠ‚æ ¹æœ¬æ²¡æœ‰åŠæ³•ç”¨yamlæ–‡ä»¶å»æ­å»ºï¼Œç”¨yamlæ–‡ä»¶å»æ­å»ºä¼šæŸå¤±ä¸€äº›ç»†èŠ‚éƒ¨åˆ†(è€Œä¸”ä¸€ä¸ªç½‘ç»œç»“æ„è®¾è®¡å¾ˆå¤šç»†èŠ‚çš„ç»“æ„ä¿®æ”¹æ–¹å¼éƒ½ä¸ä¸€æ ·ï¼Œä¸€ä¸ªä¸€ä¸ªå»ä¿®æ”¹å¤§å®¶éš¾å…ä¼šå‡ºé”™)ï¼Œæ‰€ä»¥è¿™é‡Œè®©ç½‘ç»œç›´æ¥è¿”å›æ•´ä¸ªç½‘ç»œï¼Œç„¶åä¿®æ”¹éƒ¨åˆ† yoloä»£ç ä»¥åå°±éƒ½ä»¥è¿™ç§å½¢å¼æ·»åŠ äº†ï¼Œä»¥åæˆ‘æå‡ºçš„ç½‘ç»œæ¨¡å‹åŸºæœ¬ä¸Šéƒ½ä¼šé€šè¿‡è¿™ç§æ–¹å¼ä¿®æ”¹ï¼Œæˆ‘ä¹Ÿä¼šè¿›è¡Œä¸€äº›æ¨¡å‹ç»†èŠ‚æ”¹è¿›ã€‚åˆ›æ–°å‡ºæ–°çš„ç½‘ç»œç»“æ„å¤§å®¶ç›´æ¥æ‹¿æ¥ç”¨å°±å¯ä»¥çš„ã€‚\rä¸‹é¢å¼€å§‹æ·»åŠ æ•™ç¨‹-\u0026gt;\r(åŒæ—¶æ¯ä¸€ä¸ªåé¢éƒ½æœ‰ä»£ç ï¼Œå¤§å®¶æ‹¿æ¥å¤åˆ¶ç²˜è´´æ›¿æ¢å³å¯ï¼Œä½†æ˜¯è¦çœ‹å¥½äº†ä¸è¦å¤åˆ¶ç²˜è´´æ›¿æ¢å¤šäº†)\r4.1 ä¿®æ”¹ä¸€\rç¬¬ä¸€è¿˜æ˜¯å»ºç«‹æ–‡ä»¶ï¼Œæˆ‘ä»¬æ‰¾åˆ°å¦‚ä¸‹ultralytics/nnæ–‡ä»¶å¤¹ä¸‹å»ºç«‹ä¸€ä¸ªç›®å½•åå­—å‘¢å°±æ˜¯'Addmodules'æ–‡ä»¶å¤¹\r(ç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€æ–°å»º)\rï¼\rç„¶ååœ¨å…¶å†…éƒ¨å»ºç«‹ä¸€ä¸ªæ–°çš„pyæ–‡ä»¶å°†æ ¸å¿ƒä»£ç å¤åˆ¶ç²˜è´´è¿›å»å³å¯ã€‚\râ€‹\r4.2 ä¿®æ”¹äºŒ\rç¬¬äºŒæ­¥æˆ‘ä»¬åœ¨è¯¥ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªæ–°çš„pyæ–‡ä»¶åå­—ä¸º'__init__.py'(\rç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€æ–°å»º)\rï¼Œç„¶ååœ¨å…¶å†…éƒ¨å¯¼å…¥æˆ‘ä»¬çš„æ£€æµ‹å¤´å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\r4.3 ä¿®æ”¹ä¸‰\rç¬¬ä¸‰æ­¥æˆ‘é—¨ä¸­åˆ°å¦‚ä¸‹æ–‡ä»¶'ultralytics/nn/tasks.py'è¿›è¡Œå¯¼å…¥å’Œæ³¨å†Œæˆ‘ä»¬çš„æ¨¡å—(\rç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€é‡æ–°å¯¼å…¥ç›´æ¥å¼€å§‹ç¬¬å››æ­¥å³å¯)\rï¼\rä»ä»Šå¤©å¼€å§‹ä»¥åçš„æ•™ç¨‹å°±éƒ½ç»Ÿä¸€æˆè¿™ä¸ªæ ·å­äº†ï¼Œå› ä¸ºæˆ‘é»˜è®¤å¤§å®¶ç”¨äº†æˆ‘ç¾¤å†…çš„æ–‡ä»¶æ¥è¿›è¡Œä¿®æ”¹ï¼ï¼\r4.4 ä¿®æ”¹å››\ræ·»åŠ å¦‚ä¸‹ä¸¤è¡Œä»£ç ï¼ï¼ï¼\râ€‹\r4.5 ä¿®æ”¹äº”\ræ‰¾åˆ°ä¸ƒç™¾å¤šè¡Œå¤§æ¦‚æŠŠå…·ä½“çœ‹å›¾ç‰‡ï¼ŒæŒ‰ç…§å›¾ç‰‡æ¥ä¿®æ”¹å°±è¡Œï¼Œæ·»åŠ çº¢æ¡†å†…çš„éƒ¨åˆ†ï¼Œæ³¨æ„æ²¡æœ‰()åªæ˜¯å‡½æ•°åã€‚\râ€‹\relif m in {è‡ªè¡Œæ·»åŠ å¯¹åº”çš„æ¨¡å‹å³å¯ï¼Œä¸‹é¢éƒ½æ˜¯ä¸€æ ·çš„}: # è¿™æ®µä»£ç æ˜¯è‡ªå·±æ·»åŠ çš„åŸä»£ç ä¸­æ²¡æœ‰ m = m(*args) c2 = m.width_list # è¿”å›é€šé“åˆ—è¡¨ backbone = True\r4.6 ä¿®æ”¹å…­\rä¸‹é¢çš„ä¸¤ä¸ªçº¢æ¡†å†…éƒ½æ˜¯éœ€è¦æ”¹åŠ¨çš„ã€‚\râ€‹\rif isinstance(c2, list): m_ = m m_.backbone = True else: m_ = nn.Sequential(*(m(*args) for _ in range(n))) if n \u0026gt; 1 else m(*args) # module t = str(m)[8:-2].replace('__main__.', '') # module type m.np = sum(x.numel() for x in m_.parameters()) # number params m_.i, m_.f, m_.type = i + 4 if backbone else i, f, t # attach index, 'from' index, type\r4.7 ä¿®æ”¹ä¸ƒ\rå¦‚ä¸‹çš„ä¹Ÿéœ€è¦ä¿®æ”¹ï¼Œå…¨éƒ¨æŒ‰ç…§æˆ‘çš„æ¥ã€‚\râ€‹\rä»£ç å¦‚ä¸‹æŠŠåŸå…ˆçš„ä»£ç æ›¿æ¢äº†å³å¯ã€‚\rif verbose: LOGGER.info(f'{i:\u0026gt;3}{str(f):\u0026gt;20}{n_:\u0026gt;3}{m.np:10.0f} {t:\u0026lt;45}{str(args):\u0026lt;30}') # print save.extend(x % (i + 4 if backbone else i) for x in ([f] if isinstance(f, int) else f) if x != -1) # append to savelist layers.append(m_) if i == 0: ch = [] if isinstance(c2, list): ch.extend(c2) if len(c2) != 5: ch.insert(0, 0) else: ch.append(c2)\r4.8 ä¿®æ”¹å…«\rä¿®æ”¹ä¸ƒå’Œå‰é¢çš„éƒ½ä¸å¤ªä¸€æ ·ï¼Œéœ€è¦ä¿®æ”¹å‰å‘ä¼ æ’­ä¸­çš„ä¸€ä¸ªéƒ¨åˆ†ï¼ŒÂ å·²ç»ç¦»å¼€äº†parse_modelæ–¹æ³•äº†ã€‚\rå¯ä»¥åœ¨å›¾ç‰‡ä¸­å¼€ä»£ç è¡Œæ•°ï¼Œæ²¡æœ‰ç¦»å¼€task.pyæ–‡ä»¶éƒ½æ˜¯åŒä¸€ä¸ªæ–‡ä»¶ã€‚ åŒæ—¶è¿™ä¸ªéƒ¨åˆ†æœ‰å¥½å‡ ä¸ªå‰å‘ä¼ æ’­éƒ½å¾ˆç›¸ä¼¼ï¼Œå¤§å®¶ä¸è¦çœ‹é”™äº†ï¼Œ\ræ˜¯70å¤šè¡Œå·¦å³çš„ï¼ï¼ï¼ï¼ŒåŒæ—¶æˆ‘åé¢æä¾›äº†ä»£ç ï¼Œå¤§å®¶ç›´æ¥å¤åˆ¶ç²˜è´´å³å¯ï¼Œæœ‰æ—¶é—´æˆ‘é’ˆå¯¹è¿™é‡Œä¼šå‡ºä¸€ä¸ªè§†é¢‘ã€‚\râ€‹â€‹\rä»£ç å¦‚ä¸‹-\u0026gt;\rdef _predict_once(self, x, profile=False, visualize=False, embed=None): \"\"\" Perform a forward pass through the network. Args: x (torch.Tensor): The input tensor to the model. profile (bool): Print the computation time of each layer if True, defaults to False. visualize (bool): Save the feature maps of the model if True, defaults to False. embed (list, optional): A list of feature vectors/embeddings to return. Returns: (torch.Tensor): The last output of the model. \"\"\" y, dt, embeddings = [], [], [] # outputs for m in self.model: if m.f != -1: # if not from previous layer x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f] # from earlier layers if profile: self._profile_one_layer(m, x, dt) if hasattr(m, 'backbone'): x = m(x) if len(x) != 5: # 0 - 5 x.insert(0, None) for index, i in enumerate(x): if index in self.save: y.append(i) else: y.append(None) x = x[-1] # æœ€åä¸€ä¸ªè¾“å‡ºä¼ ç»™ä¸‹ä¸€å±‚ else: x = m(x) # run y.append(x if m.i in self.save else None) # save output if visualize: feature_visualization(x, m.type, m.i, save_dir=visualize) if embed and m.i in embed: embeddings.append(nn.functional.adaptive_avg_pool2d(x, (1, 1)).squeeze(-1).squeeze(-1)) # flatten if m.i == max(embed): return torch.unbind(torch.cat(embeddings, 1), dim=0) return x\råˆ°è¿™é‡Œå°±å®Œæˆäº†ä¿®æ”¹éƒ¨åˆ†ï¼Œä½†æ˜¯è¿™é‡Œé¢ç»†èŠ‚å¾ˆå¤šï¼Œå¤§å®¶åƒä¸‡è¦æ³¨æ„ä¸è¦æ›¿æ¢å¤šä½™çš„ä»£ç ï¼Œå¯¼è‡´æŠ¥é”™ï¼Œä¹Ÿä¸è¦æ‹‰ä¸‹ä»»ä½•ä¸€éƒ¨ï¼Œéƒ½ä¼šå¯¼è‡´è¿è¡Œå¤±è´¥ï¼Œè€Œä¸”æŠ¥é”™å¾ˆéš¾æ’æŸ¥ï¼ï¼ï¼å¾ˆéš¾æ’æŸ¥ï¼ï¼ï¼\r4.9 ä¿®æ”¹ä¹\ræˆ‘ä»¬æ‰¾åˆ°å¦‚ä¸‹æ–‡ä»¶'ultralytics/utils/torch_utils.py'æŒ‰ç…§å¦‚ä¸‹çš„å›¾ç‰‡è¿›è¡Œä¿®æ”¹ï¼Œå¦åˆ™å®¹æ˜“æ‰“å°ä¸å‡ºæ¥è®¡ç®—é‡ã€‚\râ€‹\räº”ã€Swintransformerçš„yamlæ–‡ä»¶\rå¤åˆ¶å¦‚ä¸‹yamlæ–‡ä»¶è¿›è¡Œè¿è¡Œï¼ï¼ï¼\ræ­¤ç‰ˆæœ¬è®­ç»ƒä¿¡æ¯ï¼šYOLO11-SwinTransformer summary: 325 layers, 2,514,792 parameters, 2,514,776 gradients, 6.1 GFLOPs\rä½¿ç”¨è¯´æ˜ï¼š# ä¸‹é¢ [-1, 1, LSKNet, [0.25ï¼Œ0.5]] å‚æ•°ä½ç½®çš„0.25æ˜¯é€šé“æ”¾ç¼©çš„ç³»æ•°, YOLOv11Næ˜¯0.25 YOLOv11Sæ˜¯0.5 YOLOv11Mæ˜¯1. YOLOv11læ˜¯1 YOLOv11æ˜¯1.5å¤§å®¶æ ¹æ®è‡ªå·±è®­ç»ƒçš„YOLOç‰ˆæœ¬è®¾å®šå³å¯.\r# 0.5å¯¹åº”çš„æ˜¯æ¨¡å‹çš„æ·±åº¦ç³»æ•°\r# Ultralytics YOLO ğŸš€, AGPL-3.0 license# YOLO11 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect # Parametersnc: 80 # number of classesscales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n' # [depth, width, max_channels] n: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs s: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs m: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs l: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs x: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs # ä¸‹é¢ [-1, 1, SwinTransformer, [0.25ï¼Œ0.5]] å‚æ•°ä½ç½®çš„0.25æ˜¯é€šé“æ”¾ç¼©çš„ç³»æ•°, YOLOv11Næ˜¯0.25 YOLOv11Sæ˜¯0.5 YOLOv11Mæ˜¯1. YOLOv11læ˜¯1 YOLOv11æ˜¯1.5å¤§å®¶æ ¹æ®è‡ªå·±è®­ç»ƒçš„YOLOç‰ˆæœ¬è®¾å®šå³å¯. # 0.5å¯¹åº”çš„æ˜¯æ¨¡å‹çš„æ·±åº¦ç³»æ•° # YOLO11n backbonebackbone: # [from, repeats, module, args] - [-1, 1, SwinTransformer, [0.25,0.5]] # 0-4 P1/2 - [-1, 1, SPPF, [1024, 5]] # 5 - [-1, 2, C2PSA, [1024]] # 6 # YOLO11n headhead: - [-1, 1, nn.Upsample, [None, 2, \"nearest\"]] - [[-1, 3], 1, Concat, [1]] # cat backbone P4 - [-1, 2, C3k2, [512, False]] # 9 - [-1, 1, nn.Upsample, [None, 2, \"nearest\"]] - [[-1, 2], 1, Concat, [1]] # cat backbone P3 - [-1, 2, C3k2, [256, False]] # 12 (P3/8-small) - [-1, 1, Conv, [256, 3, 2]] - [[-1, 9], 1, Concat, [1]] # cat head P4 - [-1, 2, C3k2, [512, False]] # 15 (P4/16-medium) - [-1, 1, Conv, [512, 3, 2]] - [[-1, 6], 1, Concat, [1]] # cat head P5 - [-1, 2, C3k2, [1024, True]] # 18 (P5/32-large) - [[12, 15, 18], 1, Detect, [nc]] # Detect(P3, P4, P5)\rå…­ã€æˆåŠŸè¿è¡Œè®°å½•\rä¸‹é¢æ˜¯æˆåŠŸè¿è¡Œçš„æˆªå›¾ï¼Œå·²ç»å®Œæˆäº†æœ‰1ä¸ªepochsçš„è®­ç»ƒï¼Œå›¾ç‰‡å¤ªå¤§æˆªä¸å…¨ç¬¬2ä¸ªepochsäº†ã€‚\râ€‹\rä¸ƒã€æœ¬æ–‡æ€»ç»“\råˆ°æ­¤æœ¬æ–‡çš„æ­£å¼åˆ†äº«å†…å®¹å°±ç»“æŸäº†ï¼Œåœ¨è¿™é‡Œç»™å¤§å®¶æ¨èæˆ‘çš„YOLOv11æ”¹è¿›æœ‰æ•ˆæ¶¨ç‚¹ä¸“æ ï¼Œæœ¬ä¸“æ ç›®å‰ä¸ºæ–°å¼€çš„å¹³å‡è´¨é‡åˆ†98åˆ†ï¼ŒåæœŸæˆ‘ä¼šæ ¹æ®å„ç§æœ€æ–°çš„å‰æ²¿é¡¶ä¼šè¿›è¡Œè®ºæ–‡å¤ç°ï¼Œä¹Ÿä¼šå¯¹ä¸€äº›è€çš„æ”¹è¿›æœºåˆ¶è¿›è¡Œè¡¥å……ï¼Œ\rç›®å‰æœ¬ä¸“æ å…è´¹é˜…è¯»(æš‚æ—¶ï¼Œå¤§å®¶å°½æ—©å…³æ³¨ä¸è¿·è·¯~)ï¼Œ\rå¦‚æœå¤§å®¶è§‰å¾—æœ¬æ–‡å¸®åŠ©åˆ°ä½ äº†ï¼Œè®¢é˜…æœ¬ä¸“æ ï¼Œå…³æ³¨åç»­æ›´å¤šçš„æ›´æ–°~\rä¸“æ å›é¡¾ï¼š\rYOLOv11æ”¹è¿›ç³»åˆ—ä¸“æ â€”â€”æœ¬ä¸“æ æŒç»­å¤ä¹ å„ç§é¡¶ä¼šå†…å®¹â€”â€”ç§‘ç ”å¿…å¤‡\râ€‹â€‹\ræ–‡ç« çŸ¥è¯†ç‚¹ä¸å®˜æ–¹çŸ¥è¯†æ¡£æ¡ˆåŒ¹é…ï¼Œå¯è¿›ä¸€æ­¥å­¦ä¹ ç›¸å…³çŸ¥è¯†\rOpenCVæŠ€èƒ½æ ‘\rOpenCVä¸­çš„æ·±åº¦å­¦ä¹ \rå›¾åƒåˆ†ç±»\r29518\räººæ­£åœ¨ç³»ç»Ÿå­¦ä¹ ä¸­\rç¡®å®šè¦æ”¾å¼ƒæœ¬æ¬¡æœºä¼šï¼Ÿ\rç¦åˆ©å€’è®¡æ—¶\r:\r:\rç«‹å‡ Â¥\ræ™®é€šVIPå¹´å¡å¯ç”¨\rç«‹å³ä½¿ç”¨\rç›®å½•\rä¸€ã€æœ¬æ–‡ä»‹ç»\räºŒã€Swin TransformeråŸç†\r2.1Â Swin Transformerçš„åŸºæœ¬åŸç†\r2.2Â å±‚æ¬¡åŒ–ç‰¹å¾æ˜ å°„\r2.3Â å±€éƒ¨è‡ªæ³¨æ„åŠ›è®¡ç®—\r2.4Â ç§»åŠ¨çª—å£è‡ªæ³¨æ„åŠ›\r2.5Â ç§»åŠ¨çª—å£åˆ†åŒº\rä¸‰ã€Â Swin Transformerçš„å®Œæ•´ä»£ç \rå››ã€æ‰‹æŠŠæ‰‹æ•™ä½ æ·»åŠ Swin Transformerç½‘ç»œç»“æ„\r4.1 ä¿®æ”¹ä¸€\r4.2 ä¿®æ”¹äºŒ\r4.3 ä¿®æ”¹ä¸‰\r4.4 ä¿®æ”¹å››\r4.5 ä¿®æ”¹äº”\r4.6 ä¿®æ”¹å…­\r4.7 ä¿®æ”¹ä¸ƒ\r4.8 ä¿®æ”¹å…«\r4.9 ä¿®æ”¹ä¹\räº”ã€Swintransformerçš„yamlæ–‡ä»¶\rå…­ã€æˆåŠŸè¿è¡Œè®°å½•\rä¸ƒã€æœ¬æ–‡æ€»ç»“\rç¡®å®š\rå–æ¶ˆ\rä¸¾æŠ¥\ré€‰æ‹©ä½ æƒ³è¦ä¸¾æŠ¥çš„å†…å®¹ï¼ˆå¿…é€‰ï¼‰\rå†…å®¹æ¶‰é»„\ræ”¿æ²»ç›¸å…³\rå†…å®¹æŠ„è¢­\ræ¶‰å«Œå¹¿å‘Š\rå†…å®¹ä¾µæƒ\rä¾®è¾±è°©éª‚\ræ ·å¼é—®é¢˜\rå…¶ä»–\råŸæ–‡é“¾æ¥ï¼ˆå¿…å¡«ï¼‰\rè¯·é€‰æ‹©å…·ä½“åŸå› ï¼ˆå¿…é€‰ï¼‰\råŒ…å«ä¸å®ä¿¡æ¯\ræ¶‰åŠä¸ªäººéšç§\rè¯·é€‰æ‹©å…·ä½“åŸå› ï¼ˆå¿…é€‰ï¼‰\rä¾®è¾±è°©éª‚\rè¯½è°¤\rè¯·é€‰æ‹©å…·ä½“åŸå› ï¼ˆå¿…é€‰ï¼‰\ræ¬å®¶æ ·å¼\råšæ–‡æ ·å¼\rè¡¥å……è¯´æ˜ï¼ˆé€‰å¡«ï¼‰\rå–æ¶ˆ\rç¡®å®š\r","date":"0001-01-01T00:00:00Z","permalink":"https://nickk111.github.io/p/","title":""},{"content":"YOLOv11æ”¹è¿› | Convç¯‡ | AKConvè½»é‡çº§æ¶æ„ä¸‹çš„é«˜æ•ˆæ£€æµ‹ï¼ˆé™„ä»£ç  + ä¿®æ”¹æ–¹æ³• + äºŒæ¬¡åˆ›æ–°ï¼‰ ä¸€ã€æœ¬æ–‡ä»‹ç» æœ¬æ–‡ç»™å¤§å®¶å¸¦æ¥çš„æ”¹è¿›å†…å®¹æ˜¯ AKConv æ˜¯ä¸€ç§åˆ›æ–°çš„ å˜æ ¸å·ç§¯ ï¼Œå®ƒæ—¨åœ¨è§£å†³æ ‡å‡†å·ç§¯æ“ä½œä¸­çš„å›ºæœ‰ç¼ºé™·ï¼ˆé‡‡æ ·å½¢çŠ¶æ˜¯å›ºå®šçš„ï¼‰ï¼ŒAKConvçš„ æ ¸å¿ƒæ€æƒ³ åœ¨äºå®ƒä¸ºå·ç§¯æ ¸æä¾›äº†ä»»æ„æ•°é‡çš„å‚æ•°å’Œä»»æ„é‡‡æ ·å½¢çŠ¶ï¼Œèƒ½å¤Ÿä½¿ç”¨ä»»æ„æ•°é‡çš„å‚æ•°ï¼ˆå¦‚1, 2, 3, 4, 5, 6, 7ç­‰ï¼‰æ¥æå–ç‰¹å¾ï¼Œè¿™åœ¨æ ‡å‡†å·ç§¯å’Œå¯å˜å½¢å·ç§¯ä¸­å¹¶æœªå®ç°â€‹â€‹ã€‚AKConvèƒ½å¤Ÿæ ¹æ®ç¡¬ä»¶ç¯å¢ƒï¼Œä½¿å·ç§¯å‚æ•°çš„æ•°é‡å‘ˆçº¿æ€§å¢å‡ ï¼ˆ éå¸¸é€‚ç”¨äºè½»é‡åŒ–æ¨¡å‹çš„è¯»è€…ï¼‰ã€‚ æœ¬æ–‡é€šè¿‡å…ˆä»‹ç»AKConvçš„åŸºæœ¬ç½‘ç»œç»“æ„å’ŒåŸç†è®©å¤§å®¶å¯¹è¯¥å·ç§¯æœ‰ä¸€ä¸ªå¤§æ¦‚çš„äº†è§£ï¼Œç„¶åæ•™å¤§å®¶å¦‚ä½•å°†è¯¥å·ç§¯æ·»åŠ åˆ°è‡ªå·±çš„ç½‘ç»œç»“æ„ä¸­ï¼Œ äºŒæ¬¡åˆ›æ–°C3k2 ã€‚\nä¸“æ å›é¡¾ï¼š YOLOv11æ”¹è¿›ç³»åˆ—ä¸“æ â€”â€”æœ¬ä¸“æ æŒç»­å¤ä¹ å„ç§é¡¶ä¼šå†…å®¹â€”â€”ç§‘ç ”å¿…å¤‡\nç›®å½•\nä¸€ã€æœ¬æ–‡ä»‹ç»\näºŒã€AKConvç½‘ç»œç»“æ„è®²è§£\n2.1 AKConvçš„ä¸»è¦æ€æƒ³å’Œæ”¹è¿›\n2.1.1 çµæ´»çš„å·ç§¯æ ¸è®¾è®¡\n2.1.2 åˆå§‹é‡‡æ ·åæ ‡ç®—æ³•\n2.1.3 é€‚åº”æ€§é‡‡æ ·ä½ç½®è°ƒæ•´\n2.1.4 çº¿æ€§å¢å‡å·ç§¯å‚æ•°çš„æ•°é‡\nä¸‰ã€AKConvçš„ä»£ç \nå››ã€æ‰‹æŠŠæ‰‹æ•™ä½ æ·»åŠ AKConv\n4.1 ä¿®æ”¹ä¸€\n4.2 ä¿®æ”¹äºŒ\n4.3 ä¿®æ”¹ä¸‰\n4.4 ä¿®æ”¹å››\n4.5 AKConvçš„yamlæ–‡ä»¶å’Œè®­ç»ƒæˆªå›¾\n4.5.1 AKConvçš„yamlæ–‡ä»¶1\n4.5.2 AKConvçš„yamlæ–‡ä»¶2\n4.5.3 AKConvçš„è®­ç»ƒè¿‡ç¨‹æˆªå›¾\näº”ã€AKConvå¯æ·»åŠ çš„ä½ç½®\n5.1 æ¨èAKConvå¯æ·»åŠ çš„ä½ç½®\n5.2 å›¾ç¤ºAKConvå¯æ·»åŠ çš„ä½ç½®\nå…­ã€æœ¬æ–‡æ€»ç»“\näºŒã€AKConvç½‘ç»œç»“æ„è®²è§£ è®ºæ–‡åœ°å€ï¼š ** ** å®˜æ–¹è®ºæ–‡åœ°å€****\nä»£ç åœ°å€ï¼š ** ** å®˜æ–¹ä»£ç åœ°å€****\n2.1 AKConvçš„ä¸»è¦æ€æƒ³å’Œæ”¹è¿› AKConvçš„ä¸»è¦æ€æƒ³ï¼š AKConvï¼ˆå¯å˜æ ¸å·ç§¯ï¼‰ä¸»è¦æä¾›ä¸€ç§çµæ´»çš„å·ç§¯æœºåˆ¶ï¼Œ å…è®¸å·ç§¯æ ¸å…·æœ‰ä»»æ„æ•°é‡çš„å‚æ•°å’Œé‡‡æ ·å½¢çŠ¶ ã€‚è¿™ç§æ–¹æ³•çªç ´äº†ä¼ ç»Ÿå·ç§¯å±€é™äºå›ºå®šå±€éƒ¨çª—å£å’Œå›ºå®šé‡‡æ ·å½¢çŠ¶çš„é™åˆ¶ï¼Œä»è€Œä½¿å¾—å·ç§¯æ“ä½œèƒ½å¤Ÿæ›´åŠ ç²¾å‡†åœ°é€‚åº”ä¸åŒæ•°æ®é›†å’Œä¸åŒä½ç½®çš„ç›®æ ‡ã€‚\nAKConvçš„æ”¹è¿›ç‚¹ï¼š\nçµæ´»çš„å·ç§¯æ ¸è®¾è®¡ ï¼šAKConvå…è®¸å·ç§¯æ ¸å…·æœ‰ä»»æ„æ•°é‡çš„å‚æ•°ï¼Œè¿™ä½¿å¾—å…¶å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´å¤§å°å’Œå½¢çŠ¶ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°é€‚åº”ç›®æ ‡çš„å˜åŒ–ã€‚\nåˆå§‹é‡‡æ ·åæ ‡ç®—æ³• ï¼šé’ˆå¯¹ä¸åŒå¤§å°çš„å·ç§¯æ ¸ï¼ŒAKConvæå‡ºäº†ä¸€ç§æ–°çš„ç®—æ³•æ¥ç”Ÿæˆåˆå§‹é‡‡æ ·åæ ‡ï¼Œè¿™è¿›ä¸€æ­¥å¢å¼ºäº†å…¶åœ¨å¤„ç†å„ç§å°ºå¯¸ç›®æ ‡æ—¶çš„çµæ´»æ€§ã€‚\né€‚åº”æ€§é‡‡æ ·ä½ç½®è°ƒæ•´ ï¼šä¸ºé€‚åº”ç›®æ ‡çš„ä¸åŒå˜åŒ–ï¼ŒAKConvé€šè¿‡è·å¾—çš„åç§»é‡è°ƒæ•´ä¸è§„åˆ™å·ç§¯æ ¸çš„é‡‡æ ·ä½ç½®ï¼Œä»è€Œæé«˜äº†ç‰¹å¾æå–çš„å‡†ç¡®æ€§ã€‚\nå‡å°‘æ¨¡å‹å‚æ•°å’Œè®¡ç®—å¼€é”€ ï¼šAKConvæ”¯æŒçº¿æ€§å¢å‡å·ç§¯å‚æ•°çš„æ•°é‡ï¼Œæœ‰åŠ©äºåœ¨ç¡¬ä»¶ç¯å¢ƒä¸­ä¼˜åŒ–æ€§èƒ½ï¼Œå°¤å…¶é€‚åˆäºè½»é‡çº§æ¨¡å‹çš„åº”ç”¨ã€‚\nä¸ªäººæ€»ç»“ï¼š æ€»çš„æ¥è¯´ï¼ŒAKConvé€šè¿‡å…¶åˆ›æ–°çš„å¯å˜æ ¸å·ç§¯è®¾è®¡ï¼Œä¸ºå·ç§¯ç¥ç»ç½‘ç»œå¸¦æ¥äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…¶èƒ½å¤Ÿæ ¹æ®ä¸åŒçš„æ•°æ®é›†å’Œç›®æ ‡çµæ´»è°ƒæ•´å·ç§¯æ ¸çš„å¤§å°å’Œå½¢çŠ¶ï¼Œä»è€Œå®ç°æ›´é«˜æ•ˆçš„ç‰¹å¾æå–ã€‚\nå›¾ç‰‡å±•ç¤ºäº†AKConvç»“æ„çš„è¯¦ç»†ç¤ºæ„å›¾ï¼Œ å¹¶é™„ä¸Šæˆ‘ä¸ªäººçš„è¿‡ç¨‹ç†è§£ï¼š\n1. è¾“å…¥ï¼š è¾“å…¥å›¾åƒå…·æœ‰ç»´åº¦(C, H, W)ï¼Œå…¶ä¸­Cæ˜¯é€šé“æ•°ï¼ŒHå’ŒWåˆ†åˆ«æ˜¯å›¾åƒçš„é«˜åº¦å’Œå®½åº¦ã€‚\n2. åˆå§‹é‡‡æ ·å½¢çŠ¶ï¼š è¿™ä¸€æ­¥æ˜¯AKConvç‰¹æœ‰çš„ï¼Œå®ƒç»™å‡ºäº†å·ç§¯æ ¸çš„åˆå§‹é‡‡æ ·å½¢çŠ¶ã€‚\n3. å·ç§¯æ“ä½œï¼š ä½¿ç”¨Conv2då¯¹è¾“å…¥å›¾åƒæ‰§è¡Œå·ç§¯æ“ä½œã€‚\n4. åç§»ï¼š é€šè¿‡å­¦ä¹ å¾—åˆ°çš„åç§»é‡æ¥è°ƒæ•´åˆå§‹é‡‡æ ·å½¢çŠ¶ã€‚è¿™ä¸€æ­¥æ˜¯AKConvçš„å…³é”®ï¼Œå…è®¸å·ç§¯æ ¸å½¢çŠ¶åŠ¨æ€è°ƒæ•´ä»¥é€‚åº”å›¾åƒçš„ç‰¹å¾ã€‚\n5. é‡é‡‡æ ·ï¼š æ ¹æ®è°ƒæ•´åçš„é‡‡æ ·å½¢çŠ¶å¯¹ç‰¹å¾å›¾è¿›è¡Œé‡é‡‡æ ·ã€‚\n6. è¾“å‡ºç®¡é“ï¼š é‡é‡‡æ ·åçš„ç‰¹å¾å›¾ç»è¿‡é‡å¡‘ã€å†æ¬¡å·ç§¯ã€æ ‡å‡†åŒ–ï¼Œæœ€åé€šè¿‡æ¿€æ´»å‡½æ•°SiLUè¾“å‡ºæœ€ç»ˆç»“æœã€‚\nåº•éƒ¨çš„ä¸‰è¡Œå±•ç¤ºäº†é‡‡æ ·åæ ‡çš„å˜åŒ–ï¼š\nåŸå§‹åæ ‡ï¼šæ˜¾ç¤ºäº†å·ç§¯æ ¸åœ¨æ²¡æœ‰ä»»ä½•åç§»çš„æƒ…å†µä¸‹çš„åˆå§‹é‡‡æ ·ä½ç½®ã€‚ åç§»ï¼šå±•ç¤ºäº†å­¦ä¹ åˆ°çš„åç§»é‡ï¼Œè¿™äº›åç§»é‡å°†åº”ç”¨äºåŸå§‹åæ ‡ã€‚ ä¿®æ”¹åçš„åæ ‡ï¼šåº”ç”¨åç§»åçš„é‡‡æ ·åæ ‡ã€‚ æ€»ç»“ï¼š å®˜æ–¹è¿™ä¸ªå›¾è¯´æ˜äº†AKConvå¦‚ä½•ä¸ºä»»æ„å¤§å°çš„å·ç§¯åˆ†é…åˆå§‹é‡‡æ ·åæ ‡ï¼Œå¹¶é€šè¿‡å¯å­¦ä¹ çš„åç§»è°ƒæ•´é‡‡æ ·å½¢çŠ¶ã€‚ä¸åŸå§‹é‡‡æ ·å½¢çŠ¶ç›¸æ¯”ï¼Œæ¯ä¸ªä½ç½®çš„é‡‡æ ·å½¢çŠ¶éƒ½é€šè¿‡é‡é‡‡æ ·è¿›è¡Œäº†æ”¹å˜ï¼Œè¿™ä½¿å¾—AKConvå¯ä»¥æ ¹æ®å›¾åƒå†…å®¹åŠ¨æ€è°ƒæ•´å…¶æ“ä½œï¼Œä¸ºå·ç§¯ç½‘ç»œæä¾›äº†å‰æ‰€æœªæœ‰çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚\n2.1.1 çµæ´»çš„å·ç§¯æ ¸è®¾è®¡ AKConvä¸­çš„çµæ´»å·ç§¯æ ¸è®¾è®¡æ˜¯ä¸€ç§åˆ›æ–°çš„æœºåˆ¶ï¼Œæ—¨åœ¨ä½¿å·ç§¯ç½‘ç»œæ›´åŠ é€‚åº”æ€§å’Œæœ‰æ•ˆç‡ã€‚ä»¥ä¸‹æ˜¯å…¶ä¸»è¦åŸç†å’Œæœºåˆ¶çš„æ€»ç»“ï¼š\nä¸»è¦åŸç†\nä»»æ„å‚æ•°æ•°é‡ ï¼šä¼ ç»Ÿçš„å·ç§¯æ ¸é€šå¸¸å…·æœ‰å›ºå®šçš„å°ºå¯¸å’Œå½¢çŠ¶ï¼Œä¾‹å¦‚3x3æˆ–5x5çš„æ–¹å½¢ç½‘æ ¼ã€‚è€ŒAKConvçš„æ ¸å¿ƒåŸç†æ˜¯å…è®¸å·ç§¯æ ¸å…·æœ‰ä»»æ„æ•°é‡çš„å‚æ•°ã€‚è¿™æ„å‘³ç€å·ç§¯æ ¸ä¸å†å±€é™äºæ ‡å‡†çš„æ–¹å½¢ç½‘æ ¼ï¼Œè€Œæ˜¯å¯ä»¥æ ¹æ®å›¾åƒç‰¹å¾å’Œä»»åŠ¡éœ€æ±‚ï¼Œé‡‡ç”¨æ›´å¤šæ ·åŒ–å’Œçµæ´»çš„å½¢çŠ¶ (å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä»»æ„å‚æ•°æ•°é‡) ã€‚\nè‡ªé€‚åº”é‡‡æ ·å½¢çŠ¶ ï¼šåœ¨å¤„ç†ä¸åŒçš„å›¾åƒå’Œç›®æ ‡æ—¶ï¼ŒAKConvçš„å·ç§¯æ ¸èƒ½å¤Ÿè‡ªåŠ¨è°ƒæ•´å…¶é‡‡æ ·å½¢çŠ¶ã€‚è¿™æ˜¯é€šè¿‡å¼•å…¥ä¸€ç§æ–°çš„åæ ‡ç”Ÿæˆç®—æ³•å®ç°çš„ï¼Œè¯¥ç®—æ³•èƒ½å¤Ÿä¸ºä¸åŒå¤§å°å’Œå½¢çŠ¶çš„å·ç§¯æ ¸ç”Ÿæˆåˆå§‹é‡‡æ ·åæ ‡ (å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè‡ªé€‚åº”é‡‡æ ·å½¢çŠ¶) ã€‚\nå·¥ä½œæœºåˆ¶\nåˆå§‹åæ ‡ç”Ÿæˆ ï¼šAKConvé¦–å…ˆé€šè¿‡å…¶åæ ‡ç”Ÿæˆç®—æ³•ç¡®å®šå·ç§¯æ ¸çš„åˆå§‹é‡‡æ ·ä½ç½®ã€‚è¿™äº›ä½ç½®ä¸å†æ˜¯å›ºå®šä¸å˜çš„ï¼Œè€Œæ˜¯å¯ä»¥æ ¹æ®å›¾åƒä¸­çš„ç‰¹å¾å’Œç›®æ ‡åŠ¨æ€å˜åŒ–ã€‚\né‡‡æ ·ä½ç½®è°ƒæ•´ ï¼šä¸ºäº†æ›´å¥½åœ°é€‚åº”å›¾åƒä¸­ç›®æ ‡çš„å¤§å°å’Œå½¢çŠ¶å˜åŒ–ï¼ŒAKConvä¼šæ ¹æ®ç›®æ ‡çš„ç‰¹ç‚¹è°ƒæ•´å·ç§¯æ ¸çš„é‡‡æ ·ä½ç½®ã€‚è¿™ç§è°ƒæ•´æ˜¯é€šè¿‡æ·»åŠ åç§»é‡æ¥å®ç°çš„ï¼Œä½¿å¾—å·ç§¯æ“ä½œæ›´åŠ çµæ´»å’Œé€‚åº”æ€§å¼ºã€‚\nä¸ªäººæ€»ç»“ï¼š é€šè¿‡è¿™ç§çµæ´»çš„è®¾è®¡ï¼ŒAKConvèƒ½å¤Ÿæœ‰æ•ˆåœ°é€‚åº”å„ç§å¤§å°å’Œå½¢çŠ¶çš„ç›®æ ‡ï¼Œæé«˜äº†ç‰¹å¾æå–çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚å®ƒåœ¨æ ‡å‡†å·ç§¯æ ¸åŸºç¡€ä¸Šå¼•å…¥äº†æ›´å¤šçš„çµæ´»æ€§å’Œè‡ªé€‚åº”æ€§ï¼Œä»è€Œä½¿å¾—å·ç§¯ç¥ç»ç½‘ç»œåœ¨å¤„ç†å¤æ‚å’Œå¤šæ ·åŒ–çš„å›¾åƒæ•°æ®æ—¶æ›´ä¸ºé«˜æ•ˆã€‚è¿™ç§çµæ´»çš„å·ç§¯æ ¸è®¾è®¡ä¸ä»…æå‡äº†æ¨¡å‹çš„æ€§èƒ½ï¼Œè¿˜ä¸ºå‡å°‘æ¨¡å‹å‚æ•°å’Œè®¡ç®—å¼€é”€æä¾›äº†å¯èƒ½ï¼Œ ç‰¹åˆ«æ˜¯åœ¨è½»é‡çº§æ¨¡å‹çš„åº”ç”¨ä¸­æ˜¾ç¤ºå‡ºå…¶ä¼˜åŠ¿ã€‚\n2.1.2 åˆå§‹é‡‡æ ·åæ ‡ç®—æ³• AKConvä¸­çš„ åˆå§‹é‡‡æ ·åæ ‡ç®—æ³• æ˜¯å…¶æ ¸å¿ƒç‰¹å¾ä¹‹ä¸€ï¼Œè¿™ä¸ªç®—æ³•ä¸ºAKConvçš„çµæ´»æ€§å’Œé€‚åº”æ€§æä¾›äº†åŸºç¡€ã€‚ä»¥ä¸‹æ˜¯è¯¥ç®—æ³•çš„ä¸»è¦åŸç†å’Œæœºåˆ¶çš„æ¦‚è¿°ï¼š\nä¸»è¦åŸç†\né’ˆå¯¹å¤šæ ·åŒ–å°ºå¯¸çš„é€‚åº”æ€§ ï¼šä¼ ç»Ÿå·ç§¯æ“ä½œé€šå¸¸ä½¿ç”¨å›ºå®šå°ºå¯¸çš„å·ç§¯æ ¸ï¼Œè¿™é™åˆ¶äº†å…¶åœ¨å¤„ç†ä¸åŒå°ºå¯¸å’Œå½¢çŠ¶ç›®æ ‡æ—¶çš„æ•ˆæœã€‚AKConvçš„åˆå§‹é‡‡æ ·åæ ‡ç®—æ³•æ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ï¼Œé€šè¿‡å…è®¸å·ç§¯æ ¸é€‚åº”ä¸åŒå¤§å°çš„ç›®æ ‡ï¼Œå¢å¼ºå…¶çµæ´»æ€§å’Œæœ‰æ•ˆæ€§ã€‚\nåŠ¨æ€é‡‡æ ·åæ ‡ç”Ÿæˆ ï¼šè¯¥ç®—æ³•èƒ½å¤Ÿæ ¹æ®ç›®æ ‡çš„å°ºå¯¸å’Œå½¢çŠ¶åŠ¨æ€ç”Ÿæˆå·ç§¯æ ¸çš„åˆå§‹é‡‡æ ·åæ ‡ã€‚è¿™ç§åŠ¨æ€ç”Ÿæˆæ–¹å¼ä½¿å·ç§¯æ ¸èƒ½å¤Ÿæ›´ç²¾ç¡®åœ°è¦†ç›–å’Œå¤„ç†å›¾åƒä¸­çš„ä¸åŒåŒºåŸŸï¼Œä»è€Œæé«˜ç‰¹å¾æå–çš„ç²¾åº¦ã€‚\nå·¥ä½œæœºåˆ¶\né€‚åº”ä¸åŒç›®æ ‡å°ºå¯¸ ï¼šå¯¹äºæ¯ä¸€ä¸ªå·ç§¯æ“ä½œï¼Œç®—æ³•é¦–å…ˆè€ƒè™‘ç›®æ ‡çš„å°ºå¯¸ã€‚åŸºäºè¿™ä¸€ä¿¡æ¯ï¼Œå®ƒç”Ÿæˆä¸€ç»„åˆå§‹åæ ‡ï¼Œè¿™äº›åæ ‡å®šä¹‰äº†å·ç§¯æ ¸å°†è¦é‡‡æ ·çš„ä½ç½®ã€‚\nçµæ´»çš„åæ ‡è°ƒæ•´ ï¼šç”Ÿæˆçš„åˆå§‹åæ ‡ä¸æ˜¯å›ºå®šä¸å˜çš„ï¼Œè€Œæ˜¯å¯ä»¥æ ¹æ®å›¾åƒä¸­çš„ç‰¹å¾åŠ¨æ€è°ƒæ•´ã€‚è¿™æ„å‘³ç€å·ç§¯æ ¸å¯ä»¥æ ¹æ®å›¾åƒå†…å®¹çš„ä¸åŒè€Œæ”¹å˜å…¶é‡‡æ ·ç­–ç•¥ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°æå–ç‰¹å¾ã€‚\nä¸ªäººæ€»ç»“ï¼š é€šè¿‡å¼•å…¥è¿™ç§åˆå§‹é‡‡æ ·åæ ‡ç®—æ³•ï¼ŒAKConvèƒ½å¤Ÿæ›´çµæ´»åœ°å¤„ç†å„ç§å°ºå¯¸çš„ç›®æ ‡ï¼Œæ— è®ºæ˜¯å¤§å°ºå¯¸è¿˜æ˜¯å°å°ºå¯¸çš„ç›®æ ‡ï¼Œéƒ½èƒ½å¾—åˆ°æ›´å‡†ç¡®çš„ç‰¹å¾æå–ã€‚\n2.1.3 é€‚åº”æ€§é‡‡æ ·ä½ç½®è°ƒæ•´ AKConvçš„é€‚åº”æ€§é‡‡æ ·ä½ç½®è°ƒæ•´æœºåˆ¶æ˜¯å…¶æ ¸å¿ƒä¹‹ä¸€ï¼Œè¯¥æœºåˆ¶å…è®¸å·ç§¯æ ¸åŸºäºå›¾åƒå†…å®¹è¿›è¡ŒåŠ¨æ€è°ƒæ•´ã€‚è¿™é‡Œæ˜¯å¯¹è¿™ä¸€æœºåˆ¶çš„æ¦‚è¿°ï¼š\nåŠ¨æ€é‡‡æ ·è°ƒæ•´ ï¼šä¼ ç»Ÿçš„å·ç§¯ç½‘ç»œä½¿ç”¨å›ºå®šå½¢çŠ¶çš„å·ç§¯æ ¸åœ¨å›¾åƒä¸Šæ»‘åŠ¨æ¥æå–ç‰¹å¾ï¼Œè¿™ç§æ–¹æ³•å¿½ç•¥äº†å›¾åƒä¸­å¯¹è±¡å½¢çŠ¶å’Œå°ºå¯¸çš„å¤šæ ·æ€§ã€‚AKConvé‡‡ç”¨ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œå®ƒå…è®¸å·ç§¯æ ¸çš„å½¢çŠ¶å’Œä½ç½®æ ¹æ®å›¾åƒå†…å®¹åŠ¨æ€è°ƒæ•´ï¼Œæ›´å¥½åœ°åŒ¹é…å’Œè¦†ç›–ç›®æ ‡åŒºåŸŸã€‚\nåç§»é‡å­¦ä¹  ï¼šåœ¨AKConvä¸­ï¼Œå·ç§¯æ ¸çš„ä½ç½®å¯ä»¥é€šè¿‡å­¦ä¹ åˆ°çš„åç§»é‡æ¥è°ƒæ•´ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç½‘ç»œå­¦ä¹ åˆ°å¯¹äºç‰¹å®šå›¾åƒå’Œç›®æ ‡æœ€æœ‰æ•ˆçš„åç§»é‡ï¼Œä»¥ä¾¿åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­è‡ªåŠ¨è°ƒæ•´å·ç§¯æ ¸çš„ä½ç½®ã€‚\næé«˜ç‰¹å¾æå–å‡†ç¡®æ€§ ï¼šé€šè¿‡è¿™ç§è‡ªé€‚åº”è°ƒæ•´ï¼ŒAKConvèƒ½å¤Ÿæ›´å‡†ç¡®åœ°å¯¹é½å¹¶æå–å›¾åƒä¸­çš„å…³é”®ç‰¹å¾ï¼Œç‰¹åˆ«æ˜¯å½“ç›®æ ‡çš„å½¢çŠ¶å’Œå¤§å°åœ¨ä¸åŒå›¾åƒä¸­æœ‰æ‰€å˜åŒ–æ—¶ã€‚\nä¸ªäººæ€»ç»“ï¼š AKConvçš„é€‚åº”æ€§é‡‡æ ·ä½ç½®è°ƒæ•´ä¸ºå·ç§¯ç½‘ç»œæä¾›äº†å‰æ‰€æœªæœ‰çš„çµæ´»æ€§å’Œé€‚åº”æ€§ï¼Œä½¿å…¶èƒ½å¤Ÿå¯¹å„ç§ä¸åŒå½¢çŠ¶å’Œå°ºå¯¸çš„ç›®æ ‡å®ç°æ›´ç²¾ç¡®çš„ç‰¹å¾æå–ã€‚\n2.1.4 çº¿æ€§å¢å‡å·ç§¯å‚æ•°çš„æ•°é‡ AKConvé€šè¿‡å…¶ç‹¬ç‰¹çš„è®¾è®¡å‡å°‘äº†æ¨¡å‹å‚æ•°å’Œè®¡ç®—å¼€é”€å®ç°æ–¹å¼å¦‚ä¸‹ï¼š\n1. çº¿æ€§å‚æ•°è°ƒæ•´ï¼š AKConvå…è®¸å·ç§¯æ ¸çš„å‚æ•°æ•°é‡æ ¹æ®éœ€è¦è¿›è¡Œçº¿æ€§è°ƒæ•´ã€‚è¿™ä¸ä¼ ç»Ÿå·ç§¯ç½‘ç»œä¸­å‚æ•°æ•°é‡éšç€å·ç§¯æ ¸å°ºå¯¸å¹³æ–¹çº§å¢é•¿çš„æƒ…å†µå½¢æˆå¯¹æ¯”ã€‚é€šè¿‡æ”¯æŒå‚æ•°æ•°é‡çš„çº¿æ€§è°ƒæ•´ï¼ŒAKConvèƒ½å¤Ÿæ ¹æ®ä»»åŠ¡éœ€æ±‚å’Œç¡¬ä»¶èƒ½åŠ›çµæ´»åœ°å¢å‡æ¨¡å‹çš„å¤æ‚åº¦ã€‚\n2. ä¼˜åŒ–æ€§èƒ½ï¼š åœ¨ç¡¬ä»¶èµ„æºæœ‰é™çš„ç¯å¢ƒä¸­ï¼ŒAKConvèƒ½å¤Ÿé€šè¿‡å‡å°‘ä¸å¿…è¦çš„å‚æ•°æ¥ä¼˜åŒ–æ€§èƒ½ã€‚è¿™æ ·ä¸ä»…å‡è½»äº†å¯¹å­˜å‚¨å’Œè®¡ç®—èµ„æºçš„éœ€æ±‚ï¼Œè¿˜æœ‰åŠ©äºåŠ å¿«æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦ï¼ŒåŒæ—¶é™ä½èƒ½è€—ã€‚\n3. è½»é‡çº§æ¨¡å‹è®¾è®¡ï¼š AKConvç‰¹åˆ«é€‚åˆäºè½»é‡çº§æ¨¡å‹çš„è®¾è®¡ï¼Œè¿™ç±»æ¨¡å‹éœ€è¦åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶ï¼Œå°½å¯èƒ½åœ°å‡å°‘å‚æ•°æ•°é‡ã€‚AKConvçš„è¿™ä¸€ç‰¹æ€§ä½¿å…¶æˆä¸ºè®¾è®¡ç´§å‡‘è€Œé«˜æ•ˆæ¨¡å‹çš„ç†æƒ³é€‰æ‹©ï¼Œç‰¹åˆ«æ˜¯åœ¨ç§»åŠ¨è®¾å¤‡ã€åµŒå…¥å¼ç³»ç»Ÿå’Œç‰©è”ç½‘è®¾å¤‡ç­‰èµ„æºå—é™çš„å¹³å°ä¸Šã€‚\næ€»ç»“ï¼š AKConvé€šè¿‡æ”¯æŒå·ç§¯å‚æ•°çš„çº¿æ€§å¢å‡ï¼Œæä¾›äº†ä¸€ç§åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹ï¼Œé™ä½æ¨¡å‹å‚æ•°å’Œè®¡ç®—å¼€é”€çš„æœ‰æ•ˆæ–¹æ³•ã€‚è¿™ä½¿å¾—AKConvä¸ä»…åœ¨å®ç°é«˜ç²¾åº¦çš„ç‰¹å¾æå–æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œè€Œä¸”åœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰æ˜¾è‘—çš„èµ„æºæ•ˆç‡ä¼˜åŠ¿ã€‚\nä¸‰ã€AKConvçš„ä»£ç  åœ¨AKConvçš„å®˜æ–¹ä»£ç ä¸­æœ‰ä¸€ä¸ªç‰ˆæœ¬çš„è­¦å‘Šæˆ‘ç»™è¿›è¡Œäº†ä¸€å®šçš„å¤„ç†è§£å†³äº†ï¼Œè¯¥ä»£ç çš„ä½¿ç”¨æ–¹å¼æˆ‘ä»¬çœ‹ç« èŠ‚å››è¿›è¡Œä½¿ç”¨ã€‚\nimport math\rimport torch\rimport torch.nn as nn\rfrom einops import rearrange\r__all__ = ['AKConv', 'C3k2_AKConv']\rclass AKConv(nn.Module):\rdef __init__(self, inc, outc, num_param=2, stride=1, bias=None):\rsuper(AKConv, self).__init__()\rself.num_param = num_param\rself.stride = stride\rself.conv = nn.Sequential(nn.Conv2d(inc, outc, kernel_size=(num_param, 1), stride=(num_param, 1), bias=bias),\rnn.BatchNorm2d(outc),\rnn.SiLU()) # the conv adds the BN and SiLU to compare original Conv in YOLOv5.\rself.p_conv = nn.Conv2d(inc, 2 * num_param, kernel_size=3, padding=1, stride=stride)\rnn.init.constant_(self.p_conv.weight, 0)\rself.p_conv.register_full_backward_hook(self._set_lr)\r@staticmethod\rdef _set_lr(module, grad_input, grad_output):\rgrad_input = (grad_input[i] * 0.1 for i in range(len(grad_input)))\rgrad_output = (grad_output[i] * 0.1 for i in range(len(grad_output)))\rdef forward(self, x):\r# N is num_param.\roffset = self.p_conv(x)\rdtype = offset.data.type()\rN = offset.size(1) // 2\r# (b, 2N, h, w)\rp = self._get_p(offset, dtype)\r# (b, h, w, 2N)\rp = p.contiguous().permute(0, 2, 3, 1)\rq_lt = p.detach().floor()\rq_rb = q_lt + 1\rq_lt = torch.cat([torch.clamp(q_lt[..., :N], 0, x.size(2) - 1), torch.clamp(q_lt[..., N:], 0, x.size(3) - 1)],\rdim=-1).long()\rq_rb = torch.cat([torch.clamp(q_rb[..., :N], 0, x.size(2) - 1), torch.clamp(q_rb[..., N:], 0, x.size(3) - 1)],\rdim=-1).long()\rq_lb = torch.cat([q_lt[..., :N], q_rb[..., N:]], dim=-1)\rq_rt = torch.cat([q_rb[..., :N], q_lt[..., N:]], dim=-1)\r# clip p\rp = torch.cat([torch.clamp(p[..., :N], 0, x.size(2) - 1), torch.clamp(p[..., N:], 0, x.size(3) - 1)], dim=-1)\r# bilinear kernel (b, h, w, N)\rg_lt = (1 + (q_lt[..., :N].type_as(p) - p[..., :N])) * (1 + (q_lt[..., N:].type_as(p) - p[..., N:]))\rg_rb = (1 - (q_rb[..., :N].type_as(p) - p[..., :N])) * (1 - (q_rb[..., N:].type_as(p) - p[..., N:]))\rg_lb = (1 + (q_lb[..., :N].type_as(p) - p[..., :N])) * (1 - (q_lb[..., N:].type_as(p) - p[..., N:]))\rg_rt = (1 - (q_rt[..., :N].type_as(p) - p[..., :N])) * (1 + (q_rt[..., N:].type_as(p) - p[..., N:]))\r# resampling the features based on the modified coordinates.\rx_q_lt = self._get_x_q(x, q_lt, N)\rx_q_rb = self._get_x_q(x, q_rb, N)\rx_q_lb = self._get_x_q(x, q_lb, N)\rx_q_rt = self._get_x_q(x, q_rt, N)\r# bilinear\rx_offset = g_lt.unsqueeze(dim=1) * x_q_lt + \\\rg_rb.unsqueeze(dim=1) * x_q_rb + \\\rg_lb.unsqueeze(dim=1) * x_q_lb + \\\rg_rt.unsqueeze(dim=1) * x_q_rt\rx_offset = self._reshape_x_offset(x_offset, self.num_param)\rout = self.conv(x_offset)\rreturn out\r# generating the inital sampled shapes for the AKConv with different sizes.\rdef _get_p_n(self, N, dtype):\rbase_int = round(math.sqrt(self.num_param))\rrow_number = self.num_param // base_int\rmod_number = self.num_param % base_int\rp_n_x, p_n_y = torch.meshgrid(\rtorch.arange(0, row_number),\rtorch.arange(0, base_int))\rp_n_x = torch.flatten(p_n_x)\rp_n_y = torch.flatten(p_n_y)\rif mod_number \u0026gt; 0:\rmod_p_n_x, mod_p_n_y = torch.meshgrid(\rtorch.arange(row_number, row_number + 1),\rtorch.arange(0, mod_number))\rmod_p_n_x = torch.flatten(mod_p_n_x)\rmod_p_n_y = torch.flatten(mod_p_n_y)\rp_n_x, p_n_y = torch.cat((p_n_x, mod_p_n_x)), torch.cat((p_n_y, mod_p_n_y))\rp_n = torch.cat([p_n_x, p_n_y], 0)\rp_n = p_n.view(1, 2 * N, 1, 1).type(dtype)\rreturn p_n\r# no zero-padding\rdef _get_p_0(self, h, w, N, dtype):\rp_0_x, p_0_y = torch.meshgrid(\rtorch.arange(0, h * self.stride, self.stride),\rtorch.arange(0, w * self.stride, self.stride))\rp_0_x = torch.flatten(p_0_x).view(1, 1, h, w).repeat(1, N, 1, 1)\rp_0_y = torch.flatten(p_0_y).view(1, 1, h, w).repeat(1, N, 1, 1)\rp_0 = torch.cat([p_0_x, p_0_y], 1).type(dtype)\rreturn p_0\rdef _get_p(self, offset, dtype):\rN, h, w = offset.size(1) // 2, offset.size(2), offset.size(3)\r# (1, 2N, 1, 1)\rp_n = self._get_p_n(N, dtype)\r# (1, 2N, h, w)\rp_0 = self._get_p_0(h, w, N, dtype)\rp = p_0 + p_n + offset\rreturn p\rdef _get_x_q(self, x, q, N):\rb, h, w, _ = q.size()\rpadded_w = x.size(3)\rc = x.size(1)\r# (b, c, h*w)\rx = x.contiguous().view(b, c, -1)\r# (b, h, w, N)\rindex = q[..., :N] * padded_w + q[..., N:] # offset_x*w + offset_y\r# (b, c, h*w*N)\rindex = index.contiguous().unsqueeze(dim=1).expand(-1, c, -1, -1, -1).contiguous().view(b, c, -1)\rx_offset = x.gather(dim=-1, index=index).contiguous().view(b, c, h, w, N)\rreturn x_offset\r# Stacking resampled features in the row direction.\r@staticmethod\rdef _reshape_x_offset(x_offset, num_param):\rb, c, h, w, n = x_offset.size()\r# using Conv3d\r# x_offset = x_offset.permute(0,1,4,2,3), then Conv3d(c,c_out, kernel_size =(num_param,1,1),stride=(num_param,1,1),bias= False)\r# using 1 Ã— 1 Conv\r# x_offset = x_offset.permute(0,1,4,2,3), then, x_offset.view(b,cÃ—num_param,h,w) finally, Conv2d(cÃ—num_param,c_out, kernel_size =1,stride=1,bias= False)\r# using the column conv as followï¼Œ then, Conv2d(inc, outc, kernel_size=(num_param, 1), stride=(num_param, 1), bias=bias)\rx_offset = rearrange(x_offset, 'b c h w n -\u0026gt; b c (h n) w')\rreturn x_offset\râ€‹ â€‹ class Bottleneck(nn.Module): # Standard bottleneck with DCN def init(self, c1, c2, shortcut=True, g=1, k=(3, 3), e=0.5): # ch_in, ch_out, shortcut, groups, kernels, expand super().init() c_ = int(c2 * e) # hidden channels\nself.cv1 = Conv(c1, c_, k[0], 1)\rself.cv2 = AKConv(c_, c2, 3)\rself.add = shortcut and c1 == c2\rdef forward(self, x):\rreturn x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\rdef autopad(k, p=None, d=1): # kernel, padding, dilation\r\u0026quot;\u0026quot;\u0026quot;Pad to 'same' shape outputs.\u0026quot;\u0026quot;\u0026quot;\rif d \u0026gt; 1:\rk = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k] # actual kernel-size\rif p is None:\rp = k // 2 if isinstance(k, int) else [x // 2 for x in k] # auto-pad\rreturn p\râ€‹ â€‹ class Conv(nn.Module): \u0026ldquo;\u0026ldquo;\u0026ldquo;Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation).\u0026rdquo;\u0026rdquo;\u0026rdquo; default_act = nn.SiLU() # default activation\ndef __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):\r\u0026quot;\u0026quot;\u0026quot;Initialize Conv layer with given arguments including activation.\u0026quot;\u0026quot;\u0026quot;\rsuper().__init__()\rself.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)\rself.bn = nn.BatchNorm2d(c2)\rself.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()\rdef forward(self, x):\r\u0026quot;\u0026quot;\u0026quot;Apply convolution, batch normalization and activation to input tensor.\u0026quot;\u0026quot;\u0026quot;\rreturn self.act(self.bn(self.conv(x)))\rdef forward_fuse(self, x):\r\u0026quot;\u0026quot;\u0026quot;Perform transposed convolution of 2D data.\u0026quot;\u0026quot;\u0026quot;\rreturn self.act(self.conv(x))\râ€‹ class C2f(nn.Module): \u0026ldquo;\u0026ldquo;\u0026ldquo;Faster Implementation of CSP Bottleneck with 2 convolutions.\u0026rdquo;\u0026rdquo;\u0026rdquo;\ndef __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):\r\u0026quot;\u0026quot;\u0026quot;Initializes a CSP bottleneck with 2 convolutions and n Bottleneck blocks for faster processing.\u0026quot;\u0026quot;\u0026quot;\rsuper().__init__()\rself.c = int(c2 * e) # hidden channels\rself.cv1 = Conv(c1, 2 * self.c, 1, 1)\rself.cv2 = Conv((2 + n) * self.c, c2, 1) # optional act=FReLU(c2)\rself.m = nn.ModuleList(Bottleneck(self.c, self.c, shortcut, g, k=((3, 3), (3, 3)), e=1.0) for _ in range(n))\rdef forward(self, x):\r\u0026quot;\u0026quot;\u0026quot;Forward pass through C2f layer.\u0026quot;\u0026quot;\u0026quot;\ry = list(self.cv1(x).chunk(2, 1))\ry.extend(m(y[-1]) for m in self.m)\rreturn self.cv2(torch.cat(y, 1))\rdef forward_split(self, x):\r\u0026quot;\u0026quot;\u0026quot;Forward pass using split() instead of chunk().\u0026quot;\u0026quot;\u0026quot;\ry = list(self.cv1(x).split((self.c, self.c), 1))\ry.extend(m(y[-1]) for m in self.m)\rreturn self.cv2(torch.cat(y, 1))\rclass C3(nn.Module):\r\u0026quot;\u0026quot;\u0026quot;CSP Bottleneck with 3 convolutions.\u0026quot;\u0026quot;\u0026quot;\rdef __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\r\u0026quot;\u0026quot;\u0026quot;Initialize the CSP Bottleneck with given channels, number, shortcut, groups, and expansion values.\u0026quot;\u0026quot;\u0026quot;\rsuper().__init__()\rc_ = int(c2 * e) # hidden channels\rself.cv1 = Conv(c1, c_, 1, 1)\rself.cv2 = Conv(c1, c_, 1, 1)\rself.cv3 = Conv(2 * c_, c2, 1) # optional act=FReLU(c2)\rself.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, k=((1, 1), (3, 3)), e=1.0) for _ in range(n)))\rdef forward(self, x):\r\u0026quot;\u0026quot;\u0026quot;Forward pass through the CSP bottleneck with 2 convolutions.\u0026quot;\u0026quot;\u0026quot;\rreturn self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))\rclass C3k(C3):\r\u0026quot;\u0026quot;\u0026quot;C3k is a CSP bottleneck module with customizable kernel sizes for feature extraction in neural networks.\u0026quot;\u0026quot;\u0026quot;\rdef __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, k=3):\r\u0026quot;\u0026quot;\u0026quot;Initializes the C3k module with specified channels, number of layers, and configurations.\u0026quot;\u0026quot;\u0026quot;\rsuper().__init__(c1, c2, n, shortcut, g, e)\rc_ = int(c2 * e) # hidden channels\r# self.m = nn.Sequential(*(RepBottleneck(c_, c_, shortcut, g, k=(k, k), e=1.0) for _ in range(n)))\rself.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, k=(k, k), e=1.0) for _ in range(n)))\rclass C3k2_AKConv(C2f):\r\u0026quot;\u0026quot;\u0026quot;Faster Implementation of CSP Bottleneck with 2 convolutions.\u0026quot;\u0026quot;\u0026quot;\rdef __init__(self, c1, c2, n=1, c3k=False, e=0.5, g=1, shortcut=True):\r\u0026quot;\u0026quot;\u0026quot;Initializes the C3k2 module, a faster CSP Bottleneck with 2 convolutions and optional C3k blocks.\u0026quot;\u0026quot;\u0026quot;\rsuper().__init__(c1, c2, n, shortcut, g, e)\rself.m = nn.ModuleList(\rC3k(self.c, self.c, 2, shortcut, g) if c3k else Bottleneck(self.c, self.c, shortcut, g) for _ in range(n)\r)\râ€‹ â€‹ if name == \u0026ldquo;main\u0026rdquo;: # Generating Sample image image_size = (1, 64, 224, 224) image = torch.rand(*image_size)\n# Model\rmodel = C3k2_AKConv(64, 64)\rout = model(image)\rprint(out.size())\rå››ã€æ‰‹æŠŠæ‰‹æ•™ä½ æ·»åŠ AKConv 4.1 ä¿®æ”¹ä¸€ ç¬¬ä¸€è¿˜æ˜¯å»ºç«‹æ–‡ä»¶ï¼Œæˆ‘ä»¬æ‰¾åˆ°å¦‚ä¸‹ultralytics/nnæ–‡ä»¶å¤¹ä¸‹å»ºç«‹ä¸€ä¸ªç›®å½•åå­—å‘¢å°±æ˜¯\u0026rsquo;Addmodules\u0026rsquo;æ–‡ä»¶å¤¹( ç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€æ–°å»º) ï¼ç„¶ååœ¨å…¶å†…éƒ¨å»ºç«‹ä¸€ä¸ªæ–°çš„pyæ–‡ä»¶å°†æ ¸å¿ƒä»£ç å¤åˆ¶ç²˜è´´è¿›å»å³å¯ã€‚\n4.2 ä¿®æ”¹äºŒ ç¬¬äºŒæ­¥æˆ‘ä»¬åœ¨è¯¥ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªæ–°çš„pyæ–‡ä»¶åå­—ä¸º\u0026rsquo;init.py\u0026rsquo;( ç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€æ–°å»º) ï¼Œç„¶ååœ¨å…¶å†…éƒ¨å¯¼å…¥æˆ‘ä»¬çš„æ£€æµ‹å¤´å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\n4.3 ä¿®æ”¹ä¸‰ ç¬¬ä¸‰æ­¥æˆ‘é—¨ä¸­åˆ°å¦‚ä¸‹æ–‡ä»¶\u0026rsquo;ultralytics/nn/tasks.py\u0026rsquo;è¿›è¡Œå¯¼å…¥å’Œæ³¨å†Œæˆ‘ä»¬çš„æ¨¡å—( ç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€é‡æ–°å¯¼å…¥ç›´æ¥å¼€å§‹ç¬¬å››æ­¥å³å¯) ï¼\nä»ä»Šå¤©å¼€å§‹ä»¥åçš„æ•™ç¨‹å°±éƒ½ç»Ÿä¸€æˆè¿™ä¸ªæ ·å­äº†ï¼Œå› ä¸ºæˆ‘é»˜è®¤å¤§å®¶ç”¨äº†æˆ‘ç¾¤å†…çš„æ–‡ä»¶æ¥è¿›è¡Œä¿®æ”¹ï¼ï¼\n4.4 ä¿®æ”¹å›› æŒ‰ç…§æˆ‘çš„æ·»åŠ åœ¨parse_modelé‡Œæ·»åŠ å³å¯ã€‚\nåˆ°æ­¤å°±ä¿®æ”¹å®Œæˆäº†ï¼Œå¤§å®¶å¯ä»¥å¤åˆ¶ä¸‹é¢çš„yamlæ–‡ä»¶è¿è¡Œã€‚\n4.5 AKConvçš„yamlæ–‡ä»¶å’Œè®­ç»ƒæˆªå›¾ 4.5.1 AKConvçš„yamlæ–‡ä»¶1 æ­¤ç‰ˆæœ¬è®­ç»ƒä¿¡æ¯ï¼šYOLO11-C3k2-AKConv summary: 353 layers, 2,471,697 parameters, 2,471,681 gradients, 6.2 GFLOPs\n# Ultralytics YOLO ğŸš€, AGPL-3.0 license\r# YOLO11 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect\r# Parameters\rnc: 80 # number of classes\rscales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n'\r# [depth, width, max_channels]\rn: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs\rs: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs\rm: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs\rl: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs\rx: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs\r# YOLO11n backbone\rbackbone:\r# [from, repeats, module, args]\r- [-1, 1, Conv, [64, 3, 2]] # 0-P1/2\r- [-1, 1, Conv, [128, 3, 2]] # 1-P2/4\r- [-1, 2, C3k2_AKConv, [256, False, 0.25]]\r- [-1, 1, Conv, [256, 3, 2]] # 3-P3/8\r- [-1, 2, C3k2_AKConv, [512, False, 0.25]]\r- [-1, 1, Conv, [512, 3, 2]] # 5-P4/16\r- [-1, 2, C3k2_AKConv, [512, True]]\r- [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32\r- [-1, 2, C3k2_AKConv, [1024, True]]\r- [-1, 1, SPPF, [1024, 5]] # 9\r- [-1, 2, C2PSA, [1024]] # 10\r# YOLO11n head\rhead:\r- [-1, 1, nn.Upsample, [None, 2, \u0026quot;nearest\u0026quot;]]\r- [[-1, 6], 1, Concat, [1]] # cat backbone P4\r- [-1, 2, C3k2_AKConv, [512, False]] # 13\r- [-1, 1, nn.Upsample, [None, 2, \u0026quot;nearest\u0026quot;]]\r- [[-1, 4], 1, Concat, [1]] # cat backbone P3\r- [-1, 2, C3k2_AKConv, [256, False]] # 16 (P3/8-small)\r- [-1, 1, Conv, [256, 3, 2]]\r- [[-1, 13], 1, Concat, [1]] # cat head P4\r- [-1, 2, C3k2_AKConv, [512, False]] # 19 (P4/16-medium)\r- [-1, 1, Conv, [512, 3, 2]]\r- [[-1, 10], 1, Concat, [1]] # cat head P5\r- [-1, 2, C3k2_AKConv, [1024, True]] # 22 (P5/32-large)\r- [[16, 19, 22], 1, Detect, [nc]] # Detect(P3, P4, P5)\r4.5.2 AKConvçš„yamlæ–‡ä»¶2 æ­¤ç‰ˆæœ¬è®­ç»ƒä¿¡æ¯ï¼šYOLO11-AKConv summary: 337 layers, 2,173,923 parameters, 2,173,907 gradients, 5.5 GFLOPs\n# Ultralytics YOLO ğŸš€, AGPL-3.0 license\r# YOLO11 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect\r# Parameters\rnc: 80 # number of classes\rscales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n'\r# [depth, width, max_channels]\rn: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs\rs: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs\rm: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs\rl: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs\rx: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs\r# YOLO11n backbone\rbackbone:\r# [from, repeats, module, args]\r- [-1, 1, Conv, [64, 3, 2]] # 0-P1/2\r- [-1, 1, AKConv, [128, 3, 2]] # 1-P2/4\r- [-1, 2, C3k2, [256, False, 0.25]]\r- [-1, 1, AKConv, [256, 3, 2]] # 3-P3/8\r- [-1, 2, C3k2, [512, False, 0.25]]\r- [-1, 1, AKConv, [512, 3, 2]] # 5-P4/16\r- [-1, 2, C3k2, [512, True]]\r- [-1, 1, AKConv, [1024, 3, 2]] # 7-P5/32\r- [-1, 2, C3k2, [1024, True]]\r- [-1, 1, SPPF, [1024, 5]] # 9\r- [-1, 2, C2PSA, [1024]] # 10\r# YOLO11n head\rhead:\r- [-1, 1, nn.Upsample, [None, 2, \u0026quot;nearest\u0026quot;]]\r- [[-1, 6], 1, Concat, [1]] # cat backbone P4\r- [-1, 2, C3k2, [512, False]] # 13\r- [-1, 1, nn.Upsample, [None, 2, \u0026quot;nearest\u0026quot;]]\r- [[-1, 4], 1, Concat, [1]] # cat backbone P3\r- [-1, 2, C3k2, [256, False]] # 16 (P3/8-small)\r- [-1, 1, AKConv, [256, 3, 2]]\r- [[-1, 13], 1, Concat, [1]] # cat head P4\r- [-1, 2, C3k2, [512, False]] # 19 (P4/16-medium)\r- [-1, 1, AKConv, [512, 3, 2]]\r- [[-1, 10], 1, Concat, [1]] # cat head P5\r- [-1, 2, C3k2, [1024, True]] # 22 (P5/32-large)\r- [[16, 19, 22], 1, Detect, [nc]] # Detect(P3, P4, P5)\r4.5.3 AKConvçš„è®­ç»ƒè¿‡ç¨‹æˆªå›¾ ä¸‹é¢æ˜¯æ·»åŠ äº† AKConv çš„è®­ç»ƒæˆªå›¾ã€‚\nâ€‹â€‹â€‹â€‹\näº”ã€AKConvå¯æ·»åŠ çš„ä½ç½® 5.1 æ¨èAKConvå¯æ·»åŠ çš„ä½ç½® AKConvæ˜¯ä¸€ç§å³æ’å³ç”¨çš„æ¨¡å—\næ–‡å­—å¤§å®¶å¯èƒ½çœ‹æˆ‘æè¿°ä¸å¤ªæ‡‚ï¼Œå¤§å®¶å¯ä»¥çœ‹ä¸‹é¢çš„ç½‘ç»œç»“æ„å›¾ä¸­æˆ‘è¿›è¡Œäº†æ ‡æ³¨ã€‚\n5.2 å›¾ç¤º AKConv å¯æ·»åŠ çš„ä½ç½® â€‹â€‹â€‹â€‹\n","date":"0001-01-01T00:00:00Z","permalink":"https://nickk111.github.io/p/","title":""},{"content":"YOLOv11æ”¹è¿› | ä¸»å¹²/Backboneç¯‡ | è§†è§‰å˜æ¢å™¨SwinTransformerç›®æ ‡æ£€æµ‹ç½‘ç»œï¼ˆ é€‚é…yolov11å…¨ç³»åˆ—æ¨¡å‹ï¼‰ ä¸€ã€æœ¬æ–‡ä»‹ç» æœ¬æ–‡ç»™å¤§å®¶å¸¦æ¥çš„æ”¹è¿›æœºåˆ¶æ˜¯åˆ©ç”¨ Swin Transformer æ›¿æ¢ YOLOv11ä¸­çš„éª¨å¹²ç½‘ç»œ å…¶æ˜¯ä¸€ä¸ªå¼€åˆ›æ€§çš„è§†è§‰å˜æ¢å™¨æ¨¡å‹ï¼Œå®ƒé€šè¿‡ä½¿ç”¨ä½ç§»çª—å£æ¥æ„å»ºåˆ†å±‚çš„ç‰¹å¾å›¾ï¼Œæœ‰æ•ˆåœ°é€‚åº”äº†è®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚ä¸ä¼ ç»Ÿçš„å˜æ¢å™¨æ¨¡å‹ä¸åŒï¼ŒSwin Transformerçš„è‡ªæ³¨æ„åŠ›è®¡ç®—ä»…é™äºå±€éƒ¨çª—å£å†…ï¼Œä½¿å¾— è®¡ç®—å¤æ‚åº¦ä¸å›¾åƒå¤§å°æˆçº¿æ€§å…³ç³»ï¼Œè€ŒéäºŒæ¬¡æ–¹ ã€‚è¿™ç§è®¾è®¡ä¸ä»…æé«˜äº†æ¨¡å‹çš„æ•ˆç‡ï¼Œè¿˜ä¿æŒäº†å¼ºå¤§çš„ç‰¹å¾æå–èƒ½åŠ›ã€‚Swin Transformerçš„åˆ›æ–°åœ¨äºå…¶èƒ½å¤Ÿåœ¨ä¸åŒå±‚æ¬¡ä¸Šæ•æ‰å›¾åƒçš„ç»†èŠ‚å’Œå…¨å±€ä¿¡æ¯ï¼Œä½¿å…¶æˆä¸ºå„ç§è§†è§‰ä»»åŠ¡çš„å¼ºå¤§é€šç”¨éª¨å¹²ç½‘ç»œã€‚ äº²æµ‹åœ¨å°ç›®æ ‡æ£€æµ‹å’Œå¤§å°ºåº¦ç›®æ ‡æ£€æµ‹çš„æ•°æ®é›†ä¸Šéƒ½æœ‰æ¶¨ç‚¹æ•ˆæœã€‚\nï¼ˆæœ¬æ–‡å†…å®¹å¯æ ¹æ®yolov11çš„Nã€Sã€Mã€Lã€Xè¿›è¡ŒäºŒæ¬¡ç¼©æ”¾ï¼Œè½»é‡åŒ–æ›´ä¸Šä¸€å±‚ï¼‰\nä¸“æ å›é¡¾ï¼š ** ** ** ** ** ** YOLOv11æ”¹è¿›ç³»åˆ—ä¸“æ â€”â€”æœ¬ä¸“æ æŒç»­å¤ä¹ å„ç§é¡¶ä¼šå†…å®¹â€”â€”ç§‘ç ”å¿…å¤‡************\nç›®å½•\nä¸€ã€æœ¬æ–‡ä»‹ç»\näºŒã€Swin TransformeråŸç†\n2.1 Swin Transformerçš„åŸºæœ¬åŸç†\n2.2 å±‚æ¬¡åŒ–ç‰¹å¾æ˜ å°„\n2.3 å±€éƒ¨è‡ªæ³¨æ„åŠ›è®¡ç®—\n2.4 ç§»åŠ¨çª—å£è‡ªæ³¨æ„åŠ›\n2.5 ç§»åŠ¨çª—å£åˆ†åŒº\nä¸‰ã€ Swin Transformerçš„å®Œæ•´ä»£ç \nå››ã€æ‰‹æŠŠæ‰‹æ•™ä½ æ·»åŠ Swin Transformerç½‘ç»œç»“æ„\nä¿®æ”¹ä¸€\nä¿®æ”¹äºŒ\nä¿®æ”¹ä¸‰\nä¿®æ”¹å››\nä¿®æ”¹äº”\nä¿®æ”¹å…­\nä¿®æ”¹ä¸ƒ\nä¿®æ”¹å…«\n","date":"0001-01-01T00:00:00Z","permalink":"https://nickk111.github.io/p/","title":""},{"content":"ä½¿ç”¨Labelimgåˆ¶ä½œè‡ªå·±çš„YOLOæ•°æ®é›† ç›®æ ‡æ£€æµ‹å¸¸ç”¨æ ‡æ³¨å·¥å…·-LabelImgçš„ä½¿ç”¨ ç›®å‰æˆ‘ä»¬çš„å¾ˆå¤šæ•™ç¨‹éƒ½æ˜¯å›´ç»•ç›®æ ‡æ£€æµ‹å±•å¼€çš„ï¼Œä¸€èˆ¬æƒ…å†µä¸‹æˆ‘éƒ½æä¾›äº†æˆ‘æ ‡æ³¨å¥½çš„æ•°æ®é›†ï¼Œä½†æ˜¯æœ‰çš„å°ä¼™ä¼´éœ€è¦æ ¹æ®è‡ªå·±çš„æ•°æ®é›†æ¥è¿›è¡Œæ ‡æ³¨ï¼Œè¿™ä¸ªæ—¶å€™æŒæ¡å…¶ä¸­ä¸€ç§æ ‡æ³¨å·¥å…·çš„ä½¿ç”¨æ˜¾å¾—è‡³å…³é‡è¦ã€‚å…¶ä¸­åœ¨è®¡ç®—æœºè§†è§‰çš„ä»»åŠ¡ä¸­ï¼Œå¸¸ç”¨çš„æ ‡æ³¨å·¥å…·æœ‰ä¸¤ç±»ï¼Œä¸€ç±»æ˜¯labelimgï¼Œä¸»è¦æ˜¯ç”¨äºç›®æ ‡æ£€æµ‹ç±»æ•°æ®çš„æ ‡æ³¨ï¼Œä¸€ç±»æ˜¯labelmeï¼Œå¸¸ç”¨äºåˆ†å‰²ä»»åŠ¡çš„æ ‡æ³¨ã€‚è€ƒè™‘åˆ°å¹³æ—¶å¤§å®¶çš„ä»»åŠ¡ä»¥æ£€æµ‹ä¸ºä¸»ï¼Œæ‰€ä»¥æœ¬æœŸæˆ‘ä»¬ä¸»è¦è®²çš„æ˜¯æ ‡æ³¨è½¯ä»¶labelimgçš„ä½¿ç”¨ã€‚\nå®‰è£…labelimg labelimgçš„å®‰è£…éå¸¸ç®€å•ï¼Œåªéœ€è¦æ‰§è¡Œå¯¹åº”çš„pipæŒ‡ä»¤å³å¯ã€‚\nè¯·ä¿è¯ä½ åœ¨å®‰è£…ä¹‹å‰å·²ç»å®‰è£…å¥½äº†minicondaå’Œpycharmï¼Œå¦‚æœè¿™é‡Œè¿˜æ²¡æœ‰å®Œæˆï¼Œè¯·çœ‹è¿™æœŸè§†é¢‘ï¼šã€2024æ¯•è®¾ç³»åˆ—ã€‘Anacondaå’ŒPycharmå¦‚ä½•ä½¿ç”¨_å“”å“©å“”å“©_bilibili\né¦–å…ˆæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªå¯¹åº”çš„ç”¨äºè¿™ä¸ªæ ‡æ³¨åŠŸèƒ½çš„è™šæ‹Ÿç¯å¢ƒï¼Œè¯·æ‰§è¡Œä¸‹é¢ä¸¤ä¸ªæŒ‡ä»¤å®Œæˆè™šæ‹Ÿç¯å¢ƒçš„åˆ›å»ºå’Œæ¿€æ´»ã€‚\nconda create -n labelimg_env python==3.8.5\rconda activate labelimg_env\ræ¿€æ´»ç¯å¢ƒä¹‹åè¯·åœ¨å‘½ä»¤è¡Œä¸­å®‰è£…å¯¹åº”çš„labelimgè½¯ä»¶ã€‚\npip install labelimg\rä¹‹åå†å‘½ä»¤è¡Œä¸­è¾“å…¥labelimgå³å¯å¯åŠ¨æ ‡æ³¨è½¯ä»¶ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\nå‡†å¤‡ä½ çš„å›¾åƒæ•°æ®é›† ä¸€ä¸ªå®Œæ•´çš„ç›®æ ‡æ£€æµ‹çš„æ•°æ®é›†ç”±å›¾åƒå’Œæ ‡ç­¾æ„æˆï¼Œæ‰€ä»¥åœ¨å¼€å§‹ä¹‹å‰ã€‚ä½ éœ€è¦å…ˆå‡†å¤‡å¥½ä½ çš„å›¾åƒæ•°æ®é›†ï¼Œè¿™é‡Œçš„å›¾åƒæ•°æ®é›†å¯ä»¥æ˜¯ä½ ä»è§†é¢‘ä¸­è¿›è¡Œæˆªå–çš„ï¼Œæˆ–è€…æ˜¯ä½ ä»ä½ çš„è¯¾é¢˜ç»„æˆ–è€…æ˜¯ä½ ä»ä½ çš„é¡¹ç›®ä¸­è·å–çš„ã€‚æ€»ä¹‹ï¼Œä½ ä¼šæœ‰ä¸€å †çš„å›¾åƒæ”¾åœ¨ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸‹ã€‚\næ³¨æ„ï¼Œä½ å­˜æ”¾å›¾åƒçš„è·¯å¾„æœ€å¥½åªåŒ…å«è‹±æ–‡ï¼Œä¸­æ–‡å¯èƒ½å¯¼è‡´åç»­ä½ è¯»å–å›¾åƒçš„æ—¶å€™å‡ºç°ä¹±ç ï¼Œä¸ºäº†èƒ½å¤Ÿè®©ä½ çš„å›¾åƒä¸å‡ºç°ä¹±ç çš„é—®é¢˜ï¼Œæˆ‘è¿™é‡Œå†™äº†ä¸€æ®µè„šæœ¬ï¼Œä½ å¯ä»¥å°†ä½ çš„å›¾åƒè¿›è¡Œäº‹å…ˆçš„é‡å‘½åï¼Œä¿è¯ä½ çš„å›¾åƒè·¯å¾„ä¸ä¼šå‡ºç°é”™è¯¯ã€‚\n# -*-coding:utf-8 -*-\r\u0026quot;\u0026quot;\u0026quot;\r#-------------------------------\r# @Author : è‚†åäºŒ\r# @QQ : 3045834499 å¯å®šåˆ¶æ¯•è®¾\r#-------------------------------\r# @File : step2_get_names.py\r# @Description: æ–‡ä»¶æè¿°\r# @Software : PyCharm\r# @Time : 2024/2/14 13:20\r#-------------------------------\r\u0026quot;\u0026quot;\u0026quot;\rimport os\rimport os.path as osp\rimport numpy as np\rimport cv2\râ€‹ def cv_imread_chinese(file_path): cv_img = cv2.imdecode(np.fromfile(file_path, dtype=np.uint8), cv2.IMREAD_COLOR) return cv_img\nâ€‹ def folder_rename(src_folder_path, target_folder_path): os.makedirs(target_folder_path, exist_ok=True) file_names = os.listdir(src_folder_path) for i, file_name in enumerate(file_names): print(\u0026quot;{}:{}\u0026quot;.format(i, file_name)) src_name= osp.join(src_folder_path, file_name) src_img = cv_imread_chinese(src_name) target_path = osp.join(target_folder_path, \u0026ldquo;yolo_data_{}.jpg\u0026rdquo;.format(i)) cv2.imwrite( target_path,src_img ) # os.rename(src_name, target_name)\nif __name__ == '__main__':\r# è„šæœ¬åº”è¯¥ç”Ÿæˆåœ¨ä¸€ä¸ªæ–°çš„ç›®å½•ä¸‹ï¼Œé˜²æ­¢å‡ºé”™\rfolder_rename(\u0026quot;test_data/ä¸­æ–‡è·¯å¾„\u0026quot;, \u0026quot;test_data/english_path\u0026quot;)\râ€‹\næœ‰äº†å›¾åƒæ•°æ®é›†ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹è¿›è¡Œæ ‡æ³¨äº†, è¿™é‡Œæˆ‘æ”¾äº†ä¸€æ®µé»‘ç¥è¯æ‚Ÿç©ºä¸­çš„å›¾åƒæ•°æ®é›†ï¼Œä¸€ä¼šæˆ‘ä»¬å°†ä¼šä½¿ç”¨è¿™ä¸ªå›¾åƒæ•°æ®é›†æ¥å®Œæˆæ ‡æ³¨çš„ä»»åŠ¡ã€‚\nä½¿ç”¨labelimg åœ¨ç›®æ ‡æ£€æµ‹çš„é¢†åŸŸä¸­ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ä½ å°†ä¼šæ¥è§¦åˆ°ä¸‰ä¸ªæ ¼å¼çš„æ•°æ®ï¼Œåˆ†åˆ«æ˜¯txtæ ¼å¼çš„yoloæ•°æ®ï¼Œxmlæ ¼å¼çš„vocæ•°æ®é›†ä»¥åŠjsonæ ¼å¼çš„cocoæ•°æ®ï¼Œä»–ä»¬åœ¨ç›®æ ‡æ£€æµ‹æ•°æ®çš„è¡¨ç¤ºä¸Šé¢å„æœ‰ä¸åŒã€‚ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œä¸ºäº†è®­ç»ƒæ–¹ä¾¿ï¼Œå¤§å®¶é€‰æ‹©å¸¸ç”¨çš„cocoæ•°æ®ï¼Œä½†æ˜¯ä¸ºäº†çµæ´»æ€§è€ƒè™‘çš„è¯ï¼Œ å¯èƒ½æ˜¯æ ‡æ³¨ä¸ºvocæ ¼å¼æ•°æ®æ›´å¥½ï¼Œå› ä¸ºyoloæ ¼å¼ä¸­çš„æ•°æ®labelçš„idæ˜¯å›ºå®šçš„ï¼Œè¿™å°†ä¼šå¯¼è‡´åé¢å¢åŠ ç±»åˆ«æˆ–è€…å‡å°‘ç±»åˆ«çš„æ—¶å€™ä¼šå‡ºç°é—®é¢˜ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªå…¸å‹çš„æ ‡æ³¨åŒºåŸŸï¼Œåœ¨æ ‡æ³¨ä¹‹å‰è¯·ä½ å…ˆè¿›è¡Œä¸€ä¸‹è‡ªåŠ¨ä¿å­˜çš„è®¾ç½®ï¼Œè¿™æ ·çš„è¯å°±ä¸ç”¨åå¤çš„è¿›è¡Œä¿å­˜çš„ç¡®è®¤äº†ã€‚\nä¸‹é¢æœ‰ä¸€äº›å¸¸ç”¨çš„å¿«æ·é”®ï¼Œä½¿ç”¨è¿™äº›å¿«æ·é”®å¯ä»¥å¸®åŠ©ä½ å¿«é€Ÿè¿›è¡Œæ ‡æ³¨ã€‚\nå¿«æ·é”® åŠŸèƒ½ Ctrl + u Load all of the images from a directory Ctrl + r Change the default annotation target dir Ctrl + s Save Ctrl + d Copy the current label and rect box Ctrl + Shift + d Delete the current image Space Flag the current image as verified w Create a rect box d Next image a Previous image del Delete the selected rect box Ctrl++ Zoom in Ctrlâ€“ Zoom out â†‘â†’â†“â† Keyboard arrows to move selected rect box ä½¿ç”¨yoloçš„æ ¼å¼è¿›è¡Œæ ‡æ³¨ å¦‚æœä½¿ç”¨yoloæ ¼å¼è¿›è¡Œæ ‡æ³¨ï¼Œä½ å¯ä»¥æå‰å®šä¹‰å¥½æ ‡ç­¾ç„¶åè¿›è¡ŒåŠ è½½ã€‚\npython3 labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]\rYOLOï¼ˆYou Only Look Onceï¼‰æ˜¯ä¸€ç§å¹¿æ³›ç”¨äºç›®æ ‡æ£€æµ‹çš„ç®—æ³•ï¼ŒYOLOçš„è®­ç»ƒæ•°æ®æ ¼å¼å¯¹äºæ„å»ºè‡ªå®šä¹‰æ•°æ®é›†éå¸¸é‡è¦ã€‚YOLOçš„æ ‡ç­¾æ–‡ä»¶é€šå¸¸æ˜¯ .txt æ ¼å¼ï¼Œå¹¶ä¸”æ¯ä¸ªå›¾åƒæ–‡ä»¶éƒ½å¯¹åº”ä¸€ä¸ªåŒåçš„æ ‡ç­¾æ–‡ä»¶ã€‚è¿™äº›æ ‡ç­¾æ–‡ä»¶ä¸­å­˜å‚¨äº†å›¾åƒä¸­ç‰©ä½“çš„ç±»åˆ«å’Œä½ç½®ä¿¡æ¯ã€‚\nYOLOæ•°æ®æ ¼å¼è¯´æ˜ï¼š å›¾åƒæ–‡ä»¶ ï¼š * å›¾åƒæ–‡ä»¶é€šå¸¸æ˜¯ `.jpg`ã€`.png` æˆ–å…¶ä»–å¸¸è§çš„å›¾åƒæ ¼å¼ã€‚\r* å›¾åƒçš„å°ºå¯¸å’Œåˆ†è¾¨ç‡å¯ä»¥æ ¹æ®æ•°æ®é›†è°ƒæ•´ï¼Œä½†åœ¨è®­ç»ƒå‰å›¾åƒé€šå¸¸ä¼šè¢«ç¼©æ”¾åˆ°å›ºå®šå°ºå¯¸ï¼ˆä¾‹å¦‚ YOLOv3 çš„é»˜è®¤è¾“å…¥æ˜¯ 416x416ï¼‰ã€‚\ræ ‡ç­¾æ–‡ä»¶ ï¼š * æ ‡ç­¾æ–‡ä»¶æ˜¯çº¯æ–‡æœ¬æ–‡ä»¶ï¼Œæ‰©å±•åä¸º `.txt`ã€‚\r* æ¯ä¸ªå›¾åƒæ–‡ä»¶æœ‰ä¸€ä¸ªå¯¹åº”çš„ `.txt` æ–‡ä»¶ï¼Œæ–‡ä»¶åä¸å›¾åƒæ–‡ä»¶åç›¸åŒï¼ˆä½†æ‰©å±•åä¸åŒï¼‰ã€‚\r* æ ‡ç­¾æ–‡ä»¶ä¸­æ¯ä¸€è¡Œä»£è¡¨ä¸€ä¸ªç›®æ ‡ï¼Œæ¯ä¸€è¡ŒåŒ…å«ä»¥ä¸‹äº”ä¸ªå€¼ï¼š\r\u0026lt;object-class\u0026gt; \u0026lt;x_center\u0026gt; \u0026lt;y_center\u0026gt; \u0026lt;width\u0026gt; \u0026lt;height\u0026gt;\r* **object-class** : ç‰©ä½“çš„ç±»åˆ«IDï¼Œä» 0 å¼€å§‹ã€‚å‡è®¾æ•°æ®é›†ä¸­æœ‰ 3 ç±»ç‰©ä½“ï¼Œç±»åˆ«ç¼–å·ä¼šæ˜¯ 0ã€1ã€2 ç­‰ã€‚\r* **x_center** : ç‰©ä½“è¾¹ç•Œæ¡†ä¸­å¿ƒç‚¹çš„ x åæ ‡ï¼Œç›¸å¯¹äºå›¾åƒçš„å®½åº¦è¿›è¡Œå½’ä¸€åŒ–ï¼ŒèŒƒå›´ä¸º 0 åˆ° 1 ä¹‹é—´ï¼ˆä¾‹å¦‚ï¼š0.5 è¡¨ç¤ºåœ¨å›¾åƒçš„æ­£ä¸­é—´ï¼‰ã€‚\r* **y_center** : ç‰©ä½“è¾¹ç•Œæ¡†ä¸­å¿ƒç‚¹çš„ y åæ ‡ï¼Œç›¸å¯¹äºå›¾åƒçš„é«˜åº¦è¿›è¡Œå½’ä¸€åŒ–ï¼ŒèŒƒå›´ä¸º 0 åˆ° 1 ä¹‹é—´ã€‚\r* **width** : è¾¹ç•Œæ¡†çš„å®½åº¦ï¼Œç›¸å¯¹äºå›¾åƒçš„å®½åº¦è¿›è¡Œå½’ä¸€åŒ–ï¼ŒèŒƒå›´ä¸º 0 åˆ° 1 ä¹‹é—´ã€‚\r* **height** : è¾¹ç•Œæ¡†çš„é«˜åº¦ï¼Œç›¸å¯¹äºå›¾åƒçš„é«˜åº¦è¿›è¡Œå½’ä¸€åŒ–ï¼ŒèŒƒå›´ä¸º 0 åˆ° 1 ä¹‹é—´ã€‚\rå…·ä½“ä¾‹å­ï¼š å‡è®¾æœ‰ä¸€ä¸ªå›¾åƒæ–‡ä»¶ dog.jpgï¼Œå…¶å¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶ dog.txt å†…å®¹å¦‚ä¸‹ï¼š\n0.5 0.5 0.4 0.6\r0.3 0.3 0.2 0.3\rç¬¬ä¸€è¡Œï¼šç‰©ä½“ç±»åˆ«ä¸º 0ï¼ˆå‡è®¾æ˜¯ç‹—ï¼‰ï¼Œå…¶è¾¹ç•Œæ¡†ä¸­å¿ƒä½äºå›¾åƒçš„æ­£ä¸­é—´ (0.5, 0.5)ï¼Œå®½åº¦ä¸ºå›¾åƒçš„ 40%ï¼ˆ0.4ï¼‰ï¼Œé«˜åº¦ä¸ºå›¾åƒçš„ 60%ï¼ˆ0.6ï¼‰ã€‚ ç¬¬äºŒè¡Œï¼šç‰©ä½“ç±»åˆ«ä¸º 1ï¼ˆå‡è®¾æ˜¯çŒ«ï¼‰ï¼Œå…¶è¾¹ç•Œæ¡†ä¸­å¿ƒä½äº (0.3, 0.3)ï¼Œå®½åº¦ä¸ºå›¾åƒçš„ 20%ï¼ˆ0.2ï¼‰ï¼Œé«˜åº¦ä¸ºå›¾åƒçš„ 30%ï¼ˆ0.3ï¼‰ã€‚ YOLOæ ¼å¼çš„æ³¨æ„äº‹é¡¹ï¼š æ‰€æœ‰çš„åæ ‡å’Œå°ºå¯¸éƒ½éœ€è¦å½’ä¸€åŒ–ä¸ºç›¸å¯¹äºå›¾åƒå®½åº¦å’Œé«˜åº¦çš„å€¼ã€‚å³ (x_center, y_center, width, height) éƒ½æ˜¯ 0 åˆ° 1 ä¹‹é—´çš„å°æ•°ã€‚ ç‰©ä½“ç±»åˆ«IDæ˜¯ä» 0 å¼€å§‹çš„æ•´æ•°ã€‚ å¦‚æœä¸€å¼ å›¾ç‰‡ä¸­æœ‰å¤šä¸ªç‰©ä½“ï¼Œæ ‡ç­¾æ–‡ä»¶ä¸­æ¯ä¸ªç‰©ä½“éƒ½å æ®ä¸€è¡Œã€‚ ç±»åˆ«æ–‡ä»¶ï¼š é€šå¸¸ï¼ŒYOLOä¼šæœ‰ä¸€ä¸ªé¢å¤–çš„ç±»åˆ«æ–‡ä»¶ï¼Œé€šå¸¸æ˜¯ classes.names æˆ– obj.namesï¼Œè¯¥æ–‡ä»¶åˆ—å‡ºæ‰€æœ‰çš„ç±»åˆ«åç§°ï¼Œæ¯è¡Œä¸€ä¸ªç±»åˆ«ã€‚ä¾‹å¦‚ï¼š\ndog\rcat\rcar\rè¿™ä¸ªæ–‡ä»¶çš„é¡ºåºå’Œæ ‡ç­¾æ–‡ä»¶ä¸­çš„ object-class å¯¹åº”ã€‚\nä½¿ç”¨vocçš„æ ¼å¼è¿›è¡Œæ ‡æ³¨ Pascal VOCï¼ˆVisual Object Classesï¼‰æ˜¯ç›®æ ‡æ£€æµ‹é¢†åŸŸéå¸¸æµè¡Œçš„æ•°æ®é›†æ ¼å¼ï¼Œå°¤å…¶åœ¨æ—©æœŸç›®æ ‡æ£€æµ‹ç ”ç©¶ä¸­è¢«å¹¿æ³›ä½¿ç”¨ã€‚Pascal VOC æ•°æ®é›†æ ¼å¼ä¸ YOLO æ ¼å¼ä¸åŒï¼ŒVOC ä½¿ç”¨ XML æ–‡ä»¶æ¥æ ‡æ³¨ç›®æ ‡æ£€æµ‹æ•°æ®ã€‚è¿™äº› XML æ–‡ä»¶åŸºäº PASCAL VOC Challenge çš„æ ‡å‡†ï¼Œä¸”ç»“æ„åŒ–ä¿¡æ¯è¾ƒä¸ºä¸°å¯Œï¼Œä¾¿äºæ‰©å±•ã€‚\nVOCæ•°æ®æ ¼å¼è¯´æ˜ æ¯ä¸ªå›¾åƒå¯¹åº”ä¸€ä¸ª XML æ ‡æ³¨æ–‡ä»¶ï¼Œæ ¼å¼ä¸º Pascal VOC å®šä¹‰çš„ XML æ–‡ä»¶ã€‚æ–‡ä»¶ç»“æ„æè¿°äº†å›¾åƒä¸­ç‰©ä½“çš„ç±»åˆ«ã€ä½ç½®ï¼ˆä½¿ç”¨æœªå½’ä¸€åŒ–çš„åƒç´ åæ ‡ï¼‰ã€éš¾åº¦ç­‰ä¿¡æ¯ã€‚\nPascal VOCæ•°æ®ç»“æ„ å›¾åƒæ–‡ä»¶ ï¼š\nå›¾åƒæ–‡ä»¶é€šå¸¸ä¸º .jpg æˆ– .png æ ¼å¼ï¼Œå­˜å‚¨åœ¨ JPEGImages æ–‡ä»¶å¤¹ä¸­ã€‚ æ ‡ç­¾æ–‡ä»¶ ï¼š\næ ‡ç­¾æ–‡ä»¶æ˜¯ XML æ ¼å¼çš„ï¼Œé€šå¸¸å­˜å‚¨åœ¨ Annotations æ–‡ä»¶å¤¹ä¸­ï¼Œæ¯ä¸ªå›¾åƒæ–‡ä»¶å¯¹åº”ä¸€ä¸ª XML æ ‡ç­¾æ–‡ä»¶ï¼Œæ–‡ä»¶åä¸å›¾åƒåç›¸åŒã€‚ ä¸»è¦çš„ XML æ ‡ç­¾è¯´æ˜ ä¸‹é¢æ˜¯ä¸€ä¸ª Pascal VOC çš„æ ‡ç­¾æ–‡ä»¶çš„ä¾‹å­ 2007_000027.xmlï¼š\n\u0026lt;annotation\u0026gt;\r\u0026lt;folder\u0026gt;VOC2007\u0026lt;/folder\u0026gt;\r\u0026lt;filename\u0026gt;2007_000027.jpg\u0026lt;/filename\u0026gt;\r\u0026lt;size\u0026gt;\r\u0026lt;width\u0026gt;486\u0026lt;/width\u0026gt;\r\u0026lt;height\u0026gt;500\u0026lt;/height\u0026gt;\r\u0026lt;depth\u0026gt;3\u0026lt;/depth\u0026gt;\r\u0026lt;/size\u0026gt;\r\u0026lt;object\u0026gt;\r\u0026lt;name\u0026gt;dog\u0026lt;/name\u0026gt;\r\u0026lt;pose\u0026gt;Left\u0026lt;/pose\u0026gt;\r\u0026lt;truncated\u0026gt;1\u0026lt;/truncated\u0026gt;\r\u0026lt;difficult\u0026gt;0\u0026lt;/difficult\u0026gt;\r\u0026lt;bndbox\u0026gt;\r\u0026lt;xmin\u0026gt;48\u0026lt;/xmin\u0026gt;\r\u0026lt;ymin\u0026gt;240\u0026lt;/ymin\u0026gt;\r\u0026lt;xmax\u0026gt;195\u0026lt;/xmax\u0026gt;\r\u0026lt;ymax\u0026gt;371\u0026lt;/ymax\u0026gt;\r\u0026lt;/bndbox\u0026gt;\r\u0026lt;/object\u0026gt;\r\u0026lt;object\u0026gt;\r\u0026lt;name\u0026gt;person\u0026lt;/name\u0026gt;\r\u0026lt;pose\u0026gt;Unspecified\u0026lt;/pose\u0026gt;\r\u0026lt;truncated\u0026gt;0\u0026lt;/truncated\u0026gt;\r\u0026lt;difficult\u0026gt;0\u0026lt;/difficult\u0026gt;\r\u0026lt;bndbox\u0026gt;\r\u0026lt;xmin\u0026gt;8\u0026lt;/xmin\u0026gt;\r\u0026lt;ymin\u0026gt;12\u0026lt;/ymin\u0026gt;\r\u0026lt;xmax\u0026gt;352\u0026lt;/xmax\u0026gt;\r\u0026lt;ymax\u0026gt;498\u0026lt;/ymax\u0026gt;\r\u0026lt;/bndbox\u0026gt;\r\u0026lt;/object\u0026gt;\r\u0026lt;/annotation\u0026gt;\ræ ‡ç­¾è§£æ ****ï¼šæ ¹èŠ‚ç‚¹ï¼ŒåŒ…å«æ‰€æœ‰å›¾åƒå’Œç‰©ä½“çš„ä¿¡æ¯ã€‚\n****ï¼šå›¾åƒæ‰€åœ¨æ–‡ä»¶å¤¹çš„åç§°ã€‚\n****ï¼šå›¾åƒæ–‡ä»¶åï¼Œé€šå¸¸æ˜¯.jpg æ–‡ä»¶ã€‚\n****ï¼šå›¾åƒçš„å°ºå¯¸ä¿¡æ¯ï¼š\n* ****ï¼šå›¾åƒçš„å®½åº¦ï¼Œä»¥åƒç´ ä¸ºå•ä½ã€‚\r* ****ï¼šå›¾åƒçš„é«˜åº¦ï¼Œä»¥åƒç´ ä¸ºå•ä½ã€‚\r* ****ï¼šå›¾åƒçš„é€šé“æ•°ï¼Œé€šå¸¸ä¸º 3ï¼ˆRGB å›¾åƒï¼‰ã€‚\r****ï¼šæ¯ä¸ªå›¾åƒä¸­çš„ç‰©ä½“å¯¹è±¡çš„æ ‡ç­¾ï¼ŒåŒ…å«å¤šä¸ªå­å…ƒç´ ã€‚å›¾åƒä¸­æ¯ä¸ªæ£€æµ‹åˆ°çš„ç›®æ ‡éƒ½æœ‰ä¸€ä¸ª\u0026lt;object\u0026gt; æ ‡ç­¾ï¼š * ****ï¼šç‰©ä½“çš„ç±»åˆ«åç§°ï¼Œä¾‹å¦‚ â€œdogâ€ã€â€œpersonâ€ ç­‰ã€‚\r* ****ï¼šç‰©ä½“çš„å§¿æ€ï¼ˆé€‰å¡«ï¼‰ï¼Œæè¿°ç‰©ä½“çš„æ–¹å‘ï¼ˆå¦‚ â€œLeftâ€ã€â€œRightâ€ ç­‰ï¼‰ã€‚\r* ****ï¼šæ ‡è®°ç‰©ä½“æ˜¯å¦è¢«æˆªæ–­ï¼Œ1 è¡¨ç¤ºç‰©ä½“è¢«æˆªæ–­ï¼Œ0 è¡¨ç¤ºæ²¡æœ‰ã€‚è¢«æˆªæ–­çš„ç‰©ä½“å¯èƒ½åªæ˜¾ç¤ºäº†ä¸€éƒ¨åˆ†ã€‚\r* ****ï¼šæ ‡è®°ç‰©ä½“æ˜¯å¦éš¾ä»¥æ£€æµ‹ï¼Œ1 è¡¨ç¤ºéš¾æ£€æµ‹ï¼Œ0 è¡¨ç¤ºå®¹æ˜“æ£€æµ‹ã€‚è¿™ä¸ªæ ‡ç­¾å¸¸ç”¨äºè¯„ä¼°ç®—æ³•çš„æ£€æµ‹æ€§èƒ½ã€‚\r* ****ï¼šç‰©ä½“è¾¹ç•Œæ¡†ï¼ˆbounding boxï¼‰çš„åæ ‡ï¼ŒåŒ…å«ï¼š\r* ****ï¼šè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ x åæ ‡ã€‚\r* ****ï¼šè¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„ y åæ ‡ã€‚\r* ****ï¼šè¾¹ç•Œæ¡†å³ä¸‹è§’çš„ x åæ ‡ã€‚\r* ****ï¼šè¾¹ç•Œæ¡†å³ä¸‹è§’çš„ y åæ ‡ã€‚\r* åæ ‡æ˜¯ä»¥åƒç´ ä¸ºå•ä½çš„ **ç»å¯¹å€¼** ï¼Œè€Œä¸æ˜¯åƒ YOLO ä¸­å½’ä¸€åŒ–åˆ° 0 å’Œ 1 çš„åæ ‡ã€‚\rPascal VOCæ–‡ä»¶ç»“æ„ ä¸€ä¸ªå…¸å‹çš„ VOC æ•°æ®é›†çš„æ–‡ä»¶ç»“æ„å¦‚ä¸‹ï¼š\nVOCdevkit/\râ””â”€â”€ VOC2007/\râ”œâ”€â”€ Annotations/ # å­˜å‚¨ XML æ ¼å¼çš„æ ‡ç­¾æ–‡ä»¶\râ”œâ”€â”€ ImageSets/ # åŒ…å«è®­ç»ƒã€æµ‹è¯•é›†åˆ’åˆ†ä¿¡æ¯çš„æ–‡ä»¶å¤¹\râ”‚ â””â”€â”€ Main/ # åŒ…å« train.txt, val.txt, test.txt ç­‰\râ”œâ”€â”€ JPEGImages/ # å­˜å‚¨æ‰€æœ‰çš„å›¾åƒæ–‡ä»¶\râ”œâ”€â”€ SegmentationClass/ # å­˜å‚¨è¯­ä¹‰åˆ†å‰²çš„æ ‡ç­¾æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰\râ””â”€â”€ SegmentationObject/ # å­˜å‚¨å¯¹è±¡çº§åˆ†å‰²çš„æ ‡ç­¾æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰\rAnnotations ï¼šå­˜å‚¨æ¯å¼ å›¾åƒçš„æ ‡æ³¨æ–‡ä»¶ï¼Œæ ¼å¼ä¸º XMLã€‚ ImageSets/Main ï¼šå­˜å‚¨æ•°æ®é›†åˆ’åˆ†çš„æ–‡ä»¶ï¼ˆå¦‚ train.txt, val.txt, test.txtï¼‰ï¼Œæ¯ä¸ªæ–‡ä»¶åŒ…å«ç”¨äºè®­ç»ƒã€éªŒè¯ã€æµ‹è¯•çš„å›¾åƒæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ã€‚ JPEGImages ï¼šå­˜å‚¨æ‰€æœ‰çš„å›¾åƒæ–‡ä»¶ã€‚ SegmentationClass å’Œ SegmentationObject ï¼šç”¨äºè¯­ä¹‰åˆ†å‰²ä»»åŠ¡çš„æ ‡æ³¨ï¼ˆå¯é€‰ï¼‰ã€‚ Pascal VOCæ ‡ç­¾æ–‡ä»¶çš„æ³¨æ„äº‹é¡¹ æ¯ä¸ª \u0026lt;object\u0026gt; æ ‡ç­¾æè¿°å›¾åƒä¸­çš„ä¸€ä¸ªç›®æ ‡å¯¹è±¡ï¼Œå› æ­¤å¦‚æœå›¾åƒä¸­æœ‰å¤šä¸ªç›®æ ‡ï¼Œåˆ™ XML æ–‡ä»¶ä¸­ä¼šæœ‰å¤šä¸ª \u0026lt;object\u0026gt; æ ‡ç­¾ã€‚ æ ‡æ³¨çš„åæ ‡ä¸ºåƒç´ çº§åˆ«ï¼Œé€šå¸¸ä¸éœ€è¦å½’ä¸€åŒ–ã€‚ truncated å’Œ difficult æ ‡ç­¾ç”¨äºæ›´ç»†è‡´åœ°æè¿°ç›®æ ‡å¯¹è±¡ï¼Œå°¤å…¶æ˜¯åœ¨è¯„ä¼°æ¨¡å‹æ—¶ï¼Œdifficult æ ‡ç­¾çš„ç›®æ ‡å¯ä»¥é€‰æ‹©å¿½ç•¥ã€‚ å¦‚ä½•å°†Pascal VOCæ ¼å¼è½¬æ¢ä¸ºå…¶ä»–æ ¼å¼ï¼ˆå¦‚YOLOï¼‰ï¼š å¦‚æœéœ€è¦å°† Pascal VOC æ ¼å¼è½¬æ¢ä¸º YOLO æ ¼å¼ï¼Œå¯ä»¥å°†æ¯ä¸ªç›®æ ‡çš„ (xmin, ymin, xmax, ymax) åæ ‡è½¬æ¢ä¸º YOLO æ ¼å¼ä¸­çš„ (x_center, y_center, width, height)ï¼Œå¹¶è¿›è¡Œå½’ä¸€åŒ–æ“ä½œã€‚å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š\nè®¡ç®—è¾¹ç•Œæ¡†çš„ä¸­å¿ƒç‚¹ï¼š * `x_center = (xmin + xmax) / 2`\r* `y_center = (ymin + ymax) / 2`\rè®¡ç®—è¾¹ç•Œæ¡†çš„å®½åº¦å’Œé«˜åº¦ï¼š * `width = xmax - xmin`\r* `height = ymax - ymin`\rå°†ä¸­å¿ƒç‚¹åæ ‡ã€å®½åº¦å’Œé«˜åº¦å½’ä¸€åŒ–ä¸ºç›¸å¯¹äºå›¾åƒå®½åº¦å’Œé«˜åº¦çš„å€¼ã€‚ å¦‚æœæ‚¨éœ€è¦å…·ä½“çš„ä»£ç ç¤ºä¾‹æ¥å®ç°è¿™ä¸ªè½¬æ¢ï¼Œæˆ‘ä¹Ÿå¯ä»¥ä¸ºæ‚¨æä¾›ã€‚\nä½¿ç”¨cocoçš„æ ¼å¼è¿›è¡Œæ ‡æ³¨ COCOï¼ˆCommon Objects in Contextï¼‰æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸæœ€å¹¿æ³›ä½¿ç”¨çš„ç›®æ ‡æ£€æµ‹æ•°æ®é›†ä¹‹ä¸€ã€‚COCO æ•°æ®é›†é‡‡ç”¨ JSON æ–‡ä»¶æ ¼å¼æ¥å­˜å‚¨ç›®æ ‡æ£€æµ‹ã€åˆ†å‰²ã€å…³é”®ç‚¹æ£€æµ‹ç­‰æ ‡æ³¨ä¿¡æ¯ã€‚ç”±äº COCO æ•°æ®é›†ä¿¡æ¯éå¸¸ä¸°å¯Œï¼Œå…¶æ ‡æ³¨æ–‡ä»¶ä¹Ÿç›¸å¯¹å¤æ‚ï¼Œå°¤å…¶ç›¸æ¯”äº YOLO å’Œ Pascal VOC æ ¼å¼ã€‚\nCOCO æ•°æ®é›†æ ¼å¼æ¦‚è¿° COCO æ•°æ®é›†çš„æ ‡æ³¨æ–‡ä»¶æ˜¯ JSON æ ¼å¼ï¼ŒåŒ…å«äº†å¤§é‡å…³äºå›¾åƒã€ç±»åˆ«ã€ç›®æ ‡æ£€æµ‹æ¡†ã€åˆ†å‰²ã€å…³é”®ç‚¹ç­‰çš„è¯¦ç»†ä¿¡æ¯ã€‚COCO ç›®æ ‡æ£€æµ‹æ•°æ®çš„æ ‡æ³¨æ–‡ä»¶é€šå¸¸ä¼šåŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªå…³é”®éƒ¨åˆ†ï¼š\ninfo ï¼šå…³äºæ•°æ®é›†çš„æè¿°ä¿¡æ¯ï¼ˆç‰ˆæœ¬ã€æ—¥æœŸã€è´¡çŒ®è€…ç­‰ï¼‰ã€‚ images ï¼šå›¾åƒçš„åŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬å›¾åƒçš„æ–‡ä»¶åã€å®½åº¦ã€é«˜åº¦ã€å”¯ä¸€ ID ç­‰ã€‚ annotations ï¼šç›®æ ‡çš„æ ‡æ³¨ä¿¡æ¯ï¼ŒåŒ…å«ç±»åˆ«ã€è¾¹ç•Œæ¡†ã€åˆ†å‰²åŒºåŸŸã€ç›®æ ‡ ID ç­‰ã€‚ categories ï¼šç±»åˆ«ä¿¡æ¯ï¼Œå®šä¹‰äº†æ‰€æœ‰çš„ç›®æ ‡ç±»åˆ«åŠå…¶å¯¹åº”çš„ IDã€‚ 1. JSONæ–‡ä»¶ç»“æ„ å…¸å‹çš„ COCO ç›®æ ‡æ£€æµ‹æ ‡æ³¨æ–‡ä»¶ç»“æ„å¦‚ä¸‹ï¼š\n{\r\u0026quot;info\u0026quot;: {...}, # æ•°æ®é›†çš„åŸºæœ¬ä¿¡æ¯\r\u0026quot;licenses\u0026quot;: [...], # å›¾åƒçš„æˆæƒä¿¡æ¯\r\u0026quot;images\u0026quot;: [...], # å›¾åƒçš„ä¿¡æ¯\r\u0026quot;annotations\u0026quot;: [...], # æ¯ä¸ªç›®æ ‡çš„æ ‡æ³¨ä¿¡æ¯\r\u0026quot;categories\u0026quot;: [...] # ç±»åˆ«ä¿¡æ¯\r}\r2. ä¸»è¦å­—æ®µè¯´æ˜ 2.1 imagesï¼šå›¾åƒä¿¡æ¯ images åˆ—è¡¨å­˜å‚¨äº†æ¯ä¸ªå›¾åƒçš„åŸºæœ¬ä¿¡æ¯ã€‚æ¯ä¸ªå›¾åƒæœ‰å¦‚ä¸‹å­—æ®µï¼š\n\u0026quot;images\u0026quot;: [\r{\r\u0026quot;id\u0026quot;: 397133,\r\u0026quot;width\u0026quot;: 640,\r\u0026quot;height\u0026quot;: 480,\r\u0026quot;file_name\u0026quot;: \u0026quot;000000397133.jpg\u0026quot;\r},\r...\r]\ridï¼šå›¾åƒçš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œå…¶ä»–éƒ¨åˆ†å¦‚ annotations å°†ä½¿ç”¨è¿™ä¸ª ID å¼•ç”¨å¯¹åº”çš„å›¾åƒã€‚ widthï¼šå›¾åƒçš„å®½åº¦ï¼ˆä»¥åƒç´ ä¸ºå•ä½ï¼‰ã€‚ heightï¼šå›¾åƒçš„é«˜åº¦ï¼ˆä»¥åƒç´ ä¸ºå•ä½ï¼‰ã€‚ file_nameï¼šå›¾åƒçš„æ–‡ä»¶åã€‚ 2.2 annotationsï¼šæ ‡æ³¨ä¿¡æ¯ annotations åˆ—è¡¨å­˜å‚¨äº†æ¯ä¸ªç›®æ ‡çš„æ ‡æ³¨ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç›®æ ‡çš„è¾¹ç•Œæ¡†ã€ç±»åˆ«ã€åˆ†å‰²æ©ç ç­‰ã€‚ä¸€ä¸ªå…¸å‹çš„ annotation å¦‚ä¸‹ï¼š\n\u0026quot;annotations\u0026quot;: [\r{\r\u0026quot;id\u0026quot;: 1,\r\u0026quot;image_id\u0026quot;: 397133,\r\u0026quot;category_id\u0026quot;: 18,\r\u0026quot;bbox\u0026quot;: [73.77, 150.54, 227.85, 304.35],\r\u0026quot;area\u0026quot;: 69321.27,\r\u0026quot;segmentation\u0026quot;: [[192.81, 247.09, 225.11, 249.06, ...]],\r\u0026quot;iscrowd\u0026quot;: 0\r},\r...\r]\ridï¼šæ ‡æ³¨çš„å”¯ä¸€ IDã€‚ image_idï¼šå¯¹åº”çš„å›¾åƒ IDï¼Œç”¨äºå°†æ ‡æ³¨ä¸å›¾åƒå¯¹åº”ã€‚ category_idï¼šç±»åˆ«çš„ IDï¼Œè¡¨ç¤ºè¿™ä¸ªç›®æ ‡çš„ç±»åˆ«ï¼Œå‚è€ƒ categories éƒ¨åˆ†ã€‚ bboxï¼šç›®æ ‡çš„è¾¹ç•Œæ¡†ï¼ˆbounding boxï¼‰ï¼Œæ ¼å¼ä¸º [x, y, width, height]ï¼Œè¿™é‡Œçš„ x å’Œ y æ˜¯è¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„åæ ‡ï¼Œwidth å’Œ height æ˜¯è¾¹ç•Œæ¡†çš„å®½åº¦å’Œé«˜åº¦ï¼ˆä»¥åƒç´ ä¸ºå•ä½ï¼‰ã€‚ areaï¼šè¾¹ç•Œæ¡†çš„é¢ç§¯ï¼ˆbbox çš„é¢ç§¯ï¼‰ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹çš„æ£€æµ‹æ•ˆæœã€‚ segmentationï¼šå¤šè¾¹å½¢æ ¼å¼çš„åˆ†å‰²æ©ç ï¼Œç”¨äºè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ã€‚æ¯ä¸ªç›®æ ‡å¯ä»¥æœ‰ä¸€ä¸ªæˆ–å¤šä¸ªåˆ†å‰²æ©ç ã€‚ iscrowdï¼šè¡¨ç¤ºç›®æ ‡æ˜¯å¦æ˜¯å¯†é›†çš„ã€éš¾ä»¥åŒºåˆ†çš„å¯¹è±¡ã€‚å¦‚æœ iscrowd = 1ï¼Œåˆ™æ„å‘³ç€ç›®æ ‡æ˜¯ä¸€ç¾¤å¯†é›†çš„ç‰©ä½“ï¼ˆå¦‚ä¸€ç¾¤äººã€å¤šä¸ªç‰©ä½“ï¼‰ï¼Œå¦åˆ™ä¸º 0ã€‚ 2.3 categoriesï¼šç±»åˆ«ä¿¡æ¯ categories åˆ—è¡¨å­˜å‚¨äº†æ‰€æœ‰ç›®æ ‡ç±»åˆ«çš„ä¿¡æ¯ã€‚æ¯ä¸ªç±»åˆ«çš„ç»“æ„å¦‚ä¸‹ï¼š\n\u0026quot;categories\u0026quot;: [\r{\r\u0026quot;id\u0026quot;: 18,\r\u0026quot;name\u0026quot;: \u0026quot;dog\u0026quot;,\r\u0026quot;supercategory\u0026quot;: \u0026quot;animal\u0026quot;\r},\r...\r]\ridï¼šç±»åˆ«çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œannotations éƒ¨åˆ†çš„ category_id ä¼šå¼•ç”¨è¿™ä¸ª IDã€‚ nameï¼šç±»åˆ«çš„åç§°ï¼Œæ¯”å¦‚ â€œdogâ€ã€â€œpersonâ€ ç­‰ã€‚ supercategoryï¼šè¯¥ç±»åˆ«æ‰€å±çš„æ›´é«˜å±‚çº§çš„ç±»åˆ«åˆ†ç±»ï¼ˆå¯é€‰ï¼‰ï¼Œæ¯”å¦‚ â€œanimalâ€ã€‚ 3. è¾¹ç•Œæ¡†ï¼ˆbboxï¼‰æ ¼å¼è¯´æ˜ COCO æ•°æ®é›†ä¸­ï¼Œè¾¹ç•Œæ¡†çš„æ ¼å¼ä¸º [x, y, width, height]ï¼Œå…¶ä¸­ï¼š\nx å’Œ y æ˜¯è¾¹ç•Œæ¡†å·¦ä¸Šè§’çš„åæ ‡ï¼Œè¡¨ç¤ºè¯¥æ¡†åœ¨å›¾åƒä¸­çš„ä½ç½®ã€‚ width æ˜¯è¾¹ç•Œæ¡†çš„å®½åº¦ã€‚ height æ˜¯è¾¹ç•Œæ¡†çš„é«˜åº¦ã€‚ ä¸ YOLO å’Œ Pascal VOC ä¸åŒï¼ŒCOCO ä¸­çš„è¾¹ç•Œæ¡†æ˜¯ ç»å¯¹åæ ‡ ï¼Œä¸éœ€è¦å½’ä¸€åŒ–åˆ° 0 å’Œ 1 ä¹‹é—´ï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨åƒç´ å€¼ã€‚\n4. å®Œæ•´COCOæ–‡ä»¶ç¤ºä¾‹ ä»¥ä¸‹æ˜¯ä¸€ä¸ªå®Œæ•´çš„ COCO æ ‡æ³¨æ–‡ä»¶çš„ç®€åŒ–ç¤ºä¾‹ï¼ˆJSON æ ¼å¼ï¼‰ï¼š\n{\r\u0026quot;info\u0026quot;: {\r\u0026quot;year\u0026quot;: 2024,\r\u0026quot;version\u0026quot;: \u0026quot;1.0\u0026quot;,\r\u0026quot;description\u0026quot;: \u0026quot;COCO-style dataset\u0026quot;,\r\u0026quot;date_created\u0026quot;: \u0026quot;2024-10-23\u0026quot;\r},\r\u0026quot;licenses\u0026quot;: [\r{\r\u0026quot;id\u0026quot;: 1,\r\u0026quot;name\u0026quot;: \u0026quot;Creative Commons Attribution 4.0 License\u0026quot;\r}\r],\r\u0026quot;images\u0026quot;: [\r{\r\u0026quot;id\u0026quot;: 1,\r\u0026quot;width\u0026quot;: 640,\r\u0026quot;height\u0026quot;: 480,\r\u0026quot;file_name\u0026quot;: \u0026quot;000000000001.jpg\u0026quot;\r}\r],\r\u0026quot;annotations\u0026quot;: [\r{\r\u0026quot;id\u0026quot;: 1,\r\u0026quot;image_id\u0026quot;: 1,\r\u0026quot;category_id\u0026quot;: 18,\r\u0026quot;bbox\u0026quot;: [73.77, 150.54, 227.85, 304.35],\r\u0026quot;area\u0026quot;: 69321.27,\r\u0026quot;segmentation\u0026quot;: [[192.81, 247.09, 225.11, 249.06, ...]],\r\u0026quot;iscrowd\u0026quot;: 0\r}\r],\r\u0026quot;categories\u0026quot;: [\r{\r\u0026quot;id\u0026quot;: 18,\r\u0026quot;name\u0026quot;: \u0026quot;dog\u0026quot;,\r\u0026quot;supercategory\u0026quot;: \u0026quot;animal\u0026quot;\r}\r]\r}\rCOCOæ–‡ä»¶ç»“æ„ COCO æ•°æ®é›†çš„å…¸å‹æ–‡ä»¶ç»“æ„å¦‚ä¸‹ï¼š\ncoco/\râ”œâ”€â”€ annotations/ # å­˜æ”¾æ ‡æ³¨çš„ JSON æ–‡ä»¶\râ”‚ â”œâ”€â”€ instances_train2017.json # ç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„æ ‡æ³¨ï¼ˆè®­ç»ƒé›†ï¼‰\râ”‚ â”œâ”€â”€ instances_val2017.json # ç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„æ ‡æ³¨ï¼ˆéªŒè¯é›†ï¼‰\râ”œâ”€â”€ images/ # å›¾åƒæ•°æ®å­˜æ”¾ä½ç½®\râ”‚ â”œâ”€â”€ train2017/ # è®­ç»ƒé›†å›¾åƒ\râ”‚ â””â”€â”€ val2017/ # éªŒè¯é›†å›¾åƒ\râ””â”€â”€ ...\rå¦‚ä½•å°†COCOæ ¼å¼è½¬æ¢ä¸ºå…¶ä»–æ ¼å¼ï¼ˆå¦‚YOLOï¼‰ï¼š ä»COCOçš„bboxå­—æ®µæå–ï¼š * ä» `bbox` ä¸­æå–å·¦ä¸Šè§’åæ ‡ `(x, y)`ï¼Œå®½åº¦ `width` å’Œé«˜åº¦ `height`ã€‚\r* è®¡ç®— YOLO æ‰€éœ€çš„ä¸­å¿ƒç‚¹åæ ‡å’Œç›¸å¯¹å®½åº¦ã€é«˜åº¦ã€‚\r* å°†åæ ‡å½’ä¸€åŒ–åˆ° 0 åˆ° 1 ä¹‹é—´ã€‚\rç±»åˆ«æ˜ å°„ ï¼š * æ ¹æ® `category_id`ï¼Œå°† COCO ä¸­çš„ç±»åˆ«æ˜ å°„åˆ° YOLO ç±»åˆ« IDã€‚\ræ ¼å¼ä¹‹é—´çš„ç›¸äº’è½¬æ¢ å½“ç„¶ï¼Œæœ‰çš„æ—¶å€™å¤§å®¶è·å¾—æ•°æ®å¯èƒ½æ˜¯åˆ«äººä»¥åŠæ ‡æ³¨å¥½çš„ï¼Œå¯èƒ½æ˜¯vocçš„æ ¼å¼æˆ–è€…æ˜¯jsonçš„æ ¼å¼ï¼Œä½†æ˜¯ä½ å¯èƒ½åªæ˜¯æƒ³åœ¨yoloä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ‰€ä»¥åœ¨è¿™é‡Œï¼Œæˆ‘æä¾›ä¸¤æ®µè„šæœ¬ï¼Œåˆ†åˆ«ç”¨äºvocæ ¼å¼å‘yoloæ ¼å¼æ•°æ®çš„è½¬åŒ–å’Œcocoæ•°æ®å‘yoloæ ¼å¼æ•°æ®çš„è½¬åŒ–ã€‚\nvocæ ¼å¼æ•°æ®è½¬åŒ–ä¸ºyoloæ ¼å¼æ•°æ®\nimport os\rimport xml.etree.ElementTree as ET\nVOCæ ¼å¼çš„ç›®æ ‡ç±»åˆ«åˆ—è¡¨ï¼ˆæ ¹æ®å®é™…æ•°æ®é›†çš„ç±»åˆ«åç§°ä¿®æ”¹ï¼‰ è¿™æ˜¯ä¸€ä»½VOCæ•°æ®é›†çš„ç±»åˆ«ç¤ºä¾‹ï¼Œæ‚¨å¯ä»¥æ ¹æ®å®é™…ç±»åˆ«ä¿®æ”¹ classes = [\u0026ldquo;aeroplane\u0026rdquo;, \u0026ldquo;bicycle\u0026rdquo;, \u0026ldquo;bird\u0026rdquo;, \u0026ldquo;boat\u0026rdquo;, \u0026ldquo;bottle\u0026rdquo;, \u0026ldquo;bus\u0026rdquo;, \u0026ldquo;car\u0026rdquo;, \u0026ldquo;cat\u0026rdquo;, \u0026ldquo;chair\u0026rdquo;, \u0026ldquo;cow\u0026rdquo;, \u0026ldquo;diningtable\u0026rdquo;, \u0026ldquo;dog\u0026rdquo;, \u0026ldquo;horse\u0026rdquo;, \u0026ldquo;motorbike\u0026rdquo;, \u0026ldquo;person\u0026rdquo;, \u0026ldquo;pottedplant\u0026rdquo;, \u0026ldquo;sheep\u0026rdquo;, \u0026ldquo;sofa\u0026rdquo;, \u0026ldquo;train\u0026rdquo;, \u0026ldquo;tvmonitor\u0026rdquo;]\nè¯»å–XMLæ–‡ä»¶ï¼Œè½¬æ¢ä¸ºYOLOæ ¼å¼ def convert_voc_to_yolo(xml_file, output_dir, img_width, img_height): tree = ET.parse(xml_file) root = tree.getroot()\n# è·å–å›¾åƒæ–‡ä»¶å\rimage_id = os.path.splitext(os.path.basename(xml_file))[0]\rtxt_file_path = os.path.join(output_dir, f\u0026quot;{image_id}.txt\u0026quot;)\rwith open(txt_file_path, 'w') as txt_file:\rfor obj in root.findall('object'):\r# è·å–ç±»åˆ«\rclass_name = obj.find('name').text\rif class_name not in classes:\rcontinue # å¦‚æœç±»åˆ«ä¸åœ¨æˆ‘ä»¬å®šä¹‰çš„ç±»è¡¨ä¸­ï¼Œè·³è¿‡\rclass_id = classes.index(class_name)\r# è·å–è¾¹ç•Œæ¡†ä¿¡æ¯\rxml_bbox = obj.find('bndbox')\rxmin = int(xml_bbox.find('xmin').text)\rymin = int(xml_bbox.find('ymin').text)\rxmax = int(xml_bbox.find('xmax').text)\rymax = int(xml_bbox.find('ymax').text)\r# è®¡ç®—YOLOæ ¼å¼çš„ (x_center, y_center, width, height)ï¼Œå¹¶å½’ä¸€åŒ–\rx_center = (xmin + xmax) / 2.0 / img_width\ry_center = (ymin + ymax) / 2.0 / img_height\rwidth = (xmax - xmin) / img_width\rheight = (ymax - ymin) / img_height\r# å†™å…¥åˆ°YOLOæ ¼å¼çš„txtæ–‡ä»¶ä¸­\rtxt_file.write(f\u0026quot;{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\u0026quot;)\rprint(f\u0026quot;Converted {xml_file} to {txt_file_path}\u0026quot;)\ræ‰¹é‡è½¬æ¢å‡½æ•° def convert_all_voc_to_yolo(voc_annotations_dir, output_dir, img_width, img_height): if not os.path.exists(output_dir): os.makedirs(output_dir)\nxml_files = [f for f in os.listdir(voc_annotations_dir) if f.endswith('.xml')]\rfor xml_file in xml_files:\rconvert_voc_to_yolo(os.path.join(voc_annotations_dir, xml_file), output_dir, img_width, img_height)\rä½¿ç”¨ç¤ºä¾‹ï¼šå®šä¹‰VOCæ ¼å¼çš„æ³¨é‡Šç›®å½•ã€è¾“å‡ºç›®å½•ã€å›¾åƒå°ºå¯¸ voc_annotations_dir = \u0026lsquo;./VOCdevkit/VOC2007/Annotations\u0026rsquo; output_dir = \u0026lsquo;./VOCdevkit/VOC2007/YOLO_labels\u0026rsquo; img_width = 640 # æ›¿æ¢ä¸ºå›¾åƒçš„å®é™…å®½åº¦ img_height = 480 # æ›¿æ¢ä¸ºå›¾åƒçš„å®é™…é«˜åº¦\nconvert_all_voc_to_yolo(voc_annotations_dir, output_dir, img_width, img_height)\nä¸»è¦æ­¥éª¤è¯´æ˜ï¼š 1. **ç±»åˆ«æ˜ å°„ (`classes`)**ï¼šåœ¨è„šæœ¬ä¸­ï¼Œ`classes` åˆ—è¡¨å­˜å‚¨äº†æ‚¨ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­çš„ç±»åˆ«ã€‚è¯·ç¡®ä¿ VOC æ•°æ®é›†ä¸­çš„ç±»åˆ«ä¸ YOLO ä½¿ç”¨çš„ç±»åˆ«ç›¸åŒ¹é…ï¼Œå¹¶ä¸” `classes` åˆ—è¡¨ä¸­çš„é¡ºåºä¸æ‚¨å¸Œæœ›çš„ç±»åˆ«é¡ºåºä¸€è‡´ã€‚\r2. **XML è§£æ** ï¼šè„šæœ¬ä½¿ç”¨ Python çš„ `xml.etree.ElementTree` æ¨¡å—æ¥è§£æ Pascal VOC çš„ XML æ ‡æ³¨æ–‡ä»¶ï¼Œå¹¶æå–ç›®æ ‡çš„ç±»åˆ«å’Œè¾¹ç•Œæ¡†åæ ‡ã€‚\r3. **YOLO æ ¼å¼è½¬æ¢** ï¼šå¯¹äºæ¯ä¸ªè¾¹ç•Œæ¡†ï¼Œè„šæœ¬å°† `(xmin, ymin, xmax, ymax)` è½¬æ¢ä¸º YOLO æ‰€éœ€çš„ `(x_center, y_center, width, height)` æ ¼å¼ï¼Œå¹¶å°†å…¶å½’ä¸€åŒ–ï¼ˆç›¸å¯¹äºå›¾åƒçš„å®½åº¦å’Œé«˜åº¦ï¼‰ã€‚\r4. **è¾“å‡º YOLO æ–‡ä»¶** ï¼šæ¯ä¸ªå›¾åƒç”Ÿæˆä¸€ä¸ª `.txt` æ–‡ä»¶ï¼Œæ–‡ä»¶åä¸å›¾åƒåç›¸åŒã€‚æ¯ä¸ª `.txt` æ–‡ä»¶çš„æ¯ä¸€è¡Œå¯¹åº”ä¸€ä¸ªç›®æ ‡ï¼ŒåŒ…å«ç›®æ ‡ç±»åˆ«çš„ ID å’Œå½’ä¸€åŒ–åçš„è¾¹ç•Œæ¡†ä¿¡æ¯ã€‚\r5. **æ‰¹é‡å¤„ç†** ï¼š`convert_all_voc_to_yolo` å‡½æ•°å¯ä»¥æ‰¹é‡è½¬æ¢æ•´ä¸ªç›®å½•ä¸­çš„ XML æ–‡ä»¶ã€‚\rå¦‚ä½•å°†COCOæ ¼å¼è½¬æ¢ä¸ºå…¶ä»–æ ¼å¼ï¼ˆå¦‚YOLOï¼‰ï¼š 1. ä»COCOçš„`bbox`å­—æ®µæå–ï¼š * ä» `bbox` ä¸­æå–å·¦ä¸Šè§’åæ ‡ `(x, y)`ï¼Œå®½åº¦ `width` å’Œé«˜åº¦ `height`ã€‚\r* è®¡ç®— YOLO æ‰€éœ€çš„ä¸­å¿ƒç‚¹åæ ‡å’Œç›¸å¯¹å®½åº¦ã€é«˜åº¦ã€‚\r* å°†åæ ‡å½’ä¸€åŒ–åˆ° 0 åˆ° 1 ä¹‹é—´ã€‚\r2. ç±»åˆ«æ˜ å°„ï¼š * æ ¹æ® `category_id`ï¼Œå°† COCO ä¸­çš„ç±»åˆ«æ˜ å°„åˆ° YOLO ç±»åˆ« IDã€‚\rcocoæ ¼å¼æ•°æ®è½¬æ¢ä¸ºyoloæ ¼å¼æ•°æ®\nimport json\rimport os\nCOCOæ ¼å¼çš„ç±»åˆ«ä¿¡æ¯ï¼ŒæŒ‰é¡ºåºå¡«å…¥ç±»åˆ«åç§° è¿™é‡Œæ˜¯ä¸€ä¸ªç®€å•ç¤ºä¾‹ï¼ŒCOCOæ ‡å‡†æ•°æ®é›†å¯èƒ½åŒ…å«80ä¸ªç±»åˆ«ï¼Œæ‚¨å¯æ ¹æ®éœ€è¦è°ƒæ•´ coco_classes = [ \u0026lsquo;person\u0026rsquo;, \u0026lsquo;bicycle\u0026rsquo;, \u0026lsquo;car\u0026rsquo;, \u0026lsquo;motorcycle\u0026rsquo;, \u0026lsquo;airplane\u0026rsquo;, \u0026lsquo;bus\u0026rsquo;, \u0026rsquo;train\u0026rsquo;, \u0026rsquo;truck\u0026rsquo;, \u0026lsquo;boat\u0026rsquo;, \u0026rsquo;traffic light\u0026rsquo;, \u0026lsquo;fire hydrant\u0026rsquo;, \u0026lsquo;stop sign\u0026rsquo;, \u0026lsquo;parking meter\u0026rsquo;, \u0026lsquo;bench\u0026rsquo;, \u0026lsquo;bird\u0026rsquo;, \u0026lsquo;cat\u0026rsquo;, \u0026lsquo;dog\u0026rsquo;, \u0026lsquo;horse\u0026rsquo;, \u0026lsquo;sheep\u0026rsquo;, \u0026lsquo;cow\u0026rsquo;, \u0026rsquo;elephant\u0026rsquo;, \u0026lsquo;bear\u0026rsquo;, \u0026lsquo;zebra\u0026rsquo;, \u0026lsquo;giraffe\u0026rsquo;, \u0026lsquo;backpack\u0026rsquo;, \u0026lsquo;umbrella\u0026rsquo;, \u0026lsquo;handbag\u0026rsquo;, \u0026rsquo;tie\u0026rsquo;, \u0026lsquo;suitcase\u0026rsquo;, \u0026lsquo;frisbee\u0026rsquo;, \u0026lsquo;skis\u0026rsquo;, \u0026lsquo;snowboard\u0026rsquo;, \u0026lsquo;sports ball\u0026rsquo;, \u0026lsquo;kite\u0026rsquo;, \u0026lsquo;baseball bat\u0026rsquo;, \u0026lsquo;baseball glove\u0026rsquo;, \u0026lsquo;skateboard\u0026rsquo;, \u0026lsquo;surfboard\u0026rsquo;, \u0026rsquo;tennis racket\u0026rsquo;, \u0026lsquo;bottle\u0026rsquo;, \u0026lsquo;wine glass\u0026rsquo;, \u0026lsquo;cup\u0026rsquo;, \u0026lsquo;fork\u0026rsquo;, \u0026lsquo;knife\u0026rsquo;, \u0026lsquo;spoon\u0026rsquo;, \u0026lsquo;bowl\u0026rsquo;, \u0026lsquo;banana\u0026rsquo;, \u0026lsquo;apple\u0026rsquo;, \u0026lsquo;sandwich\u0026rsquo;, \u0026lsquo;orange\u0026rsquo;, \u0026lsquo;broccoli\u0026rsquo;, \u0026lsquo;carrot\u0026rsquo;, \u0026lsquo;hot dog\u0026rsquo;, \u0026lsquo;pizza\u0026rsquo;, \u0026lsquo;donut\u0026rsquo;, \u0026lsquo;cake\u0026rsquo;, \u0026lsquo;chair\u0026rsquo;, \u0026lsquo;couch\u0026rsquo;, \u0026lsquo;potted plant\u0026rsquo;, \u0026lsquo;bed\u0026rsquo;, \u0026lsquo;dining table\u0026rsquo;, \u0026rsquo;toilet\u0026rsquo;, \u0026rsquo;tv\u0026rsquo;, \u0026rsquo;laptop\u0026rsquo;, \u0026lsquo;mouse\u0026rsquo;, \u0026lsquo;remote\u0026rsquo;, \u0026lsquo;keyboard\u0026rsquo;, \u0026lsquo;cell phone\u0026rsquo;, \u0026lsquo;microwave\u0026rsquo;, \u0026lsquo;oven\u0026rsquo;, \u0026rsquo;toaster\u0026rsquo;, \u0026lsquo;sink\u0026rsquo;, \u0026lsquo;refrigerator\u0026rsquo;, \u0026lsquo;book\u0026rsquo;, \u0026lsquo;clock\u0026rsquo;, \u0026lsquo;vase\u0026rsquo;, \u0026lsquo;scissors\u0026rsquo;, \u0026rsquo;teddy bear\u0026rsquo;, \u0026lsquo;hair drier\u0026rsquo;, \u0026rsquo;toothbrush\u0026rsquo; ]\nåŠ è½½COCOçš„JSONæ–‡ä»¶ def load_coco_annotations(json_file): with open(json_file, \u0026lsquo;r\u0026rsquo;) as f: data = json.load(f) return data\nå°†COCOçš„bboxè½¬æ¢ä¸ºYOLOæ ¼å¼ def convert_coco_to_yolo(image_id, annotations, img_width, img_height, output_dir): txt_file_path = os.path.join(output_dir, f\u0026quot;{image_id}.txt\u0026quot;)\nwith open(txt_file_path, 'w') as txt_file:\rfor ann in annotations:\rif ann['image_id'] != image_id:\rcontinue\r# è·å–ç±»åˆ«IDï¼ŒCOCOçš„category_idéœ€è¦æ˜ å°„åˆ°YOLOçš„class id\rcategory_id = ann['category_id'] - 1 # å‡è®¾ç±»åˆ«ä»1å¼€å§‹ç¼–å·ï¼Œéœ€è¦å‡1\r# è·å–COCOçš„bbox (x, y, width, height)\rbbox = ann['bbox']\rx, y, width, height = bbox\r# è®¡ç®—YOLOçš„x_center, y_centerå¹¶å½’ä¸€åŒ–\rx_center = (x + width / 2.0) / img_width\ry_center = (y + height / 2.0) / img_height\rnorm_width = width / img_width\rnorm_height = height / img_height\r# å†™å…¥YOLOæ ¼å¼çš„txtæ–‡ä»¶ä¸­\rtxt_file.write(f\u0026quot;{category_id} {x_center:.6f} {y_center:.6f} {norm_width:.6f} {norm_height:.6f}\\n\u0026quot;)\rprint(f\u0026quot;Converted annotations for image {image_id} to {txt_file_path}\u0026quot;)\ræ‰¹é‡å¤„ç†COCOçš„å›¾åƒå’Œæ ‡æ³¨ä¿¡æ¯ def convert_all_coco_to_yolo(coco_json_file, output_dir): data = load_coco_annotations(coco_json_file)\n# è·å–å›¾åƒä¿¡æ¯å’Œæ ‡æ³¨ä¿¡æ¯\rimages = data['images']\rannotations = data['annotations']\r# åˆ›å»ºè¾“å‡ºç›®å½•\rif not os.path.exists(output_dir):\ros.makedirs(output_dir)\r# éå†æ‰€æœ‰å›¾åƒ\rfor image in images:\rimage_id = image['id']\rimg_width = image['width']\rimg_height = image['height']\r# è½¬æ¢æ¯ä¸ªå›¾åƒçš„æ ‡æ³¨\rconvert_coco_to_yolo(image_id, annotations, img_width, img_height, output_dir)\rä½¿ç”¨ç¤ºä¾‹ï¼šå®šä¹‰COCOçš„JSONæ–‡ä»¶ã€è¾“å‡ºç›®å½• coco_json_file = \u0026lsquo;./coco/annotations/instances_train2017.json\u0026rsquo; # æ›¿æ¢ä¸ºCOCOçš„JSONæ–‡ä»¶è·¯å¾„ output_dir = \u0026lsquo;./coco/YOLO_labels\u0026rsquo; # è¾“å‡ºç›®å½•\næ‰§è¡Œè½¬æ¢ convert_all_coco_to_yolo(coco_json_file, output_dir)\nä»£ç è¯¦ç»†è¯´æ˜ï¼š 1. **ç±»åˆ«æ˜ å°„ (`coco_classes`)**ï¼šè¯¥åˆ—è¡¨åŒ…å« COCO æ•°æ®é›†ä¸­æ‰€æœ‰ç±»åˆ«çš„åç§°ã€‚å‡è®¾ç±»åˆ«ç¼–å·ä» 1 å¼€å§‹ï¼Œå› æ­¤ç±»åˆ« ID å‡ 1 è½¬æ¢ä¸º 0 å¼€å§‹çš„ç¼–å·ï¼Œè¿™ä¸ YOLO çš„ç±»åˆ« ID å¯¹åº”ã€‚\r2. **åŠ è½½ COCO æ ‡æ³¨æ–‡ä»¶** ï¼šå‡½æ•° `load_coco_annotations` ç”¨äºåŠ è½½ COCO æ ¼å¼çš„ JSON æ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶åŒ…å«äº†å›¾åƒã€ç±»åˆ«ã€è¾¹ç•Œæ¡†ã€åˆ†å‰²ç­‰ä¿¡æ¯ã€‚\r3. **COCO åˆ° YOLO çš„è¾¹ç•Œæ¡†è½¬æ¢** ï¼šå‡½æ•° `convert_coco_to_yolo` è´Ÿè´£å°†æ¯ä¸ªç›®æ ‡çš„ COCO æ ¼å¼è¾¹ç•Œæ¡† `[x, y, width, height]` è½¬æ¢ä¸º YOLO æ‰€éœ€çš„ `(x_center, y_center, width, height)`ï¼Œå¹¶å°†å…¶å½’ä¸€åŒ–ä¸ºç›¸å¯¹äºå›¾åƒå®½åº¦å’Œé«˜åº¦çš„å€¼ã€‚\r4. **è¾“å‡º YOLO æ ¼å¼** ï¼šè½¬æ¢åçš„æ•°æ®å°†ä¿å­˜ä¸º `.txt` æ–‡ä»¶ï¼Œæ–‡ä»¶åä¸å›¾åƒåç›¸åŒã€‚æ¯è¡Œè¡¨ç¤ºä¸€ä¸ªç‰©ä½“ï¼Œå†…å®¹ä¸ºï¼š\rphp\râ€‹ Copy code \u0026lt;class_id\u0026gt; \u0026lt;x_center\u0026gt; \u0026lt;y_center\u0026gt; 5. **æ‰¹é‡å¤„ç†** ï¼šå‡½æ•° `convert_all_coco_to_yolo` éå†æ‰€æœ‰å›¾åƒï¼Œå¹¶ä¸ºæ¯ä¸ªå›¾åƒç”Ÿæˆä¸€ä¸ªå¯¹åº”çš„ `.txt` æ–‡ä»¶ã€‚\rä½¿ç”¨è¯´æ˜ï¼š * **COCO æ ‡æ³¨æ–‡ä»¶è·¯å¾„** ï¼šä¿®æ”¹ `coco_json_file` ä¸º COCO æ•°æ®é›†ä¸­ JSON æ ‡æ³¨æ–‡ä»¶çš„è·¯å¾„ï¼ˆä¾‹å¦‚ `instances_train2017.json`ï¼‰ã€‚\r* **è¾“å‡ºç›®å½•** ï¼šä¿®æ”¹ `output_dir` ä¸ºä¿å­˜ YOLO æ ¼å¼çš„æ ‡ç­¾æ–‡ä»¶çš„ç›®å½•ã€‚\rè¿è¡Œè„šæœ¬åï¼ŒYOLO æ ¼å¼çš„æ ‡ç­¾æ–‡ä»¶å°†è¢«ä¿å­˜åœ¨æŒ‡å®šçš„è¾“å‡ºç›®å½•ä¸­ï¼Œæ¯ä¸ªå›¾åƒæœ‰ä¸€ä¸ª .txt æ–‡ä»¶ã€‚\næ³¨æ„äº‹é¡¹ ä¸Šé¢å™è¿°äº†å¾ˆå¤šå†…å®¹ï¼Œä½†æ˜¯ä¸»è¦æˆ‘æƒ³è¡¨è¾¾çš„è¿˜æ˜¯å¦‚æœä½ éœ€è¦è¿›è¡Œé«˜è´¨é‡çš„æ ‡æ³¨ï¼Œç†Ÿæ‚‰è¿™äº›æ•°æ®æ ¼å¼å°†æ˜¯éå¸¸é‡è¦çš„ï¼Œç†Ÿæ‚‰æ•°æ®çš„æ ¼å¼ä¹Ÿå¯ä»¥å¸®åŠ©ä½ æ›´åŠ äº†è§£ä½ çš„ä»»åŠ¡ã€‚\nå°½é‡åªç”¨æ•°å­—ã€è‹±æ–‡ä»¥åŠä¸‹åˆ’çº¿æ¥è¿›è¡Œè¡¨ç¤ºã€‚ yoloæ¨¡å¼ä¸‹æœ€å¥½ä¸€æ¬¡æ€§æ ‡æ³¨å®Œæˆã€‚ å­¦ä¼šå¿«æ·æ–¹å¼çš„ä½¿ç”¨å°†ä¼šè®©ä½ äº‹åŠåŠŸå€ã€‚ ","date":"0001-01-01T00:00:00Z","permalink":"https://nickk111.github.io/p/","title":""},{"content":"ä½¿ç”¨YOLOv8è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†ï¼ˆåŸç†è§£æ+æ•°æ®æ ‡æ³¨è¯´æ˜+è®­ç»ƒæ•™ç¨‹+å›¾å½¢åŒ–ç³»ç»Ÿå¼€å‘ï¼‰ ä½¿ç”¨YOLOv8è®­ç»ƒè‡ªå·±çš„æ•°æ®é›† Helloï¼Œå¤§å®¶å¥½ï¼Œæœ¬æ¬¡æˆ‘ä»¬æ¥æ•™å¤§å®¶ä½¿ç”¨YOLOV8è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†ã€‚\nè§†é¢‘åœ°å€ï¼šæ‰‹æŠŠæ‰‹æ•™ä½ ç”¨YOLOv8è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†ï¼ˆåŸç†è§£æ+ä»£ç å®è·µï¼‰_å“”å“©å“”å“©_bilibili\nGitHubèµ„æºåœ°å€ï¼š\nYOLOç³»åˆ—ç›®å‰å·²ç»æ›´æ–°åˆ°äº†V11ï¼Œå¹¶ä¸”YOLOç³»åˆ—æ¨¡å‹å·²ç»ç›®å‰ç¨³å®šè¿è¡Œäº†ä¸€æ®µæ—¶é—´ã€‚ ä»åŸç†ã€æ•°æ®æ ‡æ³¨å’Œç¯å¢ƒé…ç½® ï¼Œå¸®åŠ©å°ä¼™ä¼´ä»¬æŒæ¡YOLOv8çš„åŸºæœ¬å†…å®¹ã€‚æ³¨æ„æœ¬æ¬¡çš„æ•™ç¨‹é™¤äº†æ”¯æŒv8æ¨¡å‹çš„è®­ç»ƒï¼Œè¿˜é€‚ç”¨v3ã€v5ã€v9ã€v10ç­‰ä¸€ç³»åˆ—æ¨¡å‹çš„è®­ç»ƒã€‚\nä¸ºäº†å¸®åŠ©å¤§å®¶èƒ½çµæ´»é€‰æ‹©è‡ªå·±å–œæ¬¢çš„å†…å®¹ï¼Œæˆ‘ä»¬é€‰æ‹©åˆ†Pçš„æ–¹å¼è¿›è¡Œæ›´æ–°ã€‚æ¯”å¦‚ï¼Œæœ‰çš„å°ä¼™ä¼´åªå–œæ¬¢ç†è®ºçš„éƒ¨åˆ†ï¼Œæœ‰çš„å°ä¼™ä¼´åªå–œæ¬¢å®æ“çš„éƒ¨åˆ†ï¼Œè¿™æ ·å¤§å®¶å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€è¦å„å–æ‰€éœ€ã€‚\nYOLOv8åŸç†è§£æ Ultralyticså¼€å‘çš„YOLOv8æ˜¯ä¸€æ¬¾å°–ç«¯ã€æœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„æ¨¡å‹ï¼Œå®ƒå€Ÿé‰´äº†ä¹‹å‰YOLOç‰ˆæœ¬çš„æˆåŠŸç»éªŒï¼Œå¹¶å¼•å…¥äº†æ–°çš„ç‰¹æ€§å’Œæ”¹è¿›ï¼Œä»¥è¿›ä¸€æ­¥æé«˜æ€§èƒ½å’Œçµæ´»æ€§ã€‚YOLOv8æ—¨åœ¨å®ç°å¿«é€Ÿã€å‡†ç¡®å’Œæ˜“äºä½¿ç”¨ï¼Œå› æ­¤æ˜¯å„ç§ç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²å’Œå›¾åƒåˆ†ç±»ä»»åŠ¡çš„ç»ä½³é€‰æ‹©ã€‚æ³¨æ„ï¼Œæ­¤æ—¶çš„YOLOv8çš„æ¨¡å‹å·²ç»åŸºæœ¬å®Œæˆäº†æœ€ç»ˆçš„è¿›åŒ–ï¼Œé™¤äº†æ”¯æŒæœ€ç»å…¸çš„ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¹‹å¤–ï¼Œè¿˜æ·»åŠ äº†å¯¹è¯­ä¹‰åˆ†å‰²ã€åˆ†ç±»å’Œè¿½è¸ªç­‰ä»»åŠ¡çš„æ”¯æŒã€‚å½“ç„¶æˆ‘ä»¬æœ¬æœŸè¿˜æ˜¯é€‰æ‹©å¤§å®¶æœ€ç†Ÿæ‚‰çš„æ£€æµ‹ä»»åŠ¡æ¥è¿›è¡Œå±•å¼€ï¼Œå…³äºåç»­çš„å…¶ä»–ä»»åŠ¡æˆ‘ä»¬å†å¦å¤–å½•åˆ¶ã€‚\né¦–å…ˆæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹YOLOv8ç®—æ³•çš„æ€§èƒ½ã€‚ä¸‹å›¾æ˜¯å®˜æ–¹æä¾›äº†æ€§èƒ½å›¾ï¼Œå…¶ä¸­å·¦å›¾çš„æ¨ªåæ ‡è¡¨ç¤ºçš„æ˜¯ç½‘ç»œçš„å‚æ•°é‡ï¼Œå³å›¾çš„æ¨ªåæ ‡è¡¨ç¤ºçš„ç½‘ç»œåœ¨A100æ˜¾å¡ä¸Šçš„æ¨ç†é€Ÿåº¦ï¼Œçºµåæ ‡æ–¹é¢è¡¨ç¤ºè¡¨ç¤ºçš„éƒ½æ˜¯æ¨¡å‹çš„ç²¾åº¦ã€‚å¯ä»¥çœ‹å‡ºï¼ŒYOLOv8æ¨¡å‹çš„åœ¨åŒæ ·çš„å‚æ•°é‡ä¸‹ï¼Œæ¯”å…¶ä»–ç³»åˆ—çš„YOLOæ¨¡å‹æœ‰æ˜æ˜¾çš„ç²¾åº¦æå‡ï¼Œåœ¨å³å›¾å±•ç¤ºçš„åŒæ ·çš„mapç²¾åº¦ä¸‹ï¼ŒYOLOv8çš„æ¨¡å‹ä¹ŸåŒæ ·æœ‰æ›´å¿«çš„é€Ÿåº¦ï¼Œè¿˜çœŸå°±æ˜¯é‚£ä¸ªæ›´é«˜ã€æ›´å¿«ã€æ›´å¼ºã€‚\nä¸‹é¢çš„è¡¨æ ¼åˆ™æ˜¯æ¥è‡ªYOLOv8 - Ultralytics YOLO Docsæä¾›çš„åœ¨cocoæ•°æ®é›†ä¸Šçš„æµ‹è¯•ç»“æœï¼Œä»è¡¨ä¸­å¯ä»¥çœ‹å‡ºï¼Œå¯¹äºä»–çš„nanoæ¨¡å‹è€Œè¨€ï¼Œåœ¨åªæœ‰3.2Mçš„å‚æ•°é‡ä¸‹ï¼Œå°±å¯ä»¥è¾¾åˆ°37.3çš„mAPï¼Œéå¸¸ä¼˜ç§€çš„æ•°å€¼è¡¨ç°ã€‚\nYOLOv8ç®—æ³•çš„æ ¸å¿ƒç‚¹å¯ä»¥æ€»ç»“ä¸ºä¸‹é¢å‡ ç‚¹ã€‚\nç»™å‡ºäº†ä¸€ä¸ªå…¨æ–°çš„è§†è§‰æ¨¡å‹ ï¼Œä¿æŒç²¾åº¦çš„åŒæ—¶ï¼Œå®ç°äº†è¾ƒé«˜çš„æ£€æµ‹é€Ÿåº¦ï¼Œå¹¶ä¸”åŒæ—¶æ”¯æŒæ”¯æŒå›¾åƒåˆ†ç±»ã€ç‰©ä½“æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²ç­‰å¤šç§è§†è§‰ä»»åŠ¡ã€‚å¹¶ä¸”æä¾›äº†å¤šä¸ªè§„æ¨¡çš„æ¨¡å‹ï¼ˆnanoã€smallã€mediumã€largeå’Œx-largeï¼‰ï¼Œæ»¡è¶³ç”¨æˆ·ä¸åŒåœºæ™¯çš„éœ€è¦ã€‚ æ–°çš„éª¨å¹²ç½‘ç»œ ï¼šYOLOv8å¼•å…¥äº†ä¸€ä¸ªæ–°çš„éª¨å¹²ç½‘ç»œï¼Œå¯èƒ½å‚è€ƒäº†YOLOv7 ELANè®¾è®¡æ€æƒ³ï¼Œå°†YOLOv5ä¸­çš„C3ç»“æ„æ¢æˆäº†æ¢¯åº¦æµæ›´ä¸°å¯Œçš„C2fç»“æ„ï¼Œå¹¶å¯¹ä¸åŒå°ºåº¦æ¨¡å‹è°ƒæ•´äº†ä¸åŒçš„é€šé“æ•°ï¼Œå¤§å¹…æå‡äº†æ¨¡å‹æ€§èƒ½ã€‚ è§£è€¦å¤´çš„è®¾è®¡ ï¼šYOLOv8çš„Headéƒ¨åˆ†ä»åŸå…ˆçš„è€¦åˆå¤´å˜æˆäº†è§£è€¦å¤´ç»“æ„ï¼Œå°†åˆ†ç±»å’Œæ£€æµ‹å¤´åˆ†ç¦»ï¼Œå¹¶ä¸”ä»Anchor-Basedè½¬å˜ä¸ºAnchor-Freeï¼Œç®€åŒ–äº†æ¨¡å‹ç»“æ„å¹¶æé«˜äº†æ¨ç†é€Ÿåº¦ã€‚ æ–°çš„æŸå¤±å‡½æ•° ï¼šYOLOv8åœ¨Lossè®¡ç®—æ–¹é¢é‡‡ç”¨äº†TaskAlignedAssigneræ­£æ ·æœ¬åˆ†é…ç­–ç•¥ï¼Œå¹¶å¼•å…¥äº†Distribution Focal Lossï¼Œç¡®ä¿äº†æ£€æµ‹ç»“æœçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚ OKï¼Œè¯´å®Œè¿™é‡Œçš„æ€§èƒ½è¡¨ç°ï¼Œæˆ‘ä»¬å°±ä¸€èµ·æ¥çœ‹çœ‹YOLOv8ç»“æ„æ–¹é¢çš„å†…å®¹å§ã€‚\nç»“æ„è¯´æ˜ é¦–å…ˆæ˜¯YOLOv8çš„ç½‘ç»œç»“æ„å›¾\néª¨å¹²ç½‘ç»œéƒ¨åˆ†ï¼š éª¨å¹²ç½‘ç»œéƒ¨åˆ†çš„c2fç»“æ„å¯èƒ½å€Ÿé‰´äº†YOLOv7çš„è®¾è®¡ã€‚å°†åŸå…ˆçš„c3æ¨¡å—æ›´æ–°äº†c2fçš„æ¨¡å—ï¼Œå…¶ä¸­c3è¡¨ç¤ºä½¿ç”¨äº†3ä¸ªå¸¸è§„çš„å·ç§¯æ¨¡å—ï¼Œc2fè¡¨ç¤ºä½¿ç”¨äº†2ä¸ªå·ç§¯æ¨¡å—å¹¶ä¸”æ›´å¿«ï¼ˆfastï¼‰ã€‚åœ¨ä¸æ”¹å˜åŸå§‹æ¶æ„å’Œæ¢¯åº¦ä¼ è¾“è·¯å¾„çš„å‰æä¸‹ï¼Œ ä½¿ç”¨åˆ†ç»„å·ç§¯è¸¢æ¥ä»¥åŠä½¿ç”¨æ´—ç‰Œå’Œåˆå¹¶çš„æ“ä½œç»„åˆä¸åŒç»„çš„ç‰¹å¾ï¼Œå¢å¼ºæ¨¡å‹ä»ä¸åŒç‰¹å¾å›¾ä¸­çš„å­¦ä¹ èƒ½åŠ›ï¼Œè¾¾åˆ°æ”¹å–„å‚æ•°çš„ä½œç”¨ã€‚\nä¸‹å›¾æ˜¯YOLOv7ä¸­åŸæ–‡æåˆ°çš„Elançš„ç»“æ„ï¼Œä¸»è¦æ˜¯ä½¿ç”¨äº†æ›´å¤šçš„è¿æ¥å’Œåˆå¹¶çš„æ“ä½œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 class C3(nn.Module): \u0026#34;\u0026#34;\u0026#34; è¿™é‡Œæ˜¯ä½¿ç”¨äº†3ä¸ªå·ç§¯å±‚çš„cspç»“æ„ CSP Bottleneck with 3 convolutions. \u0026#34;\u0026#34;\u0026#34; def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5): \u0026#34;\u0026#34;\u0026#34;Initialize the CSP Bottleneck with given channels, number, shortcut, groups, and expansion values.\u0026#34;\u0026#34;\u0026#34; super().__init__() c_ = int(c2 * e) # hidden channels self.cv1 = Conv(c1, c_, 1, 1) self.cv2 = Conv(c1, c_, 1, 1) self.cv3 = Conv(2 * c_, c2, 1) # optional act=FReLU(c2) self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, k=((1, 1), (3, 3)), e=1.0) for _ in range(n))) def forward(self, x): \u0026#34;\u0026#34;\u0026#34;Forward pass through the CSP bottleneck with 2 convolutions.\u0026#34;\u0026#34;\u0026#34; return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1)) class C2f(nn.Module): \u0026#34;\u0026#34;\u0026#34; è¿™é‡Œä½¿ç”¨äº†åˆ†æ”¯å¤„ç†çš„æ“ä½œï¼Œä½¿ç”¨çš„æ˜¯é€šè¿‡å…³é—­æ®‹å·®é“¾æ¥çš„æ–¹å¼å®ç° å…ˆè¿›è¡Œåˆ†æ”¯çš„æ“ä½œç„¶åå†è¿›è¡Œç‰¹å¾èåˆçš„æ“ä½œ Faster Implementation of CSP Bottleneck with 2 convolutions. \u0026#34;\u0026#34;\u0026#34; def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5): \u0026#34;\u0026#34;\u0026#34;Initialize CSP bottleneck layer with two convolutions with arguments ch_in, ch_out, number, shortcut, groups, expansion. \u0026#34;\u0026#34;\u0026#34; super().__init__() self.c = int(c2 * e) # hidden channels self.cv1 = Conv(c1, 2 * self.c, 1, 1) self.cv2 = Conv((2 + n) * self.c, c2, 1) # optional act=FReLU(c2) self.m = nn.ModuleList(Bottleneck(self.c, self.c, shortcut, g, k=((3, 3), (3, 3)), e=1.0) for _ in range(n)) def forward(self, x): \u0026#34;\u0026#34;\u0026#34;Forward pass through C2f layer.\u0026#34;\u0026#34;\u0026#34; y = list(self.cv1(x).chunk(2, 1)) y.extend(m(y[-1]) for m in self.m) return self.cv2(torch.cat(y, 1)) def forward_split(self, x): \u0026#34;\u0026#34;\u0026#34;Forward pass using split() instead of chunk().\u0026#34;\u0026#34;\u0026#34; y = list(self.cv1(x).split((self.c, self.c), 1)) y.extend(m(y[-1]) for m in self.m) return self.cv2(torch.cat(y, 1)) é™¤æ­¤ä¹‹å¤–ï¼ŒYOLOv8çš„ä¸»å¹²è¿˜å»æ‰äº†neckéƒ¨åˆ†ä¸­çš„2ä¸ªå·ç§¯å±‚ï¼Œä»¥åŠå°†blockçš„æ•°é‡ä»åŸå…ˆçš„ 3-6-9-3 æ”¹æˆäº† 3-6-6-3ã€‚å¦å¤–ï¼Œåœ¨ä¹‹å‰çš„YOLOv5çš„ç½‘ç»œç»“æ„ä¸­ï¼Œåªéœ€è¦æ›´æ”¹ä¸€ä¸‹wå’Œhç³»æ•°å°±èƒ½ç»Ÿä¸€é€‚é…ä¸åŒè§„æ¨¡çš„æ¨¡å‹ï¼Œä½†æ˜¯å¯¹äºYOLOv8è€Œè¨€ï¼Œå…¶ä¸­Nå’ŒSçš„ç»“æ„ä¸€è‡´ï¼ŒLå’ŒXçš„ç»“æ„ä¸€è‡´ï¼Œè¿™ä¸¤å¯¹æ¨¡å‹å¯ä»¥åªé€šè¿‡ä¿®æ”¹ç¼©æ”¾ç³»æ•°å°±å®Œæˆæ›¿æ¢ã€‚åœ¨YOLOv10ä¸­ï¼Œä½œè€…ä¹Ÿæåˆ°äº†è¿™ä¸ªè§‚ç‚¹ï¼Œä¸ºäº†è¿½æ±‚ç½‘ç»œçš„çµæ´»æ€§ï¼Œå¯¼è‡´ç½‘ç»œåŒè´¨åŒ–æ¯”è¾ƒä¸¥é‡ï¼Œå…¶ä¸­æœ‰äº›å†—ä½™çš„æ¨¡å—æ˜¯å¯ä»¥å»é™¤çš„ï¼Œä¹Ÿè¯´æ˜ç°åœ¨çš„ç½‘ç»œç»“æ„å‘ç€æ¯”è¾ƒå®šåˆ¶åŒ–çš„æ–¹å‘è¿›è¡Œï¼Œå½“ç„¶ï¼Œè¿™å¥è¯æ˜¯æˆ‘çš„ä¸ªäººè§‚ç‚¹ã€‚\nè§£ç å¤´éƒ¨åˆ†ï¼š è§£ç å¤´çš„éƒ¨åˆ†é€‰æ‹©ä½¿ç”¨äº†åˆ†ç±»çš„è§£ç å¤´ï¼Œä¹Ÿå°±æ˜¯è¾¹ç•Œæ¡†å›å½’æ˜¯ä¸€ä¸ªåˆ†æ”¯ä»¥åŠåˆ†ç±»çš„æ˜¯ä¸€ä¸ªåˆ†æ”¯ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä¸Šé¢çš„å­å›¾æ˜¯åŸå…ˆçš„è§£ç å¤´éƒ¨ï¼Œç»è¿‡ä¸»å¹²ç½‘ç»œè¿›è¡Œç‰¹å¾æå–ä¹‹åå¾—åˆ°ç‰¹å¾å›¾ï¼Œä¹‹åç›´æ¥è¿›å…¥ä¸€ä¸ªæ¨¡å—ä¸­è¿›è¡Œè§£ç ï¼Œè¿™é‡Œçš„æ•°å€¼è®¡ç®—åŒ…å«3ä¸ªéƒ¨åˆ†ï¼Œåˆ†åˆ«æ˜¯ç”¨äºè¾¹ç•Œæ¡†å›å½’çš„CIoUã€ç”¨äºç½®ä¿¡åº¦è®¡ç®—çš„objå’Œç”¨äºåˆ†ç±»ç±»åˆ«è®¡ç®—çš„CLSã€‚æ”¹è¿›ä¹‹åçš„å¤´éƒ¨å¦‚ä¸‹é¢çš„å­å›¾æ‰€ç¤ºï¼Œç»è¿‡ä¸»å¹²ç½‘ç»œè¿›è¡Œç‰¹å¾æå–ä¹‹åï¼Œä¸Šé¢çš„å­åˆ†æ”¯ç”¨äºå›å½’ï¼Œä¸‹é¢çš„å­åˆ†æ”¯åˆ™ç”¨äºåˆ†ç±»ï¼Œå»é™¤äº†ä¹‹å‰çš„objçš„éƒ¨åˆ†ï¼Œåœ¨å›å½’çš„åˆ†æ”¯ä¸­ï¼Œä½¿ç”¨çš„æ˜¯Distribution Focal Lossã€‚\nå…¶ä¸­DFLæŸå¤±å‡½æ•°çš„å®šä¹‰å¦‚ä¸‹ï¼Œé€šä¿—æ¥è®²å°±æ˜¯è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œç›®æ ‡çš„è¾¹ç•Œæ¡†ä¸åº”è¯¥æ˜¯ä¸€ä¸ªç¡®å®šçš„æ•°å€¼ï¼Œç›®æ ‡çš„è¾¹ç•Œæ¡†åº”è¯¥æ˜¯ä¸€ä¸ªåˆ†å¸ƒï¼Œæ¯”å¦‚å¯¹äºæµªèŠ±è¿™ä¸ªç‰©ä½“è€Œè¨€ï¼Œä»–çš„è¾¹ç•Œå°±æ˜¯ä¸æ¸…æ™°çš„ï¼Œé€šè¿‡è¿™æ ·çš„æŸå¤±å‡½æ•°å¯ä»¥å‡å°‘ç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°çš„è¿‡æ‹Ÿåˆçš„ç°è±¡ã€‚\nå…¶ä¸­ï¼ŒDFLå®ç°çš„ä»£ç å¦‚ä¸‹ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def distribution_focal_loss(pred, label): r\u0026#34;\u0026#34;\u0026#34;Distribution Focal Loss (DFL) is from `Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection \u0026lt;https://arxiv.org/abs/2006.04388\u0026gt;`_. Args: pred (torch.Tensor): Predicted general distribution of bounding boxes (before softmax) with shape (N, n+1), n is the max value of the integral set `{0, ..., n}` in paper. label (torch.Tensor): Target distance label for bounding boxes with shape (N,). Returns: torch.Tensor: Loss tensor with shape (N,). \u0026#34;\u0026#34;\u0026#34; #labelä¸ºy, predä¸ºy^(yçš„ä¼°è®¡å€¼ï¼‰ #å› ä¸ºy_i \u0026lt;= y \u0026lt;= y_i+1(paper) #å–dis_left = y_i, dis_right = y_i+1 dis_left = label.long() dis_right = dis_left + 1 weight_left = dis_right.float() - label #y_i+1-y weight_right = label - dis_left.float() #y-y_i #paperä¸­çš„log(S)è¿™é‡Œç”¨CE loss = ( F.cross_entropy(pred, dis_left, reduction=\u0026#34;none\u0026#34;) * weight_left + F.cross_entropy(pred, dis_right, reduction=\u0026#34;none\u0026#34;) * weight_right ) return loss æŸå¤±å‡½æ•°è¯´æ˜ YOLOv8çš„lossè®¡ç®—åŒ…å«äº†åˆ†ç±»å’Œå›å½’ä¸¤ä¸ªéƒ¨åˆ†ï¼Œæ²¡æœ‰äº†ä¹‹å‰çš„objectnessçš„åˆ†æ”¯éƒ¨åˆ†ï¼Œå…¶ä¸­åˆ†ç±»çš„åˆ†æ”¯é‡‡ç”¨çš„æ˜¯BCE Lossï¼Œå›å½’çš„åˆ†æ”¯ä½¿ç”¨äº†ä¸¤ä¸ªéƒ¨åˆ†ï¼Œåˆ†åˆ«æ˜¯ä¸Šé¢æåˆ°çš„Distribution Focal Losså’ŒCIoU Lossï¼Œ3ä¸ªæŸå¤±å‡½æ•°æŒ‰ç…§ä¸€å®šçš„æƒé‡æ¯”ä¾‹è¿›è¡ŒåŠ æƒã€‚\nå…³äºæ­£è´Ÿæ ·æœ¬çš„åˆ†é…ï¼Œå…¶ä¸­YOLOv5ä¸­ä½¿ç”¨çš„æ˜¯é™æ€çš„åˆ†å¸ƒç­–ç•¥ï¼Œç®€å•æ¥è¯´ï¼Œé™æ€çš„åˆ†å¸ƒç­–ç•¥æ˜¯å°†æ ‡ç­¾ä¸­çš„GT Boxå’ŒAnchor Templatesæ¨¡æ¿è®¡ç®—IoUï¼Œå¦‚æœIoUå¤§äºè®¾å®šçš„é˜ˆå€¼å°±è®¤ä¸ºæ˜¯åŒ¹é…æˆåŠŸï¼ŒåŒ¹é…æˆåŠŸçš„è¾¹ç•Œæ¡†å°†ä¼šå‚ä¸åˆ°CIoU Lossçš„è®¡ç®—ä¸­ã€‚å½“ç„¶è¿™é‡Œæ‰€è¿°çš„æ˜¯ç®€åŒ–çš„ç‰ˆæœ¬ï¼Œå®é™…å­è®¡ç®—çš„è¿‡ç¨‹ä¸­è¿˜ä¼šå»è®¡ç®—GT Boxå’Œå¯¹åº”çš„çš„Anchor Templatesæ¨¡æ¿é«˜å®½çš„æ¯”ä¾‹ã€‚å‡è®¾å¯¹æŸä¸ªGT Boxè€Œè¨€ï¼Œå…¶å®åªè¦GT Boxæ»¡è¶³åœ¨æŸä¸ªAnchor Templateå®½å’Œé«˜çš„Ã— 0.25 0.25å€å’Œ4.0å€ä¹‹é—´å°±ç®—åŒ¹é…æˆåŠŸã€‚å…³äºè¿™éƒ¨åˆ†æ›´è¯¦ç»†çš„è§£é‡Šå¯ä»¥çœ‹YOLOv5ç½‘ç»œè¯¦è§£_yolov5ç½‘ç»œç»“æ„è¯¦è§£-CSDNåšå®¢ã€‚åœ¨YOLOv8ä¸­ï¼Œä½¿ç”¨çš„æ˜¯åŠ¨æ€åˆ†å¸ƒçš„ç­–ç•¥ï¼ˆYOLOX çš„ simOTAã€TOOD çš„ TaskAlignedAssigner å’Œ RTMDet çš„ DynamicSoftLabelAssignerï¼‰ï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨çš„æ˜¯ TOOD çš„ TaskAlignedAssignerã€‚ TaskAlignedAssigner çš„åŒ¹é…ç­–ç•¥ç®€å•æ€»ç»“ä¸ºï¼š æ ¹æ®åˆ†ç±»ä¸å›å½’çš„åˆ†æ•°åŠ æƒçš„åˆ†æ•°é€‰æ‹©æ­£æ ·æœ¬ã€‚\nsæ˜¯æ ‡æ³¨ç±»åˆ«å¯¹åº”çš„é¢„æµ‹åˆ†æ•°å€¼ï¼Œuæ˜¯é¢„æµ‹æ¡†å’Œgtæ¡†ä¹‹é—´çš„iouã€‚è®¡ç®—å‡ºåˆ†æ•°ä¹‹åï¼Œæ ¹æ®åˆ†æ•°é€‰å–topKå¤§çš„ä½œä¸ºæ­£æ ·æœ¬ï¼Œå…¶ä½™ä½œä¸ºè´Ÿæ ·æœ¬ã€‚\næ•°æ®å¢å¼ºè¯´æ˜ æ•°æ®å¢å¼ºçš„éƒ¨åˆ†å’ŒYOLOv5åŸºæœ¬ä¿æŒäº†ä¸€è‡´ï¼ŒåŒ…å«äº†é¢œè‰²å˜æ¢ã€é©¬èµ›å…‹æ•°æ®å¢å¼ºã€éšæœºå‰ªåˆ‡ç­‰ä¸€ç³»åˆ—å¸¸è§„çš„æ•°æ®å¢å¼ºçš„æ–¹å¼ã€‚å¹¶ä¸”ä½¿ç”¨YOLOXçš„æ•°æ®å¢å¼ºç­–ç•¥ï¼Œåœ¨å‰é¢çš„éƒ¨åˆ†ä½¿ç”¨æ•°æ®å¢å¼ºï¼Œè€Œåœ¨æœ€åçš„10ä¸ªepochä¸­å…³é—­æ•°æ®å¢å¼ºã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\nå¯¹äºä¸€äº›å¸¸è§çš„æ•°æ®å¢å¼ºçš„æ–¹å¼çš„è¯´æ˜ã€‚\nè®­ç»ƒç­–ç•¥è¯´æ˜ YOLOv8 çš„æ¨ç†è¿‡ç¨‹å’Œ YOLOv5 å‡ ä¹ä¸€æ ·ï¼Œå”¯ä¸€å·®åˆ«åœ¨äºå‰é¢éœ€è¦å¯¹ Distribution Focal Loss ä¸­çš„ç§¯åˆ†è¡¨ç¤º bbox å½¢å¼è¿›è¡Œè§£ç ï¼Œå˜æˆå¸¸è§„çš„ 4 ç»´åº¦ bboxï¼Œåç»­è®¡ç®—è¿‡ç¨‹å°±å’Œ YOLOv5 ä¸€æ ·äº†ã€‚\nä»¥ COCO 80 ç±»ä¸ºä¾‹ï¼Œå‡è®¾è¾“å…¥å›¾ç‰‡å¤§å°ä¸º 640x640ï¼ŒMMYOLO ä¸­å®ç°çš„æ¨ç†è¿‡ç¨‹ç¤ºæ„å›¾å¦‚ä¸‹æ‰€ç¤ºï¼š\nå…¶æ¨ç†å’Œåå¤„ç†è¿‡ç¨‹ä¸ºï¼š\n(1) bbox ç§¯åˆ†å½¢å¼è½¬æ¢ä¸º 4d bbox æ ¼å¼\nå¯¹ Head è¾“å‡ºçš„ bbox åˆ†æ”¯è¿›è¡Œè½¬æ¢ï¼Œåˆ©ç”¨ Softmax å’Œ Conv è®¡ç®—å°†ç§¯åˆ†å½¢å¼è½¬æ¢ä¸º 4 ç»´ bbox æ ¼å¼\n(2) ç»´åº¦å˜æ¢\nYOLOv8 è¾“å‡ºç‰¹å¾å›¾å°ºåº¦ä¸º 80x80ã€40x40 å’Œ 20x20 çš„ä¸‰ä¸ªç‰¹å¾å›¾ã€‚Head éƒ¨åˆ†è¾“å‡ºåˆ†ç±»å’Œå›å½’å…± 6 ä¸ªå°ºåº¦çš„ç‰¹å¾å›¾ã€‚ å°† 3 ä¸ªä¸åŒå°ºåº¦çš„ç±»åˆ«é¢„æµ‹åˆ†æ”¯ã€bbox é¢„æµ‹åˆ†æ”¯è¿›è¡Œæ‹¼æ¥ï¼Œå¹¶è¿›è¡Œç»´åº¦å˜æ¢ã€‚ä¸ºäº†åç»­æ–¹ä¾¿å¤„ç†ï¼Œä¼šå°†åŸå…ˆçš„é€šé“ç»´åº¦ç½®æ¢åˆ°æœ€åï¼Œç±»åˆ«é¢„æµ‹åˆ†æ”¯ å’Œ bbox é¢„æµ‹åˆ†æ”¯ shape åˆ†åˆ«ä¸º (b, 80x80+40x40+20x20, 80)=(b,8400,80)ï¼Œ(b,8400,4)ã€‚\n(3) è§£ç è¿˜åŸåˆ°åŸå›¾å°ºåº¦\nåˆ†ç±»é¢„æµ‹åˆ†æ”¯è¿›è¡Œ Sigmoid è®¡ç®—ï¼Œè€Œ bbox é¢„æµ‹åˆ†æ”¯éœ€è¦è¿›è¡Œè§£ç ï¼Œè¿˜åŸä¸ºçœŸå®çš„åŸå›¾è§£ç å xyxy æ ¼å¼ã€‚\n(4) é˜ˆå€¼è¿‡æ»¤\néå† batch ä¸­çš„æ¯å¼ å›¾ï¼Œé‡‡ç”¨ score_thr è¿›è¡Œé˜ˆå€¼è¿‡æ»¤ã€‚åœ¨è¿™è¿‡ç¨‹ä¸­è¿˜éœ€è¦è€ƒè™‘ multi_label å’Œ nms_preï¼Œç¡®ä¿è¿‡æ»¤åçš„æ£€æµ‹æ¡†æ•°ç›®ä¸ä¼šå¤šäº nms_preã€‚\n(5) è¿˜åŸåˆ°åŸå›¾å°ºåº¦å’Œ nms\nåŸºäºå‰å¤„ç†è¿‡ç¨‹ï¼Œå°†å‰©ä¸‹çš„æ£€æµ‹æ¡†è¿˜åŸåˆ°ç½‘ç»œè¾“å‡ºå‰çš„åŸå›¾å°ºåº¦ï¼Œç„¶åè¿›è¡Œ nms å³å¯ã€‚æœ€ç»ˆè¾“å‡ºçš„æ£€æµ‹æ¡†ä¸èƒ½å¤šäº max_per_imgã€‚\næœ‰ä¸€ä¸ªç‰¹åˆ«æ³¨æ„çš„ç‚¹ï¼š YOLOv5 ä¸­é‡‡ç”¨çš„ Batch shape æ¨ç†ç­–ç•¥ï¼Œåœ¨ YOLOv8 æ¨ç†ä¸­æš‚æ—¶æ²¡æœ‰å¼€å¯ï¼Œä¸æ¸…æ¥šåé¢æ˜¯å¦ä¼šå¼€å¯ï¼Œåœ¨ MMYOLO ä¸­å¿«é€Ÿæµ‹è¯•äº†ä¸‹ï¼Œå¦‚æœå¼€å¯ Batch shape ä¼šæ¶¨å¤§æ¦‚ 0.1~0.2ã€‚\nä»£ç è§£æ ä¸‹è½½ä»£ç ä¹‹åï¼Œä½ å°†ä¼šçœ‹åˆ°ä¸‹é¢çš„ä»£ç ç›®å½•ç»“æ„ï¼Œå…¶ä¸­42_demoæ˜¯æˆ‘å‡†å¤‡çš„ç®€æ˜“çš„æ‰§è¡Œæ–‡ä»¶ï¼Œå…¶ä½™æ–‡ä»¶éƒ½æ˜¯å®˜æ–¹çš„æ–‡ä»¶å’Œç›®å½•ï¼Œæ¯ä¸ªæ–‡ä»¶å¤§æ¦‚çš„ä½œç”¨å¦‚ä¸‹ã€‚\n42_demo/ è¿™ä¸ªç›®å½•ä¸‹çš„æ–‡ä»¶æ˜¯ç”¨äºæˆ‘ä»¬æœ¬æ¬¡æ•™ç¨‹çš„è„šæœ¬ï¼Œæˆ‘ä»¬å°†è®­ç»ƒã€æµ‹è¯•ã€é¢„æµ‹ç­‰è„šæœ¬è¿›è¡Œäº†å•ç‹¬çš„å°è£…ï¼Œæ–¹ä¾¿åˆå­¦è€…æˆ–è€…ä¸æ˜¯è®¡ç®—æœºä¸“ä¸šçš„åŒå­¦è¿è¡Œï¼Œæ¯ä¸ªè„šæœ¬å¯¹åº”çš„å«ä¹‰å¦‚ä¸‹ã€‚\nå…¶ä¸­æ¯”è¾ƒé‡è¦çš„æ˜¯è®­ç»ƒçš„è„šæœ¬start_train.pyï¼Œè¿™ä¸ªè„šæœ¬è®°å½•äº†æ•°æ®çš„åŠ è½½å’Œä¸€äº›è®­ç»ƒçš„è¶…å‚æ•°ï¼Œå†…å®¹å¦‚ä¸‹ã€‚\nimport time\rfrom ultralytics import YOLO\r# yolov8næ¨¡å‹è®­ç»ƒï¼šè®­ç»ƒæ¨¡å‹çš„æ•°æ®ä¸º'A_my_data.yaml'ï¼Œè½®æ•°ä¸º100ï¼Œå›¾ç‰‡å¤§å°ä¸º640ï¼Œè®¾å¤‡ä¸ºæœ¬åœ°çš„GPUæ˜¾å¡ï¼Œå…³é—­å¤šçº¿ç¨‹çš„åŠ è½½ï¼Œå›¾åƒåŠ è½½çš„æ‰¹æ¬¡å¤§å°ä¸º4ï¼Œå¼€å¯å›¾ç‰‡ç¼“å­˜\rmodel = YOLO('yolov8n.pt') # load a pretrained model (recommended for training)\rresults = model.train(data='A_my_data.yaml', epochs=100, imgsz=640, device=[0,], workers=0, batch=4, cache=True) # å¼€å§‹è®­ç»ƒ\rtime.sleep(10) # ç¡çœ 10sï¼Œä¸»è¦æ˜¯ç”¨äºæœåŠ¡å™¨å¤šæ¬¡è®­ç»ƒçš„è¿‡ç¨‹ä¸­ä½¿ç”¨\râ€‹ â€‹\né¢„æµ‹çš„æµ‹è¯•è„šæœ¬ä¸»è¦ç”¨äºå•å¼ å›¾åƒçš„æ£€æµ‹ï¼Œè„šæœ¬ä¸ºstart_single_detect.py\nfrom ultralytics import YOLO\r# Load a model\rmodel = YOLO(\u0026quot;yolov8n.pt\u0026quot;) # pretrained YOLOv8n model\r# Run batched inference on a list of images\rresults = model([\u0026quot;images/resources/demo.jpg\u0026quot;, ]) # return a list of Results objects\r# Process results list\rfor result in results:\rboxes = result.boxes # Boxes object for bounding box outputs\rmasks = result.masks # Masks object for segmentation masks outputs\rkeypoints = result.keypoints # Keypoints object for pose outputs\rprobs = result.probs # Probs object for classification outputs\robb = result.obb # Oriented boxes object for OBB outputs\rresult.show() # display to screen\rresult.save(filename=\u0026quot;images/resources/result.jpg\u0026quot;) # save to disk\râ€‹\ndocker/ Docker æ˜¯ä¸€ä¸ªå¼€æºçš„åº”ç”¨å®¹å™¨å¼•æ“ï¼Œå®ƒå…è®¸å¼€å‘è€…æ‰“åŒ…ä»–ä»¬çš„åº”ç”¨ä»¥åŠä¾èµ–åŒ…åˆ°ä¸€ä¸ªå¯ç§»æ¤çš„å®¹å™¨ä¸­ï¼Œç„¶åå‘å¸ƒåˆ°ä»»ä½•æµè¡Œçš„ Linux æœºå™¨ä¸Šï¼Œä¹Ÿå¯ä»¥å®ç°è™šæ‹ŸåŒ–ã€‚å®¹å™¨æ˜¯å®Œå…¨ä½¿ç”¨æ²™ç®±æœºåˆ¶ï¼Œç›¸äº’ä¹‹é—´ä¸ä¼šæœ‰ä»»ä½•æ¥å£ã€‚\nç®€å•æ¥è¯´ï¼ŒDocker æä¾›äº†ä¸€ä¸ªå¯ä»¥è¿è¡Œä½ çš„åº”ç”¨ç¨‹åºçš„è™šæ‹Ÿç¯å¢ƒï¼Œä½†å®ƒæ¯”ä¼ ç»Ÿçš„è™šæ‹Ÿæœºæ›´åŠ è½»é‡å’Œå¿«é€Ÿã€‚ä½¿ç”¨ Dockerï¼Œä½ å¯ä»¥è½»æ¾åœ°åœ¨ä¸åŒçš„æœºå™¨å’Œå¹³å°ä¸Šéƒ¨ç½²ã€è¿è¡Œå’Œç®¡ç†åº”ç”¨ç¨‹åºï¼Œè€Œæ— éœ€æ‹…å¿ƒç¯å¢ƒé…ç½®å’Œä¾èµ–é—®é¢˜ã€‚\nè¿™ä¸ªç›®å½•æ˜¯æ ¹æ®ç”¨æˆ·ä¸åŒçš„è½¯ç¡¬ä»¶æƒ…å†µå†™çš„é…ç½®æ–‡ä»¶ï¼Œä½†æ˜¯ä¸€èˆ¬æƒ…å†µä¸‹å¤§å®¶ä½¿ç”¨çš„ä¸æ˜¯å¾ˆå¤šï¼Œå¯¹äºçœ‹æˆ‘å†…å®¹çš„å°ä¼™ä¼´æ¥è¯´ï¼Œå¤§éƒ¨åˆ†éƒ½æ˜¯å­¦ç”Ÿï¼Œä½¿ç”¨çš„æ›´å°‘ï¼Œæ‰€ä»¥è¿™é‡Œçš„å†…å®¹æˆ‘ä»¬å°±ä¸è¯¦ç»†è¯´æ˜äº†ã€‚\ndocs/ è¿™ä¸ªç›®å½•ç”¨äºæ”¾ç½®å¯¹è¿™ä¸ªä»£ç è§£é‡Šçš„å®˜æ–¹æ–‡æ¡£ï¼ŒåŒ…å«äº†å„ä¸ªä¸åŒçš„è¯­è¨€ã€‚\nexamples/ è¿™ä¸ªç›®å½•ä¸‹æœ‰å®˜æ–¹æä¾›çš„ä¸€äº›æ¡ˆä¾‹ï¼Œå¹¶ä¸”åŒ…å«äº†ä¸€äº›æ¨¡å‹å¯¼å‡ºä¹‹åC++çš„è°ƒç”¨è„šæœ¬ï¼Œè¿™é‡Œçš„è„šæœ¬å¤§å¤šæ•°æ—¶å€™åªæœ‰åœ¨å®é™…éƒ¨ç½²çš„æ—¶å€™æ‰ä¼šä½¿ç”¨åˆ°ï¼Œå…³äºç¡¬ä»¶éƒ¨ç½²æ˜¯ä¸€ä¸ªæ¯”è¾ƒå¤æ‚çš„å†…å®¹ï¼Œè¿™å—çš„å†…å®¹æˆ‘ä»¬ä¼šå•ç‹¬æŠ½æ—¶é—´æ¥è®²ã€‚\ntest/ testç›®å½•å­˜æ”¾äº†ä¸€äº›è‡ªåŠ¨åŒ–æµ‹è¯•çš„è„šæœ¬ã€‚\nultralytics/ è¯¥ç›®å½•æ˜¯æ•´ä¸ªé¡¹ç›®çš„æ ¸å¿ƒç›®å½•ï¼Œå­˜æ”¾äº†ç½‘ç»œç»“æ„çš„åº•å±‚å®ç°å’Œç½‘ç»œã€æ•°æ®é›†ä¸€ç³»åˆ—çš„é…ç½®æ–‡ä»¶ï¼Œå¹³å¸¸ä¿®æ”¹ç½‘ç»œç»“æ„å’Œæ–°å¢æ•°æ®éƒ½ä¼šåœ¨è¿™ä¸ªç›®å½•ä¸‹æ‰§è¡Œã€‚\nassetsç›®å½•ä¸‹å­˜æ”¾äº†ä¸¤å¼ ç»å…¸çš„æµ‹è¯•å›¾åƒï¼Œç”¨äºæ¨¡å‹çš„åˆæ­¥éªŒè¯ã€‚\ncfgç›®å½•ä¸‹å­˜æ”¾äº†æ•°æ®ã€æ¨¡å‹å’Œè¿½è¸ªçš„é…ç½®æ–‡ä»¶ï¼Œä¸¾ä¸ªä¾‹å­ï¼Œå…¶ä¸­datasetsä¸‹é¢çš„A_my_data.yamlå°±æ˜¯æˆ‘ä»¬æœ¬æ¬¡æ•™ç¨‹ä½¿ç”¨çš„æ•°æ®é›†é…ç½®æ–‡ä»¶ï¼Œåœ¨è¿™ä¸ªè·¯å¾„ä¸­æˆ‘ä»¬æŒ‡æ˜äº†æ•°æ®é›†çš„è·¯å¾„å’Œç±»åˆ«ç­‰ä¿¡æ¯ã€‚è€Œmodelsç›®å½•ä¸‹çš„yolov8.yamlé…ç½®æ–‡ä»¶åˆ™æŒ‡å®šäº†æˆ‘ä»¬è¦ä½¿ç”¨åˆ°çš„æ¨¡å‹ã€‚è¯¦ç»†çš„å†…å®¹å¦‚ä¸‹ï¼š\nA_my_data.yaml\n# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\rpath: ../../person_42_yolo_format\rtrain: # train images (relative to 'path') 16551 images\r- images/train\rval: # val images (relative to 'path') 4952 images\r- images/val\rtest: # test images (optional)\r- images/test\r# Classes\r# ['Chave', 'DISJUNTOR', 'TP', 'Pararraio', 'TC']\rnames:\r: person\râ€‹\nyolov8.yaml\n# Ultralytics YOLO ğŸš€, AGPL-3.0 license\r# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect\r# Parameters\rnc: 80 # number of classes\rscales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'\r# [depth, width, max_channels]\rn: [0.33, 0.25, 1024] # YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\rs: [0.33, 0.50, 1024] # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients, 28.8 GFLOPs\rm: [0.67, 0.75, 768] # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients, 79.3 GFLOPs\rl: [1.00, 1.00, 512] # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\rx: [1.00, 1.25, 512] # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs\r# YOLOv8.0n backbone\rbackbone:\r# [from, repeats, module, args]\r- [-1, 1, Conv, [64, 3, 2]] # 0-P1/2\r- [-1, 1, Conv, [128, 3, 2]] # 1-P2/4\r- [-1, 3, C2f, [128, True]]\r- [-1, 1, Conv, [256, 3, 2]] # 3-P3/8\r- [-1, 6, C2f, [256, True]]\r- [-1, 1, Conv, [512, 3, 2]] # 5-P4/16\r- [-1, 6, C2f, [512, True]]\r- [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32\r- [-1, 3, C2f, [1024, True]]\r- [-1, 1, SPPF, [1024, 5]] # 9\r# YOLOv8.0n head\rhead:\r- [-1, 1, nn.Upsample, [None, 2, \u0026quot;nearest\u0026quot;]]\r- [[-1, 6], 1, Concat, [1]] # cat backbone P4\r- [-1, 3, C2f, [512]] # 12\r- [-1, 1, nn.Upsample, [None, 2, \u0026quot;nearest\u0026quot;]]\r- [[-1, 4], 1, Concat, [1]] # cat backbone P3\r- [-1, 3, C2f, [256]] # 15 (P3/8-small)\r- [-1, 1, Conv, [256, 3, 2]]\r- [[-1, 12], 1, Concat, [1]] # cat head P4\r- [-1, 3, C2f, [512]] # 18 (P4/16-medium)\r- [-1, 1, Conv, [512, 3, 2]]\r- [[-1, 9], 1, Concat, [1]] # cat head P5\r- [-1, 3, C2f, [1024]] # 21 (P5/32-large)\r- [[15, 18, 21], 1, Detect, [nc]] # Detect(P3, P4, P5)\râ€‹\nåé¢çš„dataã€engineã€hubã€modelsã€nnã€solutionã€trackersã€utilsåˆ™åˆ†åˆ«å®šä¹‰äº†æ•°æ®ã€æ¨¡å‹è®­ç»ƒå¼•æ“ã€è®­ç»ƒå¯è§†åŒ–ã€æ¨¡å‹ã€ç½‘ç»œç»“æ„ã€è§£å†³æ–¹æ¡ˆã€è¿½è¸ªå’Œå·¥å…·ç±»çš„åº•å±‚ä»£ç å®ç°ã€‚æ¯”å¦‚åœ¨nnç›®å½•ä¸‹çš„modelsç›®å½•ä¸‹çš„block.pyä¸­å°±ç»™å‡ºäº†c2fæ¨¡å—çš„å®šä¹‰ã€‚\nclass C2f(nn.Module):\r\u0026quot;\u0026quot;\u0026quot;\rè¿™é‡Œä½¿ç”¨äº†åˆ†æ”¯å¤„ç†çš„æ“ä½œï¼Œä½¿ç”¨çš„æ˜¯é€šè¿‡å…³é—­æ®‹å·®é“¾æ¥çš„æ–¹å¼å®ç°\rå…ˆè¿›è¡Œåˆ†æ”¯çš„æ“ä½œç„¶åå†è¿›è¡Œç‰¹å¾èåˆçš„æ“ä½œ\rFaster Implementation of CSP Bottleneck with 2 convolutions.\r\u0026quot;\u0026quot;\u0026quot;\rdef __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):\r\u0026quot;\u0026quot;\u0026quot;Initialize CSP bottleneck layer with two convolutions with arguments ch_in, ch_out, number, shortcut, groups,\rexpansion.\r\u0026quot;\u0026quot;\u0026quot;\rsuper().__init__()\rself.c = int(c2 * e) # hidden channels\rself.cv1 = Conv(c1, 2 * self.c, 1, 1)\rself.cv2 = Conv((2 + n) * self.c, c2, 1) # optional act=FReLU(c2)\rself.m = nn.ModuleList(Bottleneck(self.c, self.c, shortcut, g, k=((3, 3), (3, 3)), e=1.0) for _ in range(n))\rdef forward(self, x):\r\u0026quot;\u0026quot;\u0026quot;Forward pass through C2f layer.\u0026quot;\u0026quot;\u0026quot;\ry = list(self.cv1(x).chunk(2, 1))\ry.extend(m(y[-1]) for m in self.m)\rreturn self.cv2(torch.cat(y, 1))\rdef forward_split(self, x):\r\u0026quot;\u0026quot;\u0026quot;Forward pass using split() instead of chunk().\u0026quot;\u0026quot;\u0026quot;\ry = list(self.cv1(x).split((self.c, self.c), 1))\ry.extend(m(y[-1]) for m in self.m)\rreturn self.cv2(torch.cat(y, 1))\râ€‹\nultralytics.egg-info/ egg-infoæ˜¯ä¸€ä¸ªç›®å½• ï¼Œå®ƒåœ¨å®‰è£…æˆ–å¼€å‘PythonåŒ…æ—¶ç”±setuptoolsç”Ÿæˆï¼Œç”¨äºå­˜å‚¨å…³äºè¯¥åŒ…çš„å…ƒæ•°æ®ã€‚è¿™äº›å…ƒæ•°æ®å¯¹äºåŒ…çš„ç®¡ç†ã€åˆ†å‘å’Œå®‰è£…è‡³å…³é‡è¦ï¼Œå®ƒä»¬å¸®åŠ©pipå’Œå…¶ä»–å·¥å…·äº†è§£åŒ…çš„è¯¦ç»†ä¿¡æ¯ã€ç‰ˆæœ¬ä¿¡æ¯ã€ä¾èµ–å…³ç³»ç­‰ã€‚è¿™ä¸ªç›®å½•æ˜¯æˆ‘ä»¬æ‰§è¡ŒpipæŒ‡ä»¤ä»¥å¼€å‘è€…æ¨¡å¼å®‰è£…çš„æ—¶å€™å‡ºç°çš„ã€‚\nCITATION.cff è¿™ä¸ªæ–‡ä»¶ä¸­åŒ…å«äº†å¼•ç”¨è¿™ä¸ªé¡¹ç›®çš„æ ¼å¼è¯´æ˜ã€‚\nCONTRIBUTING.md è¿™ä¸ªé‡Œé¢è¯´æ˜äº†ä½ å¯ä»¥å¦‚ä½•ä¸ºè¿™ä¸ªé¡¹ç›®æä¾›è‡ªå·±çš„è´¡çŒ®ï¼Œè®©è‡ªå·±çš„åå­—å‡ºç°åœ¨ä½œè€…åå•ä¸­ã€‚\nLICENSE æä¾›äº†è¿™è¯¥é¡¹ç›®çš„è®¸å¯ä¿¡æ¯ã€‚\nmkdocs.yml ç”¨äºå®šä¹‰é¡¹ç›®çš„å„ç§è®¾ç½®å’Œé…ç½®é€‰é¡¹ã€‚\npyproject.toml pyproject.toml æ˜¯ä¸€ä¸ªåœ¨ Python é¡¹ç›®ä¸­å¹¿æ³›ä½¿ç”¨çš„é…ç½®æ–‡ä»¶ï¼Œå®ƒä¸»è¦ç”¨äºå®šä¹‰é¡¹ç›®çš„æ„å»ºç³»ç»Ÿè¦æ±‚ã€ä¾èµ–å…³ç³»ä»¥åŠç›¸å…³çš„å·¥å…·é…ç½®ã€‚ç°åœ¨è¿™ä¸ª pyproject.toml ä¹Ÿæ˜¯å®˜æ–¹ä»PEP 518å¼€å§‹æ¨èçš„é¡¹ç›®é…ç½®æ–¹å¼ï¼Œæ„Ÿå…´è¶£çš„å°ä¼™ä¼´å¯ä»¥å»çœ‹ä¸€ä¸‹poetryè¿™ä¸ªåº“ï¼Œé€šè¿‡poetry newå¯ä»¥å¾ˆæ–¹ä¾¿å¿«æ·çš„ç”Ÿæˆä¸€ä¸ªé¡¹ç›®çš„è„šæ‰‹æ¶ä»£ç ã€‚\nREADME.md è¯´æ˜æ–‡ä»¶ï¼Œä¹Ÿå°±æ˜¯ä½ ç°åœ¨çœ‹åˆ°çš„è¿™ä¸ªå†…å®¹ã€‚\nREADME.zh-CN.md ä¸­æ–‡æ ¼å¼çš„è¯´æ˜æ–‡ä»¶ã€‚\næ•°æ®é›†å‡†å¤‡ æˆ‘ä»¬åœ¨è¿™é‡Œå‡†å¤‡äº†ä¸€ç³»åˆ—æ ‡æ³¨å¥½çš„æ•°æ®é›†ï¼Œå¦‚æœå¤§å®¶ä¸æƒ³è‡ªå·±æ ‡æ³¨å¯ä»¥çœ‹çœ‹è¿™é‡Œæ˜¯å¦æœ‰ä½ éœ€è¦å¾—ï¼šè‚†åäºŒå¤§ä½œä¸šç³»åˆ—æ¸…å•-CSDNåšå®¢\nç°åœ¨æ¥åˆ°æˆ‘ä»¬æ•°æ®é›†å‡†å¤‡çš„ç« èŠ‚ï¼Œè¿™ä¸ªç« èŠ‚æ•™ä¼šå¤§å®¶å¦‚ä½•è‡ªå·±æ„å»ºä¸€ä¸ªyoloçš„æ£€æµ‹æ•°æ®ä»¥åŠå¦‚ä½•ä½¿ç”¨ã€‚\né¦–å…ˆè¿™ä¸ªä½ç½®æä¾›äº†æˆ‘ä»¬æœ¬æ¬¡æ•™ç¨‹ä¸­ä½¿ç”¨åˆ°çš„ä¸€ä»½æ ‡å‡†çš„è¡Œäººæ£€æµ‹çš„æ•°æ®é›†ï¼Œä¸€ä¸ªæ ‡å‡†çš„æ•°æ®é›†çš„æ„æˆåŒ…å«ä¸‹é¢çš„å‡ ä¸ªç›®å½•ã€‚\nâ”œâ”€images # å›¾åƒæ–‡ä»¶å¤¹\râ”‚ â”œâ”€train # è®­ç»ƒé›†å›¾åƒ\râ”‚ â”œâ”€val # éªŒè¯é›†å›¾åƒ\râ”‚ â””â”€test # æµ‹è¯•é›†å›¾åƒ\râ””â”€labels # æ ‡ç­¾æ–‡ä»¶å¤¹ï¼Œæ ‡ç­¾æ ¼å¼ä¸ºyoloçš„txtæ ¼å¼\râ”œâ”€train # è®­ç»ƒé›†æ ‡ç­¾\râ”œâ”€val # éªŒè¯é›†æ ‡ç­¾\râ””â”€test # æµ‹è¯•é›†æ ‡ç­¾\rä»¥è®­ç»ƒé›†ä¸ºä¾‹ï¼Œç»™å°ä¼™ä¼´ä»¬å±•ç¤ºä¸€ä¸‹ä¸€ä¸ªæ­£ç¡®çš„å¯¹åº”å…³ç³»æ˜¯æ€æ ·çš„ï¼Œè¿™é‡Œè®­ç»ƒé›†å›¾åƒæ•°é‡å’Œæ ‡ç­¾æ•°é‡æ˜¯ä¸€è‡´çš„ï¼Œå¹¶ä¸”åç§°ä¸Šé¢å»é™¤åç¼€ä¹‹åæ˜¯ä¸€ä¸€å¯¹åº”çš„ã€‚\nä»¥2007_000480.jpgä¸ºä¾‹ï¼Œä¸‹é¢æ˜¯å¯¹åº”çš„2007_000480.txtä¸­çš„æ ‡æ³¨æ–‡ä»¶å†…å®¹ã€‚è¿™ä¸ªæ ‡æ³¨æ–‡ä»¶æœ‰ä¸‰è¡Œï¼Œå¯¹åº”çš„æ˜¯å›¾åƒä¸­çš„3ä¸ªäººç‰©ï¼Œå…¶ä¸­æ¯è¡ŒåŒ…å«5ä¸ªæ•°å­—ï¼Œåˆ†åˆ«æ˜¯ç±»åˆ«ï¼Œå½’ä¸€åŒ–å¤„ç†ä¹‹åç›®æ ‡ä¸­å¿ƒç‚¹çš„xåæ ‡ã€yåæ ‡ã€ç›®æ ‡å½’ä¸€åŒ–å¤„ç†ä¹‹åå®½åº¦wå’Œç›®æ ‡å½’ä¸€åŒ–å¤„ç†ä¹‹åçš„å®½åº¦hã€‚\nå¦‚æœå¤§å®¶è¦æ ‡æ³¨è‡ªå·±çš„æ•°æ®é›†ï¼Œåˆ™å¯ä»¥ä½¿ç”¨labelimgæ¥è¿›è¡Œæ ‡æ³¨ï¼Œæ ‡æ³¨ä¹‹å‰æœ‰å‡ ç‚¹æ³¨æ„äº‹é¡¹ã€‚\næ ‡æ³¨çš„å›¾åƒå’Œè·¯å¾„å°½é‡ä¸è¦åŒ…å«ä¸­æ–‡ï¼Œå›¾åƒåç§°æœ€å¥½æ˜¯åªæœ‰æ•°å­—æˆ–è€…è‹±æ–‡ã€‚ æ ‡æ³¨çš„æ—¶å€™å°½é‡ä½¿ç”¨jpgçš„æ ¼å¼ï¼Œå¦‚æœæ˜¯gifä¸€ç±»çš„æ ¼å¼åç»­å¯èƒ½æœ‰å…¶ä»–çš„éº»çƒ¦ã€‚ æ ‡æ³¨çš„æ—¶å€™è¯·ä¸€å®šè¦ç¡®ä¿é€‰æ‹©äº†yoloæ ¼å¼ï¼Œå¦‚æœä¸æ˜¯yoloæ ¼å¼åç»­å¤„ç†èµ·æ¥ä¼šéå¸¸éº»çƒ¦ã€‚ æœ€å¥½ä¸€æ¬¡æ€§æ ‡æ³¨å®Œï¼Œè´Ÿè´£å¯èƒ½å¯¼è‡´å‰åä¸¤æ¬¡æ ‡ç­¾çš„ç»“æœä¸ä¸€è‡´ã€‚ okï¼Œé¦–å…ˆå¤§å®¶å¯ä»¥åœ¨ä½ çš„è™šæ‹Ÿç¯å¢ƒä¸­é€šè¿‡pip install labelimgçš„æŒ‡ä»¤å®‰è£…æ ‡æ³¨ç„¶åï¼Œç„¶ååœ¨å‘½ä»¤è¡Œä¸­é”®å…¥labelimgæ¥å¯åŠ¨æ ‡æ³¨è½¯ä»¶ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ‰“å¼€è¦æ ‡æ³¨çš„æ–‡ä»¶å¤¹å°±å¯ä»¥è¿›è¡Œæ ‡æ³¨äº†ï¼Œæ ‡æ³¨ä¹‹åä¸€å®šè¦æ£€æŸ¥æ˜¯å¦æ ‡æ³¨æ–‡ä»¶ä¸ºtxtæ ¼å¼ã€‚\nä¸‹é¢æ˜¯labelimgçš„å¸¸ç”¨çš„å¿«æ·æ–¹å¼ï¼Œå¤§å®¶å¯ä»¥ç†Ÿæ‚‰ä¸‹é¢çš„å¿«æ·æ–¹å¼å¸®åŠ©ä½ æå‡æ ‡æ³¨çš„æ•ˆç‡ã€‚\nctrl+s ä¿å­˜ ctrl+d å¤åˆ¶å½“å‰æ ‡ç­¾å’ŒçŸ©å½¢æ¡† Ctrl + r æ›´æ”¹é»˜è®¤æ³¨é‡Šç›®å½•ï¼ˆxmlæ–‡ä»¶ä¿å­˜çš„åœ°å€ï¼‰ Ctrl + u åŠ è½½ç›®å½•ä¸­çš„æ‰€æœ‰å›¾åƒï¼Œé¼ æ ‡ç‚¹å‡»Open diråŒåŠŸèƒ½ w åˆ›å»ºçŸ©é˜µ d ä¸‹ä¸€å¼  a ä¸Šä¸€å¼  delete åˆ é™¤é€‰å®šçš„çŸ©é˜µæ¡† space å°†å½“å‰å›¾åƒæ ‡è®°ä¸ºå·²æ ‡è®° ç¯å¢ƒé…ç½® æ¥åˆ°æˆ‘ä»¬æœ€ç†Ÿæ‚‰çš„ç« èŠ‚ï¼Œç¯å¢ƒé…ç½®ï¼Œè€ç”Ÿå¸¸è°ˆï¼Œç¯å¢ƒé…ç½®åŸºæœ¬æ˜¯ä¸€è‡´çš„ï¼Œå¼€å§‹å‰è¯·å…ˆå­¦ä¹ pycharmå’Œanacondaçš„ä½¿ç”¨ï¼Œä¸ç†Ÿæ‚‰çš„å°ä¼™ä¼´å¯ä»¥ç§»æ­¥è¿™ä¸ªä½ç½®ï¼šã€å¤§ä½œä¸šç³»åˆ—å…¥é—¨æ•™ç¨‹ã€‘å¦‚ä½•ä½¿ç”¨Anacondaå’ŒPycharm_2024æ¯•è®¾ç³»åˆ—å¦‚ä½•ä½¿ç”¨anaconda-CSDNåšå®¢\nä¸‹è½½å®‰è£…åŒ…åˆ°æœ¬åœ°ï¼Œé¦–å…ˆè¯·æ‰§è¡Œä¸‹åˆ—æŒ‡ä»¤ç¡®ä¿ä½ å·²ç»é…ç½®å¥½äº†å›½å†…çš„æºã€‚\nconda config --remove-key channels\rconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\rconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/\rconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/\rconda config --set show_channel_urls yes\rpip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\rä¹‹åè¯·å…ˆå®‰è£…pytorchï¼Œè¯·æ ¹æ®ä½ è®¾å¤‡çš„å®é™…æƒ…å†µæ¥é€‰æ‹©æ‰§è¡ŒGPUå®‰è£…çš„æŒ‡ä»¤æˆ–è€…æ˜¯CPUå®‰è£…çš„æŒ‡ä»¤ã€‚\nconda install pytorch==1.8.0 torchvision torchaudio cudatoolkit=10.2 # æ³¨æ„è¿™æ¡å‘½ä»¤æŒ‡å®šPytorchçš„ç‰ˆæœ¬å’Œcudaçš„ç‰ˆæœ¬\rconda install pytorch==1.10.0 torchvision torchaudio cudatoolkit=11.3 # 30ç³»åˆ—ä»¥ä¸Šæ˜¾å¡gpuç‰ˆæœ¬pytorchå®‰è£…æŒ‡ä»¤\rconda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cpuonly # CPUçš„å°ä¼™ä¼´ç›´æ¥æ‰§è¡Œè¿™æ¡å‘½ä»¤å³å¯\ræ¥ç€æ¥åˆ°é¡¹ç›®çš„ç›®å½•ä¸‹ï¼Œä»¥å¼€å‘è€…çš„æ¨¡å¼å®‰è£…å…¶ä½™éœ€è¦çš„åº“ã€‚\npip install -v -e .\rOKï¼Œæˆ‘ä»¬æ¥åšä¸€ä¸ªç®€å•çš„æµ‹è¯•ï¼Œè§‚çœ‹æ˜¯å¦ç”Ÿæ•ˆï¼Œå¦‚æœä½ çœ‹åˆ°äº†ä¸‹é¢çš„ç»“æœåˆ™è¯´æ˜ä½ çš„ç¯å¢ƒé…ç½®æ²¡æœ‰é—®é¢˜ã€‚\nå¦‚æœæ²¡æœ‰å‡ºç°ä¸Šé¢çš„æ£€æµ‹ç»“æœï¼Œåˆ™è¯´æ˜ä½ çš„é…ç½®å‡ºç°äº†é—®é¢˜ï¼Œå¯ä»¥åœ¨è¯„è®ºåŒºä¸­ç•™è¨€ï¼Œè®©å°ä¼™ä¼´ä»¬ä¸€åŒç»™ä½ è§£ç­”ã€‚\næ¨¡å‹è®­ç»ƒå’Œæµ‹è¯• æ¨¡å‹çš„è®­ç»ƒ è®­ç»ƒçš„è„šæœ¬å¯¹åº”çš„æ˜¯ï¼š\nimport time\rfrom ultralytics import YOLO\râ€‹ # yolov8næ¨¡å‹è®­ç»ƒï¼šè®­ç»ƒæ¨¡å‹çš„æ•°æ®ä¸º\u0026rsquo;A_my_data.yaml\u0026rsquo;ï¼Œè½®æ•°ä¸º100ï¼Œå›¾ç‰‡å¤§å°ä¸º640ï¼Œè®¾å¤‡ä¸ºæœ¬åœ°çš„GPUæ˜¾å¡ï¼Œå…³é—­å¤šçº¿ç¨‹çš„åŠ è½½ï¼Œå›¾åƒåŠ è½½çš„æ‰¹æ¬¡å¤§å°ä¸º4ï¼Œå¼€å¯å›¾ç‰‡ç¼“å­˜ model = YOLO(\u0026lsquo;yolov8n.pt\u0026rsquo;) # load a pretrained model (recommended for training) results = model.train(data=\u0026lsquo;A_my_data.yaml\u0026rsquo;, epochs=100, imgsz=640, device=[0,], workers=0, batch=4, cache=True) # å¼€å§‹è®­ç»ƒ time.sleep(10) # ç¡çœ 10sï¼Œä¸»è¦æ˜¯ç”¨äºæœåŠ¡å™¨å¤šæ¬¡è®­ç»ƒçš„è¿‡ç¨‹ä¸­ä½¿ç”¨\nâ€‹ â€‹\nå¼€å§‹ä¹‹å‰è¯·é…ç½®å¥½ä½ çš„æ•°æ®é›†çš„è·¯å¾„å’Œå›¾ç‰‡åç§°ï¼Œæ¯”å¦‚æˆ‘ä»¬ä»Šå¤©è®­ç»ƒçš„è¡Œäººæ£€æµ‹çš„æ•°æ®é›†çš„é…ç½®å¦‚ä¸‹ï¼š\n# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\rpath: ../../person_42_yolo_format\rtrain: # train images (relative to 'path') 16551 images\r- images/train\rval: # val images (relative to 'path') 4952 images\r- images/val\rtest: # test images (optional)\r- images/test\r# Classes\r# ['Chave', 'DISJUNTOR', 'TP', 'Pararraio', 'TC']\rnames:\r: person\râ€‹\né…ç½®å¥½äº†ç›´æ¥å³é”®è¿è¡Œå³å¯ï¼Œæ¯”å¦‚æˆ‘ä»¬è¿™é‡Œæ˜¯è®­ç»ƒ100è½®ï¼Œè®­ç»ƒçš„è¿‡ç¨‹ä¸­è¿›åº¦æ¡ä¼šå®æ—¶è¿›è¡Œæ›´æ–°ã€‚\nè®­ç»ƒå®Œæ¯•ä¹‹åï¼Œå°†ä¼šåœ¨runsç›®å½•ä¸‹ç”Ÿæˆä¸€ç³»åˆ—çš„ç»“æœå›¾åƒã€‚\nå…¶ä¸­å¦‚æœä½ éœ€è¦åœ¨ä½ çš„æŠ¥å‘Šä¸­è¯´æ˜æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹å’Œè®­ç»ƒç»“æœï¼Œä½¿ç”¨æœ€å¤šçš„åˆ†åˆ«æ˜¯results.pngå’ŒPR_curve.pngï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\næ¨¡å‹çš„æµ‹è¯• æµ‹è¯•çš„è„šæœ¬å¯¹åº”çš„æ˜¯ï¼š\nfrom ultralytics import YOLO\r# åŠ è½½è‡ªå·±è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¡«å†™ç›¸å¯¹äºè¿™ä¸ªè„šæœ¬çš„ç›¸å¯¹è·¯å¾„æˆ–è€…å¡«å†™ç»å¯¹è·¯å¾„å‡å¯\rmodel = YOLO(\u0026quot;runs/detect/yolov8n/weights/best.pt\u0026quot;)\r# å¼€å§‹è¿›è¡ŒéªŒè¯ï¼ŒéªŒè¯çš„æ•°æ®é›†ä¸º'A_my_data.yaml'ï¼Œå›¾åƒå¤§å°ä¸º640ï¼Œæ‰¹æ¬¡å¤§å°ä¸º4ï¼Œç½®ä¿¡åº¦åˆ†æ•°ä¸º0.25ï¼Œäº¤å¹¶æ¯”çš„é˜ˆå€¼ä¸º0.6ï¼Œè®¾å¤‡ä¸º0ï¼Œå…³é—­å¤šçº¿ç¨‹ï¼ˆwindowsä¸‹ä½¿ç”¨å¤šçº¿ç¨‹åŠ è½½æ•°æ®å®¹æ˜“å‡ºç°é—®é¢˜ï¼‰\rvalidation_results = model.val(data='A_my_data.yaml', imgsz=640, batch=4, conf=0.25, iou=0.6, device=\u0026quot;0\u0026quot;, workers=0)\râ€‹\næ‰§è¡Œæµ‹è¯•çš„è„šæœ¬ï¼Œå°†ä¼šè¾“å‡ºä¸‹é¢çš„éªŒè¯æŒ‡æ ‡ã€‚\nå¦‚æœä½ ä¸éœ€è¦å›¾å½¢åŒ–ç•Œé¢ï¼Œå¯ä»¥é€šè¿‡ä¸‹é¢çš„è„šæœ¬æ¥ç›´æ¥å¯¹å›¾åƒè¿›è¡Œé¢„æµ‹ã€‚\nfrom ultralytics import YOLO\r# Load a model\rmodel = YOLO(\u0026quot;yolov8n.pt\u0026quot;) # pretrained YOLOv8n model\r# Run batched inference on a list of images\rresults = model([\u0026quot;images/resources/demo.jpg\u0026quot;, ]) # return a list of Results objects\r# Process results list\rfor result in results:\rboxes = result.boxes # Boxes object for bounding box outputs\rmasks = result.masks # Masks object for segmentation masks outputs\rkeypoints = result.keypoints # Keypoints object for pose outputs\rprobs = result.probs # Probs object for classification outputs\robb = result.obb # Oriented boxes object for OBB outputs\rresult.show() # display to screen\rresult.save(filename=\u0026quot;images/resources/result.jpg\u0026quot;) # save to disk\râ€‹\nå›¾å½¢åŒ–ç•Œé¢å¼€å‘ å›¾å½¢åŒ–ç•Œé¢éƒ¨åˆ†çš„å¼€å‘ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†æ–°çš„PySide6/PyQt6ã€‚PyQtå’ŒPySideéƒ½æ˜¯C++çš„ç¨‹åºå¼€å‘æ¡†æ¶Qtçš„Pythonå®ç°ã€‚PyQtæ˜¯ç¬¬ä¸‰æ–¹ç»„ç»‡å¯¹Qtå®˜æ–¹æä¾›çš„Pythonå®ç°ï¼Œä¹Ÿæ˜¯Qt for Pythonæœ€ä¸»è¦çš„å®ç°ã€‚Qtå®˜æ–¹å¯¹Pythonçš„æ”¯æŒåŠ›åº¦è¶Šæ¥è¶Šå¤§ï¼Œç”±äºå„ç§åŸå› ï¼ŒQtçš„å®˜æ–¹é€‰æ‹©ä½¿ç”¨PySideæä¾›å¯¹Python Qtçš„æ”¯æŒã€‚æ‰€ä»¥ï¼ŒPython Qtå®é™…ä¸Šå­˜åœ¨ä¸¤ä¸ªåˆ†æ”¯ï¼šQt4å¯¹åº”PyQt4å’ŒPySideï¼›Qt5å¯¹åº”PyQt5å’ŒPySide2ï¼›Qt6åˆ™å¯¹åº”äº†PyQt6å’ŒPySide6ã€‚ç”±äºå®˜æ–¹æä¾›çš„PySide6ä»åŠŸèƒ½ä¸Šæ¥è¯´æ›´å¼ºï¼Œæ‰€ä»¥æˆ‘ä»¬è¿˜æ˜¯åˆ‡æ¢ä¸ºPySide6ä½œä¸ºæœ¬æ¬¡å›¾å½¢åŒ–ç•Œé¢å¼€å‘çš„æ¡†æ¶ã€‚ï¼ˆå®æµ‹ä¸‹æ¥ä»–ä»¬ç›´æ¥çš„åˆ‡æ¢å¯¹äºæˆ‘ä»¬è¿™äº›å¼€å‘äººå‘˜æ¥è¯´éå¸¸ä¸æ»‘ï¼Œæˆ‘æœ¬æ¬¡çš„æ›´æ–°ä¸­ä¹Ÿåªæ˜¯æ›´æ¢äº†ä¸€ä¸‹å¯¼å…¥çš„è¿‡ç¨‹ï¼‰\nä¸‹é¢æ˜¯æˆ‘ä»¬è¿™ä¸ªå›¾å½¢åŒ–ç•Œé¢ç¨‹åºçš„å®ç°ï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„å›¾å½¢åŒ–ç•Œé¢æ²¡æœ‰ä½¿ç”¨åˆ°designerçš„å›¾å½¢åŒ–å·¥å…·ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„ä»£ç æ˜¯æ²¡æœ‰UIæ–‡ä»¶çš„ï¼Œå¦‚æœæœ‰å°ä¼™ä¼´å¯¹designeré‚£ç§å¯è§†åŒ–çš„å›¾å½¢åŒ–ç•Œé¢æ¯”è¾ƒæ„Ÿå…´è¶£ï¼Œå¯ä»¥å»å­¦ä¹ ä¸€ä¸‹é‚£ç§æ–¹å¼ï¼Œæ„å»ºå‡ºæ¥çš„å›¾å½¢åŒ–ç•Œé¢å¯èƒ½æ¯”è¾ƒç‚«ä¸€äº›ã€‚\nimport copy # ç”¨äºå›¾åƒå¤åˆ¶\rimport os # ç”¨äºç³»ç»Ÿè·¯å¾„æŸ¥æ‰¾\rimport shutil # ç”¨äºå¤åˆ¶\rfrom PySide6.QtGui import * # GUIç»„ä»¶\rfrom PySide6.QtCore import * # å­—ä½“ã€è¾¹è·ç­‰ç³»ç»Ÿå˜é‡\rfrom PySide6.QtWidgets import * # çª—å£ç­‰å°ç»„ä»¶\rimport threading # å¤šçº¿ç¨‹\rimport sys # ç³»ç»Ÿåº“\rimport cv2 # opencvå›¾åƒå¤„ç†\rimport torch # æ·±åº¦å­¦ä¹ æ¡†æ¶\rimport os.path as osp # è·¯å¾„æŸ¥æ‰¾\rimport time # æ—¶é—´è®¡ç®—\rfrom ultralytics import YOLO # yoloæ ¸å¿ƒç®—æ³•\r# å¸¸ç”¨çš„å­—ç¬¦ä¸²å¸¸é‡\rWINDOW_TITLE =\u0026quot;Target detection system\u0026quot;\rWELCOME_SENTENCE = \u0026quot;æ¬¢è¿ä½¿ç”¨åŸºäºyolov8çš„è¡Œäººæ£€æµ‹ç³»ç»Ÿ\u0026quot;\rICON_IMAGE = \u0026quot;images/UI/lufei.png\u0026quot;\rIMAGE_LEFT_INIT = \u0026quot;images/UI/up.jpeg\u0026quot;\rIMAGE_RIGHT_INIT = \u0026quot;images/UI/right.jpeg\u0026quot;\râ€‹ class MainWindow(QTabWidget): def init(self): # åˆå§‹åŒ–ç•Œé¢ super().init() self.setWindowTitle(WINDOW_TITLE) # ç³»ç»Ÿç•Œé¢æ ‡é¢˜ self.resize(1200, 800) # ç³»ç»Ÿåˆå§‹åŒ–å¤§å° self.setWindowIcon(QIcon(ICON_IMAGE)) # ç³»ç»Ÿlogoå›¾åƒ self.output_size = 480 # ä¸Šä¼ çš„å›¾åƒå’Œè§†é¢‘åœ¨ç³»ç»Ÿç•Œé¢ä¸Šæ˜¾ç¤ºçš„å¤§å° self.img2predict = \u0026quot;\u0026quot; # è¦è¿›è¡Œé¢„æµ‹çš„å›¾åƒè·¯å¾„ # self.device = \u0026lsquo;cpu\u0026rsquo; self.init_vid_id = \u0026lsquo;0\u0026rsquo; # æ‘„åƒå¤´ä¿®æ”¹ self.vid_source = int(self.init_vid_id) self.cap = cv2.VideoCapture(self.vid_source) self.stopEvent = threading.Event() self.webcam = True self.stopEvent.clear() self.model_path = \u0026ldquo;yolov8n.pt\u0026rdquo; # todo æŒ‡æ˜æ¨¡å‹åŠ è½½çš„ä½ç½®çš„è®¾å¤‡ self.model = self.model_load(weights=self.model_path) self.conf_thres = 0.25 # ç½®ä¿¡åº¦çš„é˜ˆå€¼ self.iou_thres = 0.45 # NMSæ“ä½œçš„æ—¶å€™ IOUè¿‡æ»¤çš„é˜ˆå€¼ self.vid_gap = 30 # æ‘„åƒå¤´è§†é¢‘å¸§ä¿å­˜é—´éš”ã€‚ self.initUI() # åˆå§‹åŒ–å›¾å½¢åŒ–ç•Œé¢ self.reset_vid() # é‡æ–°è®¾ç½®è§†é¢‘å‚æ•°ï¼Œé‡æ–°åˆå§‹åŒ–æ˜¯ä¸ºäº†é˜²æ­¢è§†é¢‘åŠ è½½å‡ºé”™\n# æ¨¡å‹åˆå§‹åŒ–\r@torch.no_grad()\rdef model_load(self, weights=\u0026quot;\u0026quot;):\r\u0026quot;\u0026quot;\u0026quot;\ræ¨¡å‹åŠ è½½\r\u0026quot;\u0026quot;\u0026quot;\rmodel_loaded = YOLO(weights)\rreturn model_loaded\rdef initUI(self):\r\u0026quot;\u0026quot;\u0026quot;\rå›¾å½¢åŒ–ç•Œé¢åˆå§‹åŒ–\r\u0026quot;\u0026quot;\u0026quot;\r# ********************* å›¾ç‰‡è¯†åˆ«ç•Œé¢ *****************************\rfont_title = QFont('æ¥·ä½“', 16)\rfont_main = QFont('æ¥·ä½“', 14)\rimg_detection_widget = QWidget()\rimg_detection_layout = QVBoxLayout()\rimg_detection_title = QLabel(\u0026quot;å›¾ç‰‡è¯†åˆ«åŠŸèƒ½\u0026quot;)\rimg_detection_title.setFont(font_title)\rmid_img_widget = QWidget()\rmid_img_layout = QHBoxLayout()\rself.left_img = QLabel()\rself.right_img = QLabel()\rself.left_img.setPixmap(QPixmap(IMAGE_LEFT_INIT))\rself.right_img.setPixmap(QPixmap(IMAGE_RIGHT_INIT))\rself.left_img.setAlignment(Qt.AlignCenter)\rself.right_img.setAlignment(Qt.AlignCenter)\rmid_img_layout.addWidget(self.left_img)\rmid_img_layout.addWidget(self.right_img)\rself.img_num_label = QLabel(\u0026quot;å½“å‰æ£€æµ‹ç»“æœï¼šå¾…æ£€æµ‹\u0026quot;)\rself.img_num_label.setFont(font_main)\rmid_img_widget.setLayout(mid_img_layout)\rup_img_button = QPushButton(\u0026quot;ä¸Šä¼ å›¾ç‰‡\u0026quot;)\rdet_img_button = QPushButton(\u0026quot;å¼€å§‹æ£€æµ‹\u0026quot;)\rup_img_button.clicked.connect(self.upload_img)\rdet_img_button.clicked.connect(self.detect_img)\rup_img_button.setFont(font_main)\rdet_img_button.setFont(font_main)\rup_img_button.setStyleSheet(\u0026quot;QPushButton{color:white}\u0026quot;\r\u0026quot;QPushButton:hover{background-color: rgb(2,110,180);}\u0026quot;\r\u0026quot;QPushButton{background-color:rgb(48,124,208)}\u0026quot;\r\u0026quot;QPushButton{border:2px}\u0026quot;\r\u0026quot;QPushButton{border-radius:5px}\u0026quot;\r\u0026quot;QPushButton{padding:5px 5px}\u0026quot;\r\u0026quot;QPushButton{margin:5px 5px}\u0026quot;)\rdet_img_button.setStyleSheet(\u0026quot;QPushButton{color:white}\u0026quot;\r\u0026quot;QPushButton:hover{background-color: rgb(2,110,180);}\u0026quot;\r\u0026quot;QPushButton{background-color:rgb(48,124,208)}\u0026quot;\r\u0026quot;QPushButton{border:2px}\u0026quot;\r\u0026quot;QPushButton{border-radius:5px}\u0026quot;\r\u0026quot;QPushButton{padding:5px 5px}\u0026quot;\r\u0026quot;QPushButton{margin:5px 5px}\u0026quot;)\rimg_detection_layout.addWidget(img_detection_title, alignment=Qt.AlignCenter)\rimg_detection_layout.addWidget(mid_img_widget, alignment=Qt.AlignCenter)\rimg_detection_layout.addWidget(self.img_num_label)\rimg_detection_layout.addWidget(up_img_button)\rimg_detection_layout.addWidget(det_img_button)\rimg_detection_widget.setLayout(img_detection_layout)\r# ********************* è§†é¢‘è¯†åˆ«ç•Œé¢ *****************************\rvid_detection_widget = QWidget()\rvid_detection_layout = QVBoxLayout()\rvid_title = QLabel(\u0026quot;è§†é¢‘æ£€æµ‹åŠŸèƒ½\u0026quot;)\rvid_title.setFont(font_title)\rself.vid_img = QLabel()\rself.vid_img.setPixmap(QPixmap(\u0026quot;images/UI/up.jpeg\u0026quot;))\rvid_title.setAlignment(Qt.AlignCenter)\rself.vid_img.setAlignment(Qt.AlignCenter)\rself.webcam_detection_btn = QPushButton(\u0026quot;æ‘„åƒå¤´å®æ—¶ç›‘æµ‹\u0026quot;)\rself.mp4_detection_btn = QPushButton(\u0026quot;è§†é¢‘æ–‡ä»¶æ£€æµ‹\u0026quot;)\rself.vid_stop_btn = QPushButton(\u0026quot;åœæ­¢æ£€æµ‹\u0026quot;)\rself.webcam_detection_btn.setFont(font_main)\rself.mp4_detection_btn.setFont(font_main)\rself.vid_stop_btn.setFont(font_main)\rself.webcam_detection_btn.setStyleSheet(\u0026quot;QPushButton{color:white}\u0026quot;\r\u0026quot;QPushButton:hover{background-color: rgb(2,110,180);}\u0026quot;\r\u0026quot;QPushButton{background-color:rgb(48,124,208)}\u0026quot;\r\u0026quot;QPushButton{border:2px}\u0026quot;\r\u0026quot;QPushButton{border-radius:5px}\u0026quot;\r\u0026quot;QPushButton{padding:5px 5px}\u0026quot;\r\u0026quot;QPushButton{margin:5px 5px}\u0026quot;)\rself.mp4_detection_btn.setStyleSheet(\u0026quot;QPushButton{color:white}\u0026quot;\r\u0026quot;QPushButton:hover{background-color: rgb(2,110,180);}\u0026quot;\r\u0026quot;QPushButton{background-color:rgb(48,124,208)}\u0026quot;\r\u0026quot;QPushButton{border:2px}\u0026quot;\r\u0026quot;QPushButton{border-radius:5px}\u0026quot;\r\u0026quot;QPushButton{padding:5px 5px}\u0026quot;\r\u0026quot;QPushButton{margin:5px 5px}\u0026quot;)\rself.vid_stop_btn.setStyleSheet(\u0026quot;QPushButton{color:white}\u0026quot;\r\u0026quot;QPushButton:hover{background-color: rgb(2,110,180);}\u0026quot;\r\u0026quot;QPushButton{background-color:rgb(48,124,208)}\u0026quot;\r\u0026quot;QPushButton{border:2px}\u0026quot;\r\u0026quot;QPushButton{border-radius:5px}\u0026quot;\r\u0026quot;QPushButton{padding:5px 5px}\u0026quot;\r\u0026quot;QPushButton{margin:5px 5px}\u0026quot;)\rself.webcam_detection_btn.clicked.connect(self.open_cam)\rself.mp4_detection_btn.clicked.connect(self.open_mp4)\rself.vid_stop_btn.clicked.connect(self.close_vid)\rvid_detection_layout.addWidget(vid_title)\rvid_detection_layout.addWidget(self.vid_img)\r# todo æ·»åŠ æ‘„åƒå¤´æ£€æµ‹æ ‡ç­¾é€»è¾‘\rself.vid_num_label = QLabel(\u0026quot;å½“å‰æ£€æµ‹ç»“æœï¼š{}\u0026quot;.format(\u0026quot;ç­‰å¾…æ£€æµ‹\u0026quot;))\rself.vid_num_label.setFont(font_main)\rvid_detection_layout.addWidget(self.vid_num_label)\rvid_detection_layout.addWidget(self.webcam_detection_btn)\rvid_detection_layout.addWidget(self.mp4_detection_btn)\rvid_detection_layout.addWidget(self.vid_stop_btn)\rvid_detection_widget.setLayout(vid_detection_layout)\r# ********************* æ¨¡å‹åˆ‡æ¢ç•Œé¢ *****************************\rabout_widget = QWidget()\rabout_layout = QVBoxLayout()\rabout_title = QLabel(WELCOME_SENTENCE)\rabout_title.setFont(QFont('æ¥·ä½“', 18))\rabout_title.setAlignment(Qt.AlignCenter)\rabout_img = QLabel()\rabout_img.setPixmap(QPixmap('images/UI/zhu.jpg'))\rself.model_label = QLabel(\u0026quot;å½“å‰æ¨¡å‹ï¼š{}\u0026quot;.format(self.model_path))\rself.model_label.setFont(font_main)\rchange_model_button = QPushButton(\u0026quot;åˆ‡æ¢æ¨¡å‹\u0026quot;)\rchange_model_button.setFont(font_main)\rchange_model_button.setStyleSheet(\u0026quot;QPushButton{color:white}\u0026quot;\r\u0026quot;QPushButton:hover{background-color: rgb(2,110,180);}\u0026quot;\r\u0026quot;QPushButton{background-color:rgb(48,124,208)}\u0026quot;\r\u0026quot;QPushButton{border:2px}\u0026quot;\r\u0026quot;QPushButton{border-radius:5px}\u0026quot;\r\u0026quot;QPushButton{padding:5px 5px}\u0026quot;\r\u0026quot;QPushButton{margin:5px 5px}\u0026quot;)\rrecord_button = QPushButton(\u0026quot;æŸ¥çœ‹å†å²è®°å½•\u0026quot;)\rrecord_button.setFont(font_main)\rrecord_button.clicked.connect(self.check_record)\rrecord_button.setStyleSheet(\u0026quot;QPushButton{color:white}\u0026quot;\r\u0026quot;QPushButton:hover{background-color: rgb(2,110,180);}\u0026quot;\r\u0026quot;QPushButton{background-color:rgb(48,124,208)}\u0026quot;\r\u0026quot;QPushButton{border:2px}\u0026quot;\r\u0026quot;QPushButton{border-radius:5px}\u0026quot;\r\u0026quot;QPushButton{padding:5px 5px}\u0026quot;\r\u0026quot;QPushButton{margin:5px 5px}\u0026quot;)\rchange_model_button.clicked.connect(self.change_model)\rabout_img.setAlignment(Qt.AlignCenter)\rlabel_super = QLabel() # todo æ›´æ¢ä½œè€…ä¿¡æ¯\rlabel_super.setText(\u0026quot;\u0026lt;a href='https://blog.csdn.net/ECHOSON'\u0026gt;ä½œè€…ï¼šè‚†åäºŒ\u0026lt;/a\u0026gt;\u0026quot;)\rlabel_super.setFont(QFont('æ¥·ä½“', 16))\rlabel_super.setOpenExternalLinks(True)\rlabel_super.setAlignment(Qt.AlignRight)\rabout_layout.addWidget(about_title)\rabout_layout.addStretch()\rabout_layout.addWidget(about_img)\rabout_layout.addWidget(self.model_label)\rabout_layout.addStretch()\rabout_layout.addWidget(change_model_button)\rabout_layout.addWidget(record_button)\rabout_layout.addWidget(label_super)\rabout_widget.setLayout(about_layout)\rself.left_img.setAlignment(Qt.AlignCenter)\rself.addTab(about_widget, 'ä¸»é¡µ')\rself.addTab(img_detection_widget, 'å›¾ç‰‡æ£€æµ‹')\rself.addTab(vid_detection_widget, 'è§†é¢‘æ£€æµ‹')\rself.setTabIcon(0, QIcon(ICON_IMAGE))\rself.setTabIcon(1, QIcon(ICON_IMAGE))\rself.setTabIcon(2, QIcon(ICON_IMAGE))\ræˆ‘ä»¬åœ¨ä»£ç çš„è¿™ä¸ªä½ç½®å¯ä»¥æ›´æ¢è¿™ä¸ªç³»ç»Ÿçš„é»˜è®¤æ ‡é¢˜å’Œé»˜è®¤çš„logoå›¾åƒã€‚\nä»¥åŠåœ¨è¿™ä¸ªä½ç½®å¯ä»¥æ›´æ¢ä¸ºä½ è‡ªå·±çš„æ¨¡å‹ã€‚\n","date":"0001-01-01T00:00:00Z","permalink":"https://nickk111.github.io/p/","title":""}]